<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Rust Cross Compile on OSX</title>
    <link href="/tech/rust_cross_compile_on_osx/"/>
    <url>/tech/rust_cross_compile_on_osx/</url>
    
    <content type="html"><![CDATA[<blockquote><p>Talk is cheap, show me the Makefile.</p></blockquote><h2 id="Setup">Setup</h2><div class="code-wrapper"><pre><code class="hljs make"><span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>: osx-setup-musl</span><span class="hljs-section">setup-osx-musl:</span>@brew install filosottile/musl-cross/musl-cross<span class="hljs-comment"># @sudo ln -s &quot;$(brew --prefix musl-cross)/bin/x86_64-linux-musl-gcc&quot; /usr/local/bin/musl-gcc</span><span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>: osx-setup-gnu</span><span class="hljs-section">setup-osx-gnu:</span>@brew tap SergioBenitez/osxct@brew install x86_64-unknown-linux-gnu</code></pre></div><h2 id="Build">Build</h2><div class="code-wrapper"><pre><code class="hljs make"><span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>: osx-cross-build-gnu</span><span class="hljs-section">osx-cross-build-gnu:</span>@echo <span class="hljs-string">&quot;Building presence-tool with gnu&quot;</span>@rustup target add x86_64-unknown-linux-gnu@CARGO_TARGET_X86_64_UNKNOWN_LINUX_GNU_LINKER=x86_64-unknown-linux-gnu-gcc cargo build --release --target=x86_64-unknown-linux-gnu<span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>: osx-cross-build-musl</span><span class="hljs-section">osx-cross-build-musl:</span>@echo <span class="hljs-string">&quot;Building presence-tool with musl&quot;</span>@rustup target add x86_64-unknown-linux-musl@CARGO_TARGET_X86_64_UNKNOWN_LINUX_MUSL_LINKER=x86_64-linux-musl-gcc cargo build --release --target x86_64-unknown-linux-musl</code></pre></div><h2 id="Chore">Chore</h2><div class="code-wrapper"><pre><code class="hljs make"><span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>: osx-setup-cargo-hint</span><span class="hljs-section">setup-osx-cargo-hint:</span>@echo <span class="hljs-string">&quot;Put these lines into your ~/.cargo/config.toml:&quot;</span>@echo &#x27;```toml&#x27;@echo <span class="hljs-string">&quot;[target.x86_64-unknown-linux-musl]&quot;</span>@echo <span class="hljs-string">&quot;linker = \&quot;x86_64-linux-musl-gcc\&quot;&quot;</span>@echo <span class="hljs-string">&quot;[target.x86_64-unknown-linux-gnu]&quot;</span>@echo <span class="hljs-string">&quot;linker = \&quot;x86_64-unknown-linux-gnu-gcc\&quot;&quot;</span>@echo &#x27;```&#x27;<span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>: install-bin</span><span class="hljs-section">install-bin:</span>@echo <span class="hljs-string">&quot;Installing current bin crate to ~/.cargo/bin&quot;</span>@cargo install --path .<span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>: check-dynamic-link-osx</span><span class="hljs-section">check-dynamic-link-osx: build</span>@echo <span class="hljs-string">&quot;Checking for dynamic linking on OSX&quot;</span>@otool -L target/release/presence-tool<span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>: check-dynamic-link-linux</span><span class="hljs-section">check-dynamic-link-linux: build-musl</span>@echo <span class="hljs-string">&quot;Checking for dynamic linking on Linux&quot;</span>@ldd target/release/presence-tool</code></pre></div><h2 id="Cargo-Config">Cargo Config</h2><div class="code-wrapper"><pre><code class="hljs toml"><span class="hljs-section">[target.x86_64-unknown-linux-musl]</span><span class="hljs-attr">linker</span> = <span class="hljs-string">&quot;x86_64-linux-musl-gcc&quot;</span><span class="hljs-section">[target.x86_64-unknown-linux-gnu]</span><span class="hljs-attr">linker</span> = <span class="hljs-string">&quot;x86_64-unknown-linux-gnu-gcc&quot;</span></code></pre></div><p>Once you’ve configured your <code>Cargo.toml</code> and <code>~/.cargo/config.toml</code>, you can simply try this:</p><div class="code-wrapper"><pre><code class="hljs make"><span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>: build-musl</span><span class="hljs-section">build-musl:</span>@rustup target add x86_64-unknown-linux-musl <span class="hljs-comment"># this line is optional</span>@cargo build --release --target x86_64-unknown-linux-musl</code></pre></div>]]></content>
    
    
    <categories>
      
      <category>tech</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rust</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Rust Atomics and Locks</title>
    <link href="/tech/rust_atomics_and_locks/"/>
    <url>/tech/rust_atomics_and_locks/</url>
    
    <content type="html"><![CDATA[<div class="note note-warning">            <p>WIP, No ETA provided</p>          </div><div class="note note-danger">            <p>TL;DR - Please refer to the ToC on the right side</p>          </div><blockquote><p>The <strong><em>tremendous</em></strong> book<br><a href="https://marabos.nl/atomics/"><em>Rust Atomics and Locks</em></a> by <a href="https://marabos.nl/">Mara Bos</a><br>in my POV.</p></blockquote><h2 id="Cell-RefCell">Cell, RefCell</h2><p><strong><em>Interior mutability</em></strong>: a design pattern in Rust that allows you to mutate data even when there are immutable references to that data.</p><p>In short, you can use <code>fn foo(&amp;self)</code> to change the data inside the struct. Normally, we have to use <code>fn foo(&amp;mut self)</code>.</p><p><strong>Cell</strong></p><ul><li><code>take()</code> out the data, modify it, and <code>set()</code> it back.<blockquote><p><code>Mutex</code> is the concurrent version of <code>Cell</code>.</p></blockquote></li></ul><p><strong>Refcell:</strong></p><ul><li><code>borrow_mut()</code> will panic if there’s already a mutable borrow.<blockquote><p><code>RWMutex</code> is the concurrent version of <code>RefCell</code>, but it will block until the mutable borrow is released instead of panicking.</p></blockquote></li></ul><div class="note note-light">            <p><strong>Aside: UnsafeCell</strong><br>Both of them are built with a core primitive called <code>UnsafeCell</code>.</p><p>This struct provides the basic abstraction for interior mutability, however, you have to use <code>unsafe</code> to access.</p><p><code>Cell</code>, <code>RefCell</code> and all other types that allows internal mutability use <code>UnsafeCell</code> to wrap their data and provide <code>safe</code> apis.</p>          </div><h2 id="MutexGuard-lifetime">MutexGuard lifetime</h2><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">if</span> list.<span class="hljs-title function_ invoke__">lock</span>().<span class="hljs-title function_ invoke__">unwrap</span>().<span class="hljs-title function_ invoke__">pop</span>() == <span class="hljs-title function_ invoke__">Some</span>(<span class="hljs-number">1</span>) &#123; <span class="hljs-comment">// &lt;--- drop here</span>    <span class="hljs-title function_ invoke__">do_something</span>();&#125;<span class="hljs-comment">// PERF: needlessly hold on to the lock while processing the item.</span><span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-variable">Some</span>(item) = list.<span class="hljs-title function_ invoke__">lock</span>().<span class="hljs-title function_ invoke__">unwrap</span>().<span class="hljs-title function_ invoke__">pop</span>() &#123;    <span class="hljs-title function_ invoke__">process_item</span>(item);&#125; <span class="hljs-comment">// &lt;--- drop here</span><span class="hljs-comment">// FIXED:</span><span class="hljs-keyword">let</span> <span class="hljs-variable">item</span> = list.<span class="hljs-title function_ invoke__">lock</span>().<span class="hljs-title function_ invoke__">unwrap</span>().<span class="hljs-title function_ invoke__">pop</span>(); <span class="hljs-comment">// &lt;--- drop here</span><span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-variable">Some</span>(item) = item &#123;    <span class="hljs-title function_ invoke__">process_item</span>(item);&#125;</code></pre></div><p>Reason:</p><ul><li>The basic <code>if</code> statement is always a simple <code>boolean</code> expression.</li><li>If we replace <code>pop()</code> with <code>front()</code>, things’re clear. That’s how borrow checker works.</li></ul><h2 id="Parking">Parking</h2><p>Consider this situation: we only process items when the list is not empty.<br>If we use <code>Mutex</code>, then we have to keep calling <code>lock()</code> again and again, which is not efficient.</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::collections::VecDeque;<span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;    <span class="hljs-keyword">let</span> <span class="hljs-variable">queue</span> = Mutex::<span class="hljs-title function_ invoke__">new</span>(VecDeque::<span class="hljs-title function_ invoke__">new</span>());    thread::<span class="hljs-title function_ invoke__">scope</span>(|s| &#123;        <span class="hljs-comment">// Consuming thread</span>        <span class="hljs-keyword">let</span> <span class="hljs-variable">t</span> = s.<span class="hljs-title function_ invoke__">spawn</span>(|| <span class="hljs-keyword">loop</span> &#123;            <span class="hljs-keyword">let</span> <span class="hljs-variable">item</span> = queue.<span class="hljs-title function_ invoke__">lock</span>().<span class="hljs-title function_ invoke__">unwrap</span>().<span class="hljs-title function_ invoke__">pop_front</span>();            <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-variable">Some</span>(item) = item &#123;                dbg!(item);            &#125; <span class="hljs-keyword">else</span> &#123;                thread::<span class="hljs-title function_ invoke__">park</span>();            &#125;        &#125;);        <span class="hljs-comment">// Producing thread</span>        <span class="hljs-keyword">for</span> <span class="hljs-variable">i</span> <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>.. &#123;            queue.<span class="hljs-title function_ invoke__">lock</span>().<span class="hljs-title function_ invoke__">unwrap</span>().<span class="hljs-title function_ invoke__">push_back</span>(i);            t.<span class="hljs-title function_ invoke__">thread</span>().<span class="hljs-title function_ invoke__">unpark</span>();            thread::<span class="hljs-title function_ invoke__">sleep</span>(Duration::<span class="hljs-title function_ invoke__">from_secs</span>(<span class="hljs-number">1</span>));        &#125;    &#125;);&#125;</code></pre></div><div class="note note-primary">            <p>A call to <code>unpark()</code> before the thread parks itself <strong><em>does not get lost</em></strong></p><p>However, unpark requests <strong><em>don’t stack up</em></strong>.</p><p>Calling unpark() two times and then calling park() two times afterwards still results in the thread going to sleep.</p>          </div><h2 id="Cond-Vars">Cond Vars</h2><p>The example above is low-efficiency when we want to use more consumers.<br>Because the producer doesn’t know which consumer to wake up.</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;    <span class="hljs-keyword">use</span> std::sync::Condvar;    <span class="hljs-keyword">use</span> std::&#123;collections::VecDeque, sync::Mutex, thread, time::Duration&#125;;    <span class="hljs-keyword">let</span> <span class="hljs-variable">queue</span> = Mutex::<span class="hljs-title function_ invoke__">new</span>(VecDeque::<span class="hljs-title function_ invoke__">new</span>());    <span class="hljs-keyword">let</span> <span class="hljs-variable">not_empty</span> = Condvar::<span class="hljs-title function_ invoke__">new</span>();    <span class="hljs-keyword">let</span> <span class="hljs-variable">empty</span> = Condvar::<span class="hljs-title function_ invoke__">new</span>();    thread::<span class="hljs-title function_ invoke__">scope</span>(|s| &#123;        <span class="hljs-comment">// not_empty handler</span>        s.<span class="hljs-title function_ invoke__">spawn</span>(|| <span class="hljs-keyword">loop</span> &#123;            <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">q</span> = queue.<span class="hljs-title function_ invoke__">lock</span>().<span class="hljs-title function_ invoke__">unwrap</span>();            <span class="hljs-keyword">let</span> <span class="hljs-variable">item</span> = <span class="hljs-keyword">loop</span> &#123;                <span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-variable">Some</span>(item) = q.<span class="hljs-title function_ invoke__">pop_front</span>() &#123;                    <span class="hljs-keyword">break</span> item;                &#125; <span class="hljs-keyword">else</span> &#123;                    empty.<span class="hljs-title function_ invoke__">notify_one</span>(); <span class="hljs-comment">// wake up the empty handler(s)</span>                    q = not_empty.<span class="hljs-title function_ invoke__">wait</span>(q).<span class="hljs-title function_ invoke__">unwrap</span>();                &#125;            &#125;;            <span class="hljs-title function_ invoke__">drop</span>(q);            <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Got item: &#123;&#125;&quot;</span>, item);        &#125;);        <span class="hljs-comment">// empty handler</span>        s.<span class="hljs-title function_ invoke__">spawn</span>(|| <span class="hljs-keyword">loop</span> &#123;            <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">q</span> = queue.<span class="hljs-title function_ invoke__">lock</span>().<span class="hljs-title function_ invoke__">unwrap</span>();            <span class="hljs-keyword">loop</span> &#123;                <span class="hljs-keyword">if</span> q.<span class="hljs-title function_ invoke__">is_empty</span>() &#123;                    <span class="hljs-keyword">break</span>;                &#125; <span class="hljs-keyword">else</span> &#123;                    q = empty.<span class="hljs-title function_ invoke__">wait</span>(q).<span class="hljs-title function_ invoke__">unwrap</span>();                &#125;            &#125;            <span class="hljs-title function_ invoke__">drop</span>(q);            <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Queue is empty&quot;</span>);            thread::<span class="hljs-title function_ invoke__">sleep</span>(Duration::<span class="hljs-title function_ invoke__">from_millis</span>(<span class="hljs-number">400</span>));        &#125;);        <span class="hljs-comment">// producer</span>        <span class="hljs-keyword">for</span> <span class="hljs-variable">i</span> <span class="hljs-keyword">in</span> <span class="hljs-number">0</span>.. &#123;            queue.<span class="hljs-title function_ invoke__">lock</span>().<span class="hljs-title function_ invoke__">unwrap</span>().<span class="hljs-title function_ invoke__">push_back</span>(i);            not_empty.<span class="hljs-title function_ invoke__">notify_one</span>(); <span class="hljs-comment">// wake up the not_empty handler(s)</span>            thread::<span class="hljs-title function_ invoke__">sleep</span>(Duration::<span class="hljs-title function_ invoke__">from_secs</span>(<span class="hljs-number">1</span>));        &#125;    &#125;);&#125;</code></pre></div><h2 id="Memory-Ordering">Memory Ordering</h2><h3 id="Happens-Before">Happens-Before</h3><p>Before we dive into the specific memory orderings below, we must have a deep understanding of <code>happens-before</code> relationship.</p><p><code>happens-before</code> dose not mean that the first operation is literally executed before the second one. (If you want to achieve that, you should use <code>Mutex</code>, <code>CondVar</code>, <code>Chan</code> or other synchronization primitives to help threads communicate.)</p><p>There’re 2 points to remember:</p><ol><li><p><code>happens-before</code> is all about the ‘instruction reordering’ by the compiler or the CPU.</p></li><li><p><code>happens-before</code> itself doesn’t happen until <code>observable behavior</code> occurs.</p></li></ol><p>For example:</p><div class="code-wrapper"><pre><code class="hljs text">Thread A:                          Thread B:some ops (A) ----------...                   |a.store(1, Release);  | visible                      |                      |     if a.load(Acquire) == 1 &#123;                      -&gt; (B)    // do something                            &#125;</code></pre></div><p>There’s no <code>happens-before</code> relationship until Thread B sees the value <code>1</code> in <code>a.load(Acquire)</code>, and at that point, we can say that <code>(A)</code> happens before <code>(B)</code>, or <code>(A)</code> is visible to <code>(B)</code>.</p><h3 id="Relaxed">Relaxed</h3><p>While atomic operations using relaxed memory ordering do not provide any happens-before relationship,<br>they do guarantee a total modification order of each individual atomic variable.<br>This means that all modifications of the same atomic variable happen in an order that is the same from the perspective of every single thread.</p><p>Example:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">static</span> X: AtomicI32 = AtomicI32::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-number">0</span>);<span class="hljs-comment">// thread 1</span><span class="hljs-keyword">fn</span> <span class="hljs-title function_">a</span>() &#123;    X.<span class="hljs-title function_ invoke__">fetch_add</span>(<span class="hljs-number">5</span>, Relaxed);    X.<span class="hljs-title function_ invoke__">fetch_add</span>(<span class="hljs-number">10</span>, Relaxed);&#125;<span class="hljs-comment">// thread 2</span><span class="hljs-keyword">fn</span> <span class="hljs-title function_">b</span>() &#123;    <span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = X.<span class="hljs-title function_ invoke__">load</span>(Relaxed);    <span class="hljs-keyword">let</span> <span class="hljs-variable">b</span> = X.<span class="hljs-title function_ invoke__">load</span>(Relaxed);    <span class="hljs-keyword">let</span> <span class="hljs-variable">c</span> = X.<span class="hljs-title function_ invoke__">load</span>(Relaxed);    <span class="hljs-keyword">let</span> <span class="hljs-variable">d</span> = X.<span class="hljs-title function_ invoke__">load</span>(Relaxed);    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&#123;a&#125; &#123;b&#125; &#123;c&#125; &#123;d&#125;&quot;</span>);&#125;</code></pre></div><p>The output will never be <code>0 5 0 15</code> or <code>0 0 10 15</code> due to the order of the 2 <code>fetch_add</code> ops.</p><ul><li><code>0 5 0 15</code>: since we’ve written 5 and it has been read, the next read mustn’t be 0.</li><li><code>0 0 10 15</code>: write 5 happens before write 10.</li></ul><hr><h3 id="Release-Acquire">Release / Acquire</h3><p><code>Release</code> corresponds to the <code>store</code> operation, and <code>Acquire</code> corresponds to the <code>load</code> operation.</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::sync::atomic::Ordering::&#123;Acquire, Release&#125;;<span class="hljs-keyword">static</span> DATA: AtomicU64 = AtomicU64::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-number">0</span>);<span class="hljs-keyword">static</span> READY: AtomicBool = AtomicBool::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-literal">false</span>);<span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;    thread::<span class="hljs-title function_ invoke__">spawn</span>(|| &#123;        DATA.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-number">123</span>, Relaxed);        READY.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-literal">true</span>, Release); <span class="hljs-comment">// Everything from before this store ..</span>    &#125;);    <span class="hljs-keyword">while</span> !READY.<span class="hljs-title function_ invoke__">load</span>(Acquire) &#123; <span class="hljs-comment">// .. is visible after this loads `true`.</span>        thread::<span class="hljs-title function_ invoke__">sleep</span>(Duration::<span class="hljs-title function_ invoke__">from_millis</span>(<span class="hljs-number">100</span>));        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;waiting...&quot;</span>);    &#125;    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&#123;&#125;&quot;</span>, DATA.<span class="hljs-title function_ invoke__">load</span>(Relaxed));&#125;</code></pre></div><div class="note note-info">            <p>Note that if we use <code>Relaxed</code> instead of <code>Acquire</code> for <code>READY</code>, we might read <code>0</code> instead of <code>123</code>.<br>That’s because <code>Relaxed</code> only provides a total order for the <strong><em>same</em></strong> atomic variable, not across <strong><em>different</em></strong> variables.</p>          </div><p>Since <code>Release</code> and <code>Acquire</code> have a happens-before relationship, we can simply use <code>u64</code> instead of <code>AtomicU64</code>:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">static</span> <span class="hljs-keyword">mut</span> DATA: <span class="hljs-type">u64</span> = <span class="hljs-number">0</span>;<span class="hljs-keyword">static</span> READY: AtomicBool = AtomicBool::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-literal">false</span>);<span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;    thread::<span class="hljs-title function_ invoke__">spawn</span>(|| &#123;        <span class="hljs-comment">// Safety: Nothing else is accessing DATA,</span>        <span class="hljs-comment">// because we haven&#x27;t set the READY flag yet.</span>        <span class="hljs-keyword">unsafe</span> &#123; DATA = <span class="hljs-number">123</span> &#125;;        READY.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-literal">true</span>, Release); <span class="hljs-comment">// Everything from before this store ..</span>    &#125;);    <span class="hljs-keyword">while</span> !READY.<span class="hljs-title function_ invoke__">load</span>(Acquire) &#123;        <span class="hljs-comment">// .. is visible after this loads `true`.</span>        thread::<span class="hljs-title function_ invoke__">sleep</span>(Duration::<span class="hljs-title function_ invoke__">from_millis</span>(<span class="hljs-number">100</span>));        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;waiting...&quot;</span>);    &#125;    <span class="hljs-comment">// Safety: Nothing is mutating DATA, because READY is set.</span>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&#123;&#125;&quot;</span>, <span class="hljs-keyword">unsafe</span> &#123; DATA &#125;);&#125;</code></pre></div><hr><h3 id="SeqCst">SeqCst</h3><p>To be short, the order of excution is just like the order of the codes.<br>Here’s a example of the difference between <code>Acq/Rel</code> and <code>SeqCst</code>:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">static</span> A: AtomicUsize = AtomicUsize::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-number">0</span>);<span class="hljs-keyword">static</span> B: AtomicUsize = AtomicUsize::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-number">0</span>);<span class="hljs-keyword">fn</span> <span class="hljs-title function_">thread1</span>() &#123;    A.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-number">1</span>, SeqCst);    B.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-number">2</span>, SeqCst);&#125;<span class="hljs-keyword">fn</span> <span class="hljs-title function_">thread2</span>() &#123;    <span class="hljs-keyword">let</span> <span class="hljs-variable">b</span> = B.<span class="hljs-title function_ invoke__">load</span>(SeqCst);    <span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = A.<span class="hljs-title function_ invoke__">load</span>(SeqCst);    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;a = &#123;&#125;, b = &#123;&#125;&quot;</span>, a, b);&#125;</code></pre></div><blockquote><p>If b is <code>2</code> then a must be <code>1</code>.</p></blockquote><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">static</span> A: AtomicUsize = AtomicUsize::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-number">0</span>);<span class="hljs-keyword">static</span> B: AtomicUsize = AtomicUsize::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-number">0</span>);<span class="hljs-keyword">fn</span> <span class="hljs-title function_">thread1</span>() &#123;    A.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-number">1</span>, Release);    B.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-number">2</span>, Relaxed);&#125;<span class="hljs-keyword">fn</span> <span class="hljs-title function_">thread2</span>() &#123;    <span class="hljs-keyword">let</span> <span class="hljs-variable">b</span> = B.<span class="hljs-title function_ invoke__">load</span>(Relaxed);    <span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = A.<span class="hljs-title function_ invoke__">load</span>(Acquire);    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;a = &#123;&#125;, b = &#123;&#125;&quot;</span>, a, b);&#125;</code></pre></div><blockquote><p>If b is <code>2</code>, we can’t guarantee that a is <code>1</code>.</p></blockquote><hr><h3 id="Fence">Fence</h3><p>To be short, <code>fence</code> stops the compiler from reordering instructions following the fence with instructions preceding the fence.</p><p>We’ve already known that <code>Release</code> and <code>Acquire</code> have a happens-before relationship, and we can use <code>fence</code> to substitute them like this:</p><p><strong>before:</strong></p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">// Thread A</span>&#123;    DATA.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-number">42</span>, Relaxed);    READY.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-literal">true</span>, Release); <span class="hljs-comment">// What happens-before the `Release`...</span>&#125;<span class="hljs-comment">// Thread B</span><span class="hljs-keyword">if</span> READY.<span class="hljs-title function_ invoke__">load</span>(Acquire) &#123;            <span class="hljs-comment">// ... is visible after the `Acquire`.</span>    <span class="hljs-keyword">let</span> <span class="hljs-variable">value</span> = DATA.<span class="hljs-title function_ invoke__">load</span>(Relaxed); <span class="hljs-comment">// The observation has occured (READY false -&gt; true), so we can see the value must be 42.</span>    <span class="hljs-built_in">assert_eq!</span>(value, <span class="hljs-number">42</span>);&#125;</code></pre></div><p><strong>after:</strong></p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">// Thread A</span>&#123;    DATA.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-number">42</span>, Relaxed);    <span class="hljs-title function_ invoke__">fence</span>(Release);             <span class="hljs-comment">// fence before store</span>    READY.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-literal">true</span>, Relaxed); <span class="hljs-comment">// just Relaxed</span>&#125;<span class="hljs-comment">// Thread B</span><span class="hljs-keyword">if</span> READY.<span class="hljs-title function_ invoke__">load</span>(Relaxed) &#123; <span class="hljs-comment">// just Relaxed</span>    <span class="hljs-title function_ invoke__">fence</span>(Acquire);      <span class="hljs-comment">// fence after load</span>    <span class="hljs-keyword">let</span> <span class="hljs-variable">value</span> = DATA.<span class="hljs-title function_ invoke__">load</span>(Relaxed);    <span class="hljs-built_in">assert_eq!</span>(value, <span class="hljs-number">42</span>);&#125;</code></pre></div><ol><li><code>fence</code> after <code>load</code>:</li></ol><p>Let’s say, if we move the <code>fence</code> to the front of the <code>if</code> block, then the compiler <strong><em>might</em></strong> reorder the <code>load</code> before the <code>if</code> check:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-comment">// Thread B</span><span class="hljs-title function_ invoke__">fence</span>(Acquire);<span class="hljs-keyword">let</span> <span class="hljs-variable">value</span> = DATA.<span class="hljs-title function_ invoke__">load</span>(Relaxed); <span class="hljs-comment">// what value will be?</span><span class="hljs-keyword">if</span> READY.<span class="hljs-title function_ invoke__">load</span>(Relaxed) &#123;    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;DATA = &#123;&#125;&quot;</span>, value);&#125;</code></pre></div><p>So we’ll probably get <code>DATA = 0</code> instead of <code>DATA = 42</code>.</p><ol start="2"><li><code>fence</code> before <code>store</code></li></ol><div class="code-wrapper"><pre><code class="hljs rust">&#123;    DATA.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-number">42</span>, Relaxed);    <span class="hljs-title function_ invoke__">fence</span>(Release); <span class="hljs-comment">// make sure DATA is stored</span>    READY.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-literal">true</span>, Relaxed);&#125;</code></pre></div><p>Finally, check another example to make a deeper impression - use <code>fence</code> to get better performance:</p><div style="display: flex; flex-direction: row; justify-content: space-between;">  <div style="width: 49%;">    <div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">p</span> = PTR.<span class="hljs-title function_ invoke__">load</span>(Acquire);<span class="hljs-keyword">if</span> p.<span class="hljs-title function_ invoke__">is_null</span>() &#123;    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;no data&quot;</span>);&#125; <span class="hljs-keyword">else</span> &#123;    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;data = &#123;&#125;&quot;</span>, <span class="hljs-keyword">unsafe</span> &#123; *p &#125;);&#125;</code></pre></div>  </div>  <div style="width: 49%;">    <div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">p</span> = PTR.<span class="hljs-title function_ invoke__">load</span>(Relaxed);<span class="hljs-keyword">if</span> p.<span class="hljs-title function_ invoke__">is_null</span>() &#123;    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;no data&quot;</span>);&#125; <span class="hljs-keyword">else</span> &#123;    <span class="hljs-title function_ invoke__">fence</span>(Acquire);    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;data = &#123;&#125;&quot;</span>, <span class="hljs-keyword">unsafe</span> &#123; *p &#125;);&#125;</code></pre></div>  </div></div><div class="note note-info">            <ul><li><p>Why is the performance better?<br>Because the <code>fence</code> is only needed when <code>p</code> is not null, and load by <code>Relaxed</code> is lighter weight than <code>Acquire</code>.</p></li><li><p>How does it work?<br>Because <code>fence</code> stops <code>*p</code> from being reordered before the <code>if</code> check, and we can avoid the <code>Acquire</code> load when <code>p</code> is null.</p></li></ul>          </div><div class="note note-second">            <p>Any way, if you find it hard to understand, keeping these 2 rules in mind might help:</p><div class="code-wrapper"><pre><code class="hljs rust">a.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-number">1</span>, Release);<span class="hljs-comment">// equals to</span><span class="hljs-title function_ invoke__">fence</span>(Release);a.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-number">1</span>, Relaxed);</code></pre></div><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = b.<span class="hljs-title function_ invoke__">load</span>(Acquire);<span class="hljs-comment">// equals to</span><span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = b.<span class="hljs-title function_ invoke__">load</span>(Relaxed);<span class="hljs-title function_ invoke__">fence</span>(Acquire);</code></pre></div><p>If you simply do ‘Variable Replacement’, you’ll see that a <code>fence</code> isn’t actually dependent on another <code>fence</code>, it can also work with a <code>store</code> or a <code>load</code>.</p><p>i.e. A <code>fence(Acquire)</code> doesn’t have to work with a <code>fence(Release)</code>, we don’t have to use <code>fence</code> in pairs.</p><p>And that’s how the last example works.</p><p>PS: The ‘replacement’ doesn’t strictly requires you to do something like <code>:s/ori/new</code>. Of course you can add some lines between <code>fence</code> and <code>store</code> / <code>load</code>, as long as the codes you add don’t care about the mem order.</p>          </div><hr><h3 id="Misconceptions">Misconceptions</h3><ol><li><strong>I need strong memory ordering to make sure changes are immediately visible to other threads.</strong></li></ol><ul><li>In real life, memory ordering is about things like reordering instructions, which usually happen at nanosecond scale.<br>Stronger memory ordering does not make your data travel faster; it might even slow your program down.</li></ul><ol start="2"><li><strong>Disabling optimization means I don’t need to care about memory ordering.</strong></li></ol><ul><li>Processor optimizations still happen even if you disable compiler optimizations.</li></ul><ol start="3"><li><strong>Sequentially consistent memory ordering can be used for a “release-load” or an “acquire-store.”</strong></li></ol><ul><li>Release-store <strong><em>does not</em></strong> form any release-acquire relationship with a SeqCst-store.<br>If you need them to be part of a globally consistent order, <u>both operations will have to use SeqCst</u>.</li></ul><hr><h3 id="Summary">Summary</h3><table><thead><tr><th>type</th><th>guarantee</th></tr></thead><tbody><tr><td>Relaxed</td><td>Total modification order of a specific single atomic variable</td></tr><tr><td>Acq/Rel</td><td>Make sure changes before “Rel” are visible to “Acq”</td></tr><tr><td>SeqCst</td><td>Just like the order of the codes look like</td></tr><tr><td>Fence</td><td>Codes after the fence are not reordered with the codes before the fence</td></tr></tbody></table><div class="note note-light">            <p><strong>Aside: <code>compare_exchange</code> vs. <code>compare_exchange_weak</code></strong></p><p>To be short, <code>compare_exchange_weak</code> might return <code>Err</code> even if the comparison is successful.</p><p>This is because the low-level instructions of <code>_weak</code> is <code>LL/SC</code> (Load-Linked/Store-Conditional), which might fail due to cache contention.</p><p>Since we always need to use <code>while</code> loop to retry, <code>compare_exchange_weak</code> is <strong>more efficient</strong> on some specific platforms, such as <code>ARM</code>.</p>          </div><h2 id="Spin-Lock">Spin Lock</h2><blockquote><p>If a lock is only ever held for very brief moments and the threads locking it can run in parallel on <strong><u>different processor cores</u></strong>,<br>it might be better for the threads to repeatedly try to lock it without actually going to sleep.</p></blockquote><h3 id="Minimal-Impl">Minimal Impl</h3><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">impl</span> <span class="hljs-title class_">SpinLock</span> &#123;    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">const</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">new</span>() <span class="hljs-punctuation">-&gt;</span> <span class="hljs-keyword">Self</span> &#123;        <span class="hljs-keyword">Self</span> &#123; locked: AtomicBool::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-literal">false</span>) &#125;    &#125;    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">lock</span>(&amp;<span class="hljs-keyword">self</span>) &#123;        <span class="hljs-keyword">while</span> <span class="hljs-keyword">self</span>.locked.<span class="hljs-title function_ invoke__">swap</span>(<span class="hljs-literal">true</span>, Acquire) &#123;            std::hint::<span class="hljs-title function_ invoke__">spin_loop</span>();        &#125;    &#125;    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">unlock</span>(&amp;<span class="hljs-keyword">self</span>) &#123;        <span class="hljs-keyword">self</span>.locked.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-literal">false</span>, Release);    &#125;&#125;</code></pre></div><hr><h3 id="Hold-value">Hold value</h3><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">SpinLock</span>&lt;T&gt; &#123;    locked: AtomicBool,    value: UnsafeCell&lt;T&gt;,&#125;<span class="hljs-keyword">impl</span>&lt;T&gt; SpinLock&lt;T&gt; &#123;    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">new</span>(value: T) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-keyword">Self</span> &#123;        <span class="hljs-keyword">Self</span> &#123;            locked: AtomicBool::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-literal">false</span>),            value: UnsafeCell::<span class="hljs-title function_ invoke__">new</span>(value),        &#125;    &#125;    <span class="hljs-comment">// use this macro to suppress the clippy error</span>    <span class="hljs-meta">#[allow(clippy::mut_from_ref)]</span>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">lock</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> &amp;<span class="hljs-keyword">mut</span> T &#123;        <span class="hljs-keyword">while</span> <span class="hljs-keyword">self</span>.locked.<span class="hljs-title function_ invoke__">swap</span>(<span class="hljs-literal">true</span>, Acquire) &#123;            std::hint::<span class="hljs-title function_ invoke__">spin_loop</span>();        &#125;        <span class="hljs-keyword">unsafe</span> &#123; &amp;<span class="hljs-keyword">mut</span> *<span class="hljs-keyword">self</span>.value.<span class="hljs-title function_ invoke__">get</span>() &#125;    &#125;    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">unlock</span>(&amp;<span class="hljs-keyword">self</span>) &#123;        <span class="hljs-keyword">self</span>.locked.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-literal">false</span>, Release);    &#125;&#125;</code></pre></div><hr><h3 id="Use-Guard-to-auto-unlock">Use Guard to auto unlock</h3><blockquote><p>Ignore the <code>Swift</code> syntax, <code>highlightjs</code> doesn’t handle the rust lifetime specifier properly.</p></blockquote><div class="code-wrapper"><pre><code class="hljs swift">pub <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Guard</span>&lt;&#x27;a, <span class="hljs-type">T</span>&gt; &#123;    lock: <span class="hljs-operator">&amp;</span>&#x27;a <span class="hljs-type">SpinLock</span>&lt;<span class="hljs-type">T</span>&gt;,&#125;impl<span class="hljs-operator">&lt;</span><span class="hljs-type">T</span><span class="hljs-operator">&gt;</span> <span class="hljs-type">Deref</span> <span class="hljs-keyword">for</span> <span class="hljs-type">Guard</span>&lt;&#x27;<span class="hljs-keyword">_</span>, <span class="hljs-type">T</span>&gt; &#123;    type <span class="hljs-type">Target</span> <span class="hljs-operator">=</span> <span class="hljs-type">T</span>;    fn deref(<span class="hljs-operator">&amp;</span><span class="hljs-keyword">self</span>) -&gt; <span class="hljs-operator">&amp;</span><span class="hljs-keyword">Self</span>::<span class="hljs-type">Target</span> &#123;        unsafe &#123; <span class="hljs-operator">&amp;*</span><span class="hljs-keyword">self</span>.lock.value &#125;    &#125;&#125;impl<span class="hljs-operator">&lt;</span><span class="hljs-type">T</span><span class="hljs-operator">&gt;</span> <span class="hljs-type">DerefMut</span> <span class="hljs-keyword">for</span> <span class="hljs-type">Guard</span>&lt;&#x27;<span class="hljs-keyword">_</span>, <span class="hljs-type">T</span>&gt; &#123;    fn deref_mut(<span class="hljs-operator">&amp;</span>mut <span class="hljs-keyword">self</span>) -&gt; <span class="hljs-operator">&amp;</span>mut <span class="hljs-keyword">Self</span>::<span class="hljs-type">Target</span> &#123;        unsafe &#123; <span class="hljs-operator">&amp;</span>mut <span class="hljs-operator">*</span><span class="hljs-keyword">self</span>.lock.value &#125;    &#125;&#125;impl<span class="hljs-operator">&lt;</span><span class="hljs-type">T</span><span class="hljs-operator">&gt;</span> <span class="hljs-type">Drop</span> <span class="hljs-keyword">for</span> <span class="hljs-type">Guard</span>&lt;&#x27;<span class="hljs-keyword">_</span>, <span class="hljs-type">T</span>&gt; &#123;    fn drop(<span class="hljs-operator">&amp;</span>mut <span class="hljs-keyword">self</span>) &#123;        <span class="hljs-keyword">self</span>.lock.unlock();    &#125;&#125;</code></pre></div><p>Now let’s change the <code>lock</code> method to return a <code>Guard</code>:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">impl</span>&lt;T&gt; SpinLock&lt;T&gt; &#123;    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">lock</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> Guard&lt;T&gt; &#123;        <span class="hljs-keyword">while</span> <span class="hljs-keyword">self</span>.locked.<span class="hljs-title function_ invoke__">swap</span>(<span class="hljs-literal">true</span>, Acquire) &#123;            std::hint::<span class="hljs-title function_ invoke__">spin_loop</span>();        &#125;        Guard &#123; lock: <span class="hljs-keyword">self</span> &#125;    &#125;&#125;</code></pre></div><hr><h3 id="Fence-it">Fence it!</h3><p>Remember we’ve talked about using <code>fence</code> to substitute <code>load</code> or <code>store</code> in the <a href="#Fence">previous section</a>? There happens to be an example of building a <code>SpinLock</code> with <code>fence</code> in the rust doc of <code>fence</code> itself:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Mutex</span> &#123;    flag: AtomicBool,&#125;<span class="hljs-keyword">impl</span> <span class="hljs-title class_">Mutex</span> &#123;    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">new</span>() <span class="hljs-punctuation">-&gt;</span> Mutex &#123;        Mutex &#123;            flag: AtomicBool::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-literal">false</span>),        &#125;    &#125;    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">lock</span>(&amp;<span class="hljs-keyword">self</span>) &#123;        <span class="hljs-comment">// Wait until the old value is `false`.</span>        <span class="hljs-keyword">while</span> <span class="hljs-keyword">self</span>            .flag            .<span class="hljs-title function_ invoke__">compare_exchange_weak</span>(<span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>, Ordering::Relaxed, Ordering::Relaxed)            .<span class="hljs-title function_ invoke__">is_err</span>()        &#123;&#125;        <span class="hljs-comment">// This fence synchronizes-with store in `unlock`.</span>        <span class="hljs-title function_ invoke__">fence</span>(Ordering::Acquire);    &#125;    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">unlock</span>(&amp;<span class="hljs-keyword">self</span>) &#123;        <span class="hljs-keyword">self</span>.flag.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-literal">false</span>, Ordering::Release);    &#125;&#125;</code></pre></div><p>A little bit confused of the single <code>fence</code>? Let’s break it down:</p><p>First, to see things clearly, we can cast the <code>while</code> loop to a <code>loop</code>:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">lock</span>(&amp;<span class="hljs-keyword">self</span>) &#123;    <span class="hljs-comment">// Wait until the old value is `false`.</span>    <span class="hljs-keyword">loop</span> &#123;        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>            .flag            .<span class="hljs-title function_ invoke__">compare_exchange_weak</span>(<span class="hljs-literal">false</span>, <span class="hljs-literal">true</span>, Ordering::Relaxed, Ordering::Relaxed)            .<span class="hljs-title function_ invoke__">is_ok</span>()        &#123;            <span class="hljs-keyword">break</span>;        &#125;    &#125;    <span class="hljs-comment">// This fence synchronizes-with store in `unlock`.</span>    <span class="hljs-title function_ invoke__">fence</span>(Ordering::Acquire);&#125;</code></pre></div><p>Then, we replace <code>compare_exchange_weak</code> with <code>load</code> and <code>store</code>, note that this is <span class="label label-danger">impossible</span> in real code because split <code>cas</code> into individual <code>load</code> and <code>store</code> will break the atomicity:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">lock</span>(&amp;<span class="hljs-keyword">self</span>) &#123;    <span class="hljs-comment">// Wait until the old value is `false`.</span>    <span class="hljs-keyword">loop</span> &#123;        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.flag.<span class="hljs-title function_ invoke__">load</span>(Ordering::Relaxed) == <span class="hljs-literal">false</span> &#123;            <span class="hljs-keyword">self</span>.flag.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-literal">true</span>, Ordering::Relaxed);            <span class="hljs-keyword">break</span>;        &#125;    &#125;    <span class="hljs-comment">// This fence synchronizes-with store in `unlock`.</span>    <span class="hljs-title function_ invoke__">fence</span>(Ordering::Acquire);&#125;</code></pre></div><p>Do a little bit adjustment:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">lock</span>(&amp;<span class="hljs-keyword">self</span>) &#123;    <span class="hljs-comment">// Wait until the old value is `false`.</span>    <span class="hljs-keyword">loop</span> &#123;        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.flag.<span class="hljs-title function_ invoke__">load</span>(Ordering::Relaxed) == <span class="hljs-literal">false</span> &#123;            <span class="hljs-title function_ invoke__">fence</span>(Ordering::Acquire);            <span class="hljs-keyword">self</span>.flag.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-literal">true</span>, Ordering::Relaxed);            <span class="hljs-keyword">break</span>;        &#125;    &#125;&#125;</code></pre></div><p>Now we can see that <code>fence</code> after <code>load</code> pattern! It’s equivalent to:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">lock</span>(&amp;<span class="hljs-keyword">self</span>) &#123;    <span class="hljs-comment">// Wait until the old value is `false`.</span>    <span class="hljs-keyword">loop</span> &#123;        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.flag.<span class="hljs-title function_ invoke__">load</span>(Ordering::Acquire) == <span class="hljs-literal">false</span> &#123;            <span class="hljs-keyword">self</span>.flag.<span class="hljs-title function_ invoke__">store</span>(<span class="hljs-literal">true</span>, Ordering::Relaxed);            <span class="hljs-keyword">break</span>;        &#125;    &#125;&#125;</code></pre></div><p>And that’s exactly how does the <code>fence</code> synchronizes-with the <code>store</code> in <code>unlock</code>.</p><p>It’s a little bit verbose, but it’s a good way to understand how <code>fence</code> works.</p><h2 id="Chan">Chan</h2><blockquote><p>Ignore the <code>Swift</code> syntax, <code>highlightjs</code> doesn’t handle the rust lifetime specifier properly.</p></blockquote><div class="code-wrapper"><pre><code class="hljs swift">pub <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Channel</span>&lt;<span class="hljs-type">T</span>&gt; &#123;    message: <span class="hljs-type">UnsafeCell</span>&lt;<span class="hljs-type">MaybeUninit</span>&lt;<span class="hljs-type">T</span>&gt;&gt;,    ready: <span class="hljs-type">AtomicBool</span>,&#125;unsafe impl<span class="hljs-operator">&lt;</span><span class="hljs-type">T</span><span class="hljs-operator">&gt;</span> <span class="hljs-type">Sync</span> <span class="hljs-keyword">for</span> <span class="hljs-type">Channel</span>&lt;<span class="hljs-type">T</span>&gt; <span class="hljs-keyword">where</span> <span class="hljs-type">T</span>: <span class="hljs-type">Send</span> &#123;&#125;pub <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Sender</span>&lt;&#x27;a, <span class="hljs-type">T</span>&gt; &#123;    channel: <span class="hljs-operator">&amp;</span>&#x27;a <span class="hljs-type">Channel</span>&lt;<span class="hljs-type">T</span>&gt;,    recv_thread: <span class="hljs-type">Thread</span>,&#125;pub <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Receiver</span>&lt;&#x27;a, <span class="hljs-type">T</span>&gt; &#123;    channel: <span class="hljs-operator">&amp;</span>&#x27;a <span class="hljs-type">Channel</span>&lt;<span class="hljs-type">T</span>&gt;,    _marker: std::marker::<span class="hljs-type">PhantomData</span>&lt;&amp;&#x27;a <span class="hljs-type">T</span>&gt;,&#125;impl<span class="hljs-operator">&lt;</span><span class="hljs-type">T</span><span class="hljs-operator">&gt;</span> <span class="hljs-type">Channel</span>&lt;<span class="hljs-type">T</span>&gt; &#123;    pub const fn new() -&gt; <span class="hljs-keyword">Self</span> &#123;        <span class="hljs-keyword">Self</span> &#123;            message: <span class="hljs-type">UnsafeCell</span>::new(MaybeUninit::uninit()),            ready: <span class="hljs-type">AtomicBool</span>::new(<span class="hljs-literal">false</span>),        &#125;    &#125;    pub fn split(<span class="hljs-operator">&amp;</span>mut <span class="hljs-keyword">self</span>) -&gt; (<span class="hljs-type">Sender</span>&lt;<span class="hljs-type">T</span>&gt;, <span class="hljs-type">Receiver</span>&lt;<span class="hljs-type">T</span>&gt;) &#123;        <span class="hljs-operator">*</span><span class="hljs-keyword">self</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">Self</span>::new();        (            <span class="hljs-type">Sender</span> &#123;                channel: <span class="hljs-keyword">self</span>,                recv_thread: thread::current(),            &#125;,            <span class="hljs-type">Receiver</span> &#123;                channel: <span class="hljs-keyword">self</span>,                _marker: std::marker::<span class="hljs-type">PhantomData</span>,            &#125;,        )    &#125;&#125;impl<span class="hljs-operator">&lt;</span><span class="hljs-type">T</span><span class="hljs-operator">&gt;</span> <span class="hljs-type">Sender</span>&lt;&#x27;<span class="hljs-keyword">_</span>, <span class="hljs-type">T</span>&gt; &#123;    pub fn send(<span class="hljs-keyword">self</span>, message: <span class="hljs-type">T</span>) &#123;        unsafe &#123; (<span class="hljs-operator">*</span><span class="hljs-keyword">self</span>.channel.message.get()).write(message) &#125;;        <span class="hljs-keyword">self</span>.channel.ready.store(<span class="hljs-literal">true</span>, <span class="hljs-type">Release</span>);        <span class="hljs-keyword">self</span>.recv_thread.unpark();    &#125;&#125;impl<span class="hljs-operator">&lt;</span><span class="hljs-type">T</span><span class="hljs-operator">&gt;</span> <span class="hljs-type">Receiver</span>&lt;&#x27;<span class="hljs-keyword">_</span>, <span class="hljs-type">T</span>&gt; &#123;    pub fn is_ready(<span class="hljs-operator">&amp;</span><span class="hljs-keyword">self</span>) -&gt; bool &#123;        <span class="hljs-keyword">self</span>.channel.ready.load(<span class="hljs-type">Relaxed</span>)    &#125;    pub fn receive(<span class="hljs-keyword">self</span>) -&gt; <span class="hljs-type">T</span> &#123;        <span class="hljs-keyword">while</span> <span class="hljs-operator">!</span><span class="hljs-keyword">self</span>.channel.ready.swap(<span class="hljs-literal">false</span>, <span class="hljs-type">Acquire</span>) &#123;            thread::park();        &#125;        unsafe &#123; (<span class="hljs-operator">*</span><span class="hljs-keyword">self</span>.channel.message.get()).assume_init_read() &#125;    &#125;&#125;impl<span class="hljs-operator">&lt;</span><span class="hljs-type">T</span><span class="hljs-operator">&gt;</span> <span class="hljs-type">Drop</span> <span class="hljs-keyword">for</span> <span class="hljs-type">Channel</span>&lt;<span class="hljs-type">T</span>&gt; &#123;    fn drop(<span class="hljs-operator">&amp;</span>mut <span class="hljs-keyword">self</span>) &#123;        <span class="hljs-keyword">if</span> <span class="hljs-operator">*</span><span class="hljs-keyword">self</span>.ready.get_mut() &#123;            unsafe &#123; <span class="hljs-keyword">self</span>.message.get_mut().assume_init_drop() &#125;        &#125;    &#125;&#125;</code></pre></div><p>Pay attention to these points:</p><ol><li>Use <code>MaybeUninit</code> to save memory.</li><li>Abstract <code>Sender</code> and <code>Receiver</code> to limit the user’s access to the channel.(Think about the <code>MutexGuard</code> in <code>Mutex</code>)</li><li>Use thread handle to park / unpark the receiver thread.</li><li>Do not forget to drop the <code>MaybeUninit</code> due to the struct won’t drop the inner data automatically.</li></ol><h2 id="Arc">Arc</h2><h3 id="Minimal-Impl-2">Minimal Impl</h3><ul><li><p>snippet 1:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">ArcData</span>&lt;T&gt; &#123;    ref_cnt: AtomicUsize,    data: T,&#125;<span class="hljs-keyword">pub</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Arc</span>&lt;T&gt; &#123;    data: NonNull&lt;ArcData&lt;T&gt;&gt;,&#125;<span class="hljs-keyword">unsafe</span> <span class="hljs-keyword">impl</span>&lt;T: <span class="hljs-built_in">Send</span> + <span class="hljs-built_in">Sync</span>&gt; <span class="hljs-built_in">Send</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">Arc</span>&lt;T&gt; &#123;&#125;<span class="hljs-keyword">unsafe</span> <span class="hljs-keyword">impl</span>&lt;T: <span class="hljs-built_in">Send</span> + <span class="hljs-built_in">Sync</span>&gt; <span class="hljs-built_in">Sync</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">Arc</span>&lt;T&gt; &#123;&#125;</code></pre></div><ul><li><code>NonNull</code> is almost same as <code>*mut T</code> but non-null and [covariant]</li><li><code>Arc&lt;T&gt;</code> should be shared between threads, so <code>T</code> should be <code>Sync</code>.</li><li><code>Arc&lt;T&gt;</code> could be dropped by other threads, so <code>T</code> should be <code>Send</code>.</li></ul></li><li><p>snippet 2:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">impl</span>&lt;T&gt; Arc&lt;T&gt; &#123;    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">new</span>(data: T) <span class="hljs-punctuation">-&gt;</span> Arc&lt;T&gt; &#123;        Arc &#123;            ptr: NonNull::<span class="hljs-title function_ invoke__">from</span>(<span class="hljs-type">Box</span>::<span class="hljs-title function_ invoke__">leak</span>(<span class="hljs-type">Box</span>::<span class="hljs-title function_ invoke__">new</span>(ArcData &#123;                ref_count: AtomicUsize::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-number">1</span>),                data,            &#125;))),        &#125;    &#125;    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">data</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> &amp;ArcData&lt;T&gt; &#123;        <span class="hljs-keyword">unsafe</span> &#123; <span class="hljs-keyword">self</span>.ptr.<span class="hljs-title function_ invoke__">as_ref</span>() &#125;    &#125;&#125;<span class="hljs-keyword">impl</span>&lt;T&gt; Deref <span class="hljs-keyword">for</span> <span class="hljs-title class_">Arc</span>&lt;T&gt; &#123;    <span class="hljs-keyword">type</span> <span class="hljs-title class_">Target</span> = T;    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">deref</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> &amp;T &#123;        &amp;<span class="hljs-keyword">self</span>.<span class="hljs-title function_ invoke__">data</span>().data    &#125;&#125;</code></pre></div><ul><li>Use <code>Box::leak</code> to give up the exclusive ownership of a <code>Box</code> allocation.</li></ul></li><li><p>snippet 3:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">impl</span>&lt;T&gt; <span class="hljs-built_in">Clone</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">Arc</span>&lt;T&gt; &#123;    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">clone</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-keyword">Self</span> &#123;        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.<span class="hljs-title function_ invoke__">data</span>().ref_count.<span class="hljs-title function_ invoke__">fetch_add</span>(<span class="hljs-number">1</span>, Relaxed) &gt; <span class="hljs-type">usize</span>::MAX / <span class="hljs-number">2</span> &#123;            std::process::<span class="hljs-title function_ invoke__">abort</span>();        &#125;        Arc &#123; ptr: <span class="hljs-keyword">self</span>.ptr &#125;    &#125;&#125;<span class="hljs-keyword">impl</span>&lt;T&gt; <span class="hljs-built_in">Drop</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">Arc</span>&lt;T&gt; &#123;    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">drop</span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) &#123;        <span class="hljs-keyword">if</span> <span class="hljs-keyword">self</span>.<span class="hljs-title function_ invoke__">data</span>().ref_count.<span class="hljs-title function_ invoke__">fetch_sub</span>(<span class="hljs-number">1</span>, Release) == <span class="hljs-number">1</span> &#123;            <span class="hljs-title function_ invoke__">fence</span>(Acquire);            <span class="hljs-keyword">unsafe</span> &#123;                <span class="hljs-title function_ invoke__">drop</span>(<span class="hljs-type">Box</span>::<span class="hljs-title function_ invoke__">from_raw</span>(<span class="hljs-keyword">self</span>.ptr.<span class="hljs-title function_ invoke__">as_ptr</span>()));            &#125;        &#125;    &#125;&#125;</code></pre></div><ul><li><code>fetch_add</code> and <code>fetch_sub</code> are used to increment and decrement the reference count.</li><li><code>fetch_add</code> is <code>Relaxed</code> because we don’t need to guarantee the order of the reference count, but pay attention to the next line.</li><li><code>fetch_sub</code> is <code>Release</code> and then <code>fence(Acquire)</code> to make sure no one is still accessing the data when we drop it.<br>We need to guarantee that <strong>all the previous</strong> <code>fetch_sub</code> <strong><u>happens before</u></strong> the <strong>final</strong> <code>fetch_sub</code>.<br>In hence, we can use <code>AcqRel</code> for that, however, only the final decrement needs <code>Acquire</code>, so we use <code>Release</code> + <code>fence(Acquire)</code> for efficiency.</li></ul></li></ul><hr><h3 id="Self-Reference">Self-Reference</h3><p>Futher more, if we want to handle ‘self-reference’ struct with <code>Arc</code>, it might cause memory leak, because the <code>Arc</code> will only be dropped when the reference count is zero while self-reference struct will never be zero:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::sync::&#123;Arc, Mutex&#125;;<span class="hljs-meta">#[derive(Debug)]</span><span class="hljs-keyword">struct</span> <span class="hljs-title class_">MyStruct</span> &#123;    value: <span class="hljs-type">String</span>,    self_ref: <span class="hljs-type">Option</span>&lt;Arc&lt;Mutex&lt;MyStruct&gt;&gt;&gt;,&#125;<span class="hljs-keyword">impl</span> <span class="hljs-title class_">MyStruct</span> &#123;    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">new</span>(value: <span class="hljs-type">String</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-keyword">Self</span> &#123;        MyStruct &#123;            value,            self_ref: <span class="hljs-literal">None</span>,        &#125;    &#125;    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">set_reference</span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, other: Arc&lt;Mutex&lt;MyStruct&gt;&gt;) &#123;        <span class="hljs-keyword">self</span>.self_ref = <span class="hljs-title function_ invoke__">Some</span>(other);    &#125;&#125;<span class="hljs-keyword">impl</span> <span class="hljs-title class_">Drop</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">MyStruct</span> &#123;    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">drop</span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) &#123;        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;MyStruct is dropped&quot;</span>);    &#125;&#125;<span class="hljs-keyword">struct</span> <span class="hljs-title class_">DetectDrop</span> &#123;&#125;<span class="hljs-keyword">impl</span> <span class="hljs-title class_">Drop</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">DetectDrop</span> &#123;    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">drop</span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) &#123;        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;DetectDrop is dropped&quot;</span>);    &#125;&#125;<span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;    <span class="hljs-keyword">let</span> <span class="hljs-variable">a</span> = Arc::<span class="hljs-title function_ invoke__">new</span>(Mutex::<span class="hljs-title function_ invoke__">new</span>(MyStruct::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-string">&quot;Hello&quot;</span>.<span class="hljs-title function_ invoke__">to_string</span>())));    <span class="hljs-keyword">let</span> <span class="hljs-variable">_b</span> = Arc::<span class="hljs-title function_ invoke__">new</span>(DetectDrop &#123;&#125;);    &#123;        <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">a_ref</span> = a.<span class="hljs-title function_ invoke__">lock</span>().<span class="hljs-title function_ invoke__">unwrap</span>();        a_ref.<span class="hljs-title function_ invoke__">set_reference</span>(a.<span class="hljs-title function_ invoke__">clone</span>());    &#125;    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Arc count: &#123;&#125;&quot;</span>, Arc::<span class="hljs-title function_ invoke__">strong_count</span>(&amp;a));&#125;<span class="hljs-comment">// OUTPUT:</span><span class="hljs-comment">// Arc count: 2</span><span class="hljs-comment">// DetectDrop is dropped</span></code></pre></div><p>So, here comes the <code>Weak</code>.</p><hr><h3 id="Weak">Weak</h3><p><code>Weak</code> is a non-owning reference to the managed allocation, which means it won’t increase the reference count.</p><p>To achieve that, we can simply split the <code>Arc</code> into <code>Weak</code> and <code>Arc</code>:</p><div class="code-wrapper"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Arc</span>&lt;T&gt; &#123;    ptr: NonNull&lt;ArcData&lt;T&gt;&gt;,&#125;<span class="hljs-keyword">unsafe</span> <span class="hljs-keyword">impl</span>&lt;T: <span class="hljs-built_in">Sync</span> + <span class="hljs-built_in">Send</span>&gt; <span class="hljs-built_in">Send</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">Arc</span>&lt;T&gt; &#123;&#125;<span class="hljs-keyword">unsafe</span> <span class="hljs-keyword">impl</span>&lt;T: <span class="hljs-built_in">Sync</span> + <span class="hljs-built_in">Send</span>&gt; <span class="hljs-built_in">Sync</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">Arc</span>&lt;T&gt; &#123;&#125;<span class="hljs-keyword">pub</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">Weak</span>&lt;T&gt; &#123;    ptr: NonNull&lt;ArcData&lt;T&gt;&gt;,&#125;<span class="hljs-keyword">unsafe</span> <span class="hljs-keyword">impl</span>&lt;T: <span class="hljs-built_in">Sync</span> + <span class="hljs-built_in">Send</span>&gt; <span class="hljs-built_in">Send</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">Weak</span>&lt;T&gt; &#123;&#125;<span class="hljs-keyword">unsafe</span> <span class="hljs-keyword">impl</span>&lt;T: <span class="hljs-built_in">Sync</span> + <span class="hljs-built_in">Send</span>&gt; <span class="hljs-built_in">Sync</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">Weak</span>&lt;T&gt; &#123;&#125;<span class="hljs-keyword">struct</span> <span class="hljs-title class_">ArcData</span>&lt;T&gt; &#123;    <span class="hljs-comment">/// Number of `Arc`s.</span>    data_ref_count: AtomicUsize,    <span class="hljs-comment">/// Number of `Weak`s, plus one if there are any `Arc`s.</span>    alloc_ref_count: AtomicUsize,    <span class="hljs-comment">/// The data. Dropped if there are only weak pointers left.</span>    data: UnsafeCell&lt;ManuallyDrop&lt;T&gt;&gt;,&#125;</code></pre></div>]]></content>
    
    
    <categories>
      
      <category>tech</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rust</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>「甜点」：复式记账法</title>
    <link href="/dessert/double_entry_bookkeeping/"/>
    <url>/dessert/double_entry_bookkeeping/</url>
    
    <content type="html"><![CDATA[<blockquote><p>「甜点」：只看一件事的一个点，告别 TL;DR，拥抱 RTFM。</p></blockquote><h2 id="核心点">核心点</h2><ul><li>有借必有贷，借贷必相等</li><li>借 = debit，贷 = credit</li></ul><p>核心点不难理解，就是字面意思。只是注意不要陷入中文的语言陷阱中 —— 有人觉得&quot;找银行借钱和找银行贷款&quot;是同一个意思，于是就会搞混 debit 和 credit 的概念。</p><p>你只需要记住&quot;贷 credit&quot;才是需要偿还的即可（类比你的房贷）。如果你希望让&quot;借&quot;的理解更合理，你可以理解为是你把钱借给了银行，因为钱是你的，而你放在银行那存着。</p><h2 id="记账过程">记账过程</h2><p>假设我使用某支付平台通过我的银行卡支付了 5 元购买了一瓶饮料，我的钱最终应该从我的账户流向商家的账户，理论上来说一个完备的记账流程大致如下：</p><table><thead><tr><th>事件</th><th>D 应收待清算</th><th>C 网关过渡户</th><th>C 商户待结算</th><th>D 应收应清算</th><th>D 备付金头寸</th><th>C 商户余额户</th></tr></thead><tbody><tr><td>渠道扣款成功</td><td>D + 5</td><td>C + 5</td><td></td><td></td><td></td><td></td></tr><tr><td>支付成功</td><td></td><td>D - 5</td><td>C + 5</td><td></td><td></td><td></td></tr><tr><td>网联清分完成(完成明细对账)</td><td>C - 5</td><td></td><td></td><td>D + 5</td><td></td><td></td></tr><tr><td>资金到账(完成资金对账)</td><td></td><td></td><td></td><td>C - 5</td><td>D + 5</td><td></td></tr><tr><td>结算完成</td><td></td><td></td><td>D - 5</td><td></td><td></td><td>C + 5</td></tr></tbody></table><p>我们先不管上述复杂的流程，按照下面的步骤从易到难逐步理解。</p><hr><h3 id="一、事件">一、事件</h3><p>事件的类型已经在上面标注出来了，你可以理解为这是行业内的通用实践，也可以理解为这是基于安全考量所必备的一些步骤。</p><p>比如，理论上来说，平台给商家打款，也可以不关心外部的网联的对账：</p><details><summary><i>TL;DR 点击展开</i></summary><blockquote>假设我是「XX 支付」，用户的钱在我的系统里本质上只是一个数字，在不涉及出入金的情况下，我完全可以随意修改这个数字。<br>平台的零钱 / 余额只能在平台内流通，直到你点击「提现到银行卡」，这笔钱我才真正需要和银行结算。<br>因此用户付费购买商品这个流程，我可以直接把 user.balance - 5, merchant.balance + 5，然后告诉商家「你的钱到账了」。<br>我们之所以需要消费上述的具体事件来推进流程，是因为这笔钱的来源并不是平台内的用户零钱，而是用户的银行卡，也就是说用户选择了「使用银行卡支付」。<br>所以如果我主动跳过其中的核心检查步骤，直接给商户加钱，那么万一用户的银行卡扣款失败，那我作为平台就损失了 5 元。</blockquote></details><hr><h3 id="二、C-D-的特征">二、C / D 的特征</h3><p>复习一下：C = credit 贷记，D = debit 借记。</p><p>我们不难发现上述表中有如下特征：</p><ul><li><p>每一列的 C 和 D 的和都是 0（除了最后两列）</p><details><summary><i>解释</i></summary><blockquote><u>每一列代表的都是某个独立账户的变动</u>，那么显然，除了最终的商户余额户和备付金头寸，其他账户的变动都是功能性的、短暂的。<br>换句话来说，钱只是经过这些账户流入了商户的钱包，这些账户在不收取手续费的情况下，不应该从中拿取或者给予任何金额。<br>为什么后两列不符合特征呢？因为商户通过卖饮料赚到了 5 元。</blockquote></details></li><li><p>每一行的 C 和 D 的和都是 0（除了第一行）</p><details><summary><i>解释</i></summary><blockquote><u>每一行代表的都是一个事件产生的账户变动</u>，这个变动显然是双向的，要符合借贷必相等的原则。<br>为什么第一行不符合特征呢？因为商户本质是要收钱的，这个钱本身就是由外部用户的银行卡流入我们平台再结算给商户的。<br>换句话来说，我向第一个杯子里倒了水，此时第一个杯子里的水就独立的增加了，后续向第二第三个杯子里转移水的时候，前一个杯子里的水会减少，后一个杯子里的水会增加。</blockquote></details></li><li><p>符号与账户类型对应</p><details><summary><i>解释</i></summary><blockquote><u>账户本身的CD代表了账户的基本属性——表达资产还是负债</u>。<br>那么对应的，如果我是一个负债账户C，此时我又额外背上了一笔贷款，显然我在这个账户上应该使用加法，而不是减法。<br>同样，如果我还清了一笔债务D，那么我应该使用减法，而不是加法。<br></blockquote></details></li></ul><hr><h3 id="三、账户的功能">三、账户的功能</h3><p>现在我们可以尝试理解，为什么我们会定义这么多账户了，每个账户又有什么功能。<br>主要考虑以下两个方面：</p><h4 id="账户的属性-——-资产还是负债">账户的属性 —— 资产还是负债?</h4><p>这一步比较复杂，说起来也比较抽象，更像是一个逻辑题 / 文字游戏。我个人认为，单个账户本身的属性是什么都不重要，重要的是账户之间的关系。</p><p>比如，我用 0 / 1 来标注账户属性显然是完全可以的，关键点在于当前账户的对手账户必须是我的属性的对立面。</p><p>例如，商户的余额账户，显然和平台的备付金账户是对立的，因为商户的余额账户是平台的负债，而备付金账户是平台的资产。那么如果我用 1 标注了其中一者，那么另一个账户就必须用 0 标注。</p><p>然后我们在&quot;符合逻辑&quot;的基础上，可以根据实际情况来定义账户的属性。比如前面说了，商户的余额账户，显然是平台的负债，我们就给它赋予 C 的属性，然后给备付金账户赋予 D 的属性。</p><hr><h4 id="账户的功能-——-用途是什么">账户的功能 —— 用途是什么?</h4><p>如果我们直接去探究某一个具体账户的功能，可能会感觉有些头疼。因此我们需要转换一下思路：<br>当我们站在技术的视角上审视这个问题，可能会更简单一些。作为平台，我们显然需要对安全性和健壮性负责，避免出现任何资金的误差导致资金的亏损和信誉的下降。</p><p>因此，我们可能会首先归纳出，外部事件的种类和功能，然后选取必要的事件进行消费，同时构建其状态机 —— 形成一个事件驱动的模型。<br>那么每个账户的功能就是在这个状态机中的一个节点，我们需要在这个节点上完成一些操作，然后将状态转移到下一个节点。</p><p>举例来说，上述记账过程中，最抽象的账户是「C 网关过渡户」，这看起来就很 Hack，不像是金融领域的术语和模型。但是如果我们站在状态机的视角来观察，你会发现它的功能其实是很明确的：帮助我们消费「支付成功」这个事件，也就是说，如果「C 网关过渡户」里面的负债过多，那显然意味着外部平台的资金没有及时完成支付，我们需要联系对应的平台进行处理。</p><p>类似的，如果我们的「D 应收应清算」里面的头寸过多，那么显然意味着外部平台比如银行没有及时的把资金转入我们的平台账户中，钱还卡在银行那，我们此时应该及时联系银行进行处理。</p><blockquote><p>上述没有及时结算的状态，在金融领域往往被称为「风险敞口」<br>这个敞口需要我们及时的进行处理，处理的过程往往被称为「头寸管理(Position Management)」或者「平盘」<br>如果平台不及时的进行平盘，那么显然当用户大量提现的时候，平台就会出现资金链断裂的情况，导致资金的亏损和信誉的下降。</p></blockquote><br>为了方便理解以上陈述，我们做出一个假设：银行渠道扣款和支付成功是一回事，于是可以剔除「C 网关过渡户」进行简化，表格也就变成了如下样貌：<table><thead><tr><th>事件</th><th>D 应收待清算</th><th>C 商户待结算</th><th>D 应收应清算</th><th>D 备付金头寸</th><th>C 商户余额户</th></tr></thead><tbody><tr><td>渠道扣款成功</td><td>D + 5</td><td>C + 5</td><td></td><td></td><td></td></tr><tr><td>网联清分完成(完成明细对账)</td><td>C - 5</td><td></td><td>D + 5</td><td></td><td></td></tr><tr><td>资金到账(完成资金对账)</td><td></td><td></td><td>C - 5</td><td>D + 5</td><td></td></tr><tr><td>结算完成</td><td></td><td>D - 5</td><td></td><td></td><td>C + 5</td></tr></tbody></table><p>明细对账？我们也不要了！钱收到了就行！</p><table><thead><tr><th>事件</th><th>D 应收待清算</th><th>C 商户待结算</th><th>D 备付金头寸</th><th>C 商户余额户</th></tr></thead><tbody><tr><td>渠道扣款成功</td><td>D + 5</td><td>C + 5</td><td></td><td></td></tr><tr><td>资金到账(完成资金对账)</td><td>C - 5</td><td></td><td>D + 5</td><td></td></tr><tr><td>结算完成</td><td></td><td>D - 5</td><td></td><td>C + 5</td></tr></tbody></table><p>再简化就不礼貌了，也不现实了，但我们可以让它变得更抽象，更明显的表达状态机的思想：</p><table><thead><tr><th>Events</th><th>D Account1</th><th>C Account2</th><th>D Position</th><th>C Merchant</th></tr></thead><tbody><tr><td>Init Event</td><td>D + 5</td><td>C + 5</td><td></td><td></td></tr><tr><td>Processing Event</td><td>C - 5</td><td></td><td>D + 5</td><td></td></tr><tr><td>Final Event</td><td></td><td>D - 5</td><td></td><td>C + 5</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>dessert</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Finance</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Chores</title>
    <link href="/chores/chores/"/>
    <url>/chores/chores/</url>
    
    <content type="html"><![CDATA[<h2 id="Stories">Stories</h2><h3 id="Donate-a-laptop-for-a-child-in-Bangladesh-2024-12-13">Donate a laptop for a child in Bangladesh - 2024.12.13</h3><p>I’ve been using <code>NeoVim</code> as my primary code editor for 3 years, and I found a plug called <code>markview.nvim</code> in the first half of 2024.</p><p>This plug is a markdown previewer, and it’s very convenient for me to preview the markdown file I’m editing in real-time.</p><blockquote><p>Actually, this article is written in markdown, and I’m exactly using <code>markview.nvim</code> to edit it.</p></blockquote><p>Recently, I found the author of this plugin is a child from Bangladesh, and he completed all the development with his phone…</p><p>In hence, someone suggested that we can donate a laptop to him.</p><p><strong>See:</strong></p><ul><li><a href="https://www.reddit.com/r/neovim/comments/1h7vhmg/bro_been_developing_his_2k_star_plugin_on_a/">Bro been developing his 2k star plugin on a freaking touch phone 🤯🤯🤯</a></li><li><a href="https://github.com/OXY2DEV/markview.nvim/issues/218">Thinkpad GoFundMe</a></li><li><a href="https://www.reddit.com/r/neovim/comments/1hb5szp/please_help_me_raise_funds_for_a_laptop/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button">Please help me raise funds for a laptop</a></li><li><a href="https://hcb.hackclub.com/oxy2dev-laptop/transactions">Transparent ledger of donations</a></li></ul><p><strong>Community’s response:</strong><br><img src="/img/chores/donations_for_the_markview_author.jpg" alt="Donations in 3 days"></p><p><img src="/img/chores/my_comment_for_markview_author.jpg" alt="My Comment"></p><p><strong>markview.nvim</strong></p><p><img src="/img/chores/without_markview.jpg" alt="Without markview.nvim"></p><p><img src="/img/chores/with_markview.jpg" alt="With markview.nvim"></p><p>What a touching and inspiring story!</p>]]></content>
    
    
    <categories>
      
      <category>chores</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Chores</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>「胡思乱想」：马克思的货币与神造的 BTC</title>
    <link href="/imagination/gods_currency/"/>
    <url>/imagination/gods_currency/</url>
    
    <content type="html"><![CDATA[<blockquote><p>如果神造出了一种像 BTC 一样的东西, 它会成为货币吗？</p></blockquote><h2 id="神造的货币">神造的货币</h2><p>神造的货币是什么样子？我们以 BTC 的形态给它再赋予上神的特性，并给它起名为 <u><strong>goin</strong></u>：</p><ul><li>总量固定</li><li>可以无限微分</li><li>社会共识同一使用</li><li>余额无法篡改</li><li>神替每一个人保管账户</li></ul><p>比如，我用 1 <u><strong>goin</strong></u> 买了一杯咖啡，神会在我的账户上扣除 1 <u><strong>goin</strong></u>，然后在咖啡店的账户上增加 1 <u><strong>goin</strong></u>。<br>这个过程是不可逆的，因为神的账本是不可篡改的。</p><h2 id="能成为货币吗？">能成为货币吗？</h2><p>想象这样一种情况：</p><p>世界上只有 2 个人，这两个人加起来一天可以造 2 个人量的水以及 2 个人量的饭，除此之外他们没有别的产出和需求。<br>此时神设定这个世界上一共有 4 个 <u><strong>goin</strong></u>，每个 <u><strong>goin</strong></u> 可以换取一份水或饭。</p><p>假如 A 包揽了 4 个活，B 什么都不干，但是初始情况下，B 毫不费力地占有了全部的 4 个 <u><strong>goin</strong></u>。</p><p>此时 A 是不会接受 B 用 <u><strong>goin</strong></u> 来与他交换水或者饭的，因为他知道 B 没有劳动，所以 B 的 <u><strong>goin</strong></u> 是不值钱的。</p><p>同理 B 会发现，他的 <u><strong>goin</strong></u> 一文不值，因为他的 goin 无法换到任何东西。</p><p><u>所以问题的关键在于 <strong>goin</strong> 的分配。</u></p><p>具体来说，神会在第一天的劳动结束后，也就是 A 造出 2 个人的水，B 造出 2 个人的饭之后，将 4 个 <u><strong>goin</strong></u> 平均分配给他们，于是 A 和 B 各自拥有 2 个 <u><strong>goin</strong></u>。</p><p>换句话来说，如果 A 包揽了所有的活，那么 A 就会拥有全部的 <u><strong>goin</strong></u>，而 B 什么都得不到。此时 A 的 <u><strong>goin</strong></u> 当然也没有什么交换价值，因为他的 <u><strong>goin</strong></u> 无法换到任何东西，因为 B 没有产出。<br>当然了，A 可以在第二天选择啥也不干，由 B 包揽所有的活，A 就可以用他的 <u><strong>goin</strong></u> 来换取水和饭了。</p><p>这还不够，如果 A 和 B 之间稳定的分工合作，两人各自稳定的持有 2 个 <u><strong>goin</strong></u>，让我们假设在这个情况下，冒出来了一个新的人 C，C 也需要水和饭，但是他没有 <u><strong>goin</strong></u>。</p><p>于是 C 在初始情况下，需要自己去劳动，然后用自己的劳动满足自己的需求，或者干多余的活来换取 A 和 B 的 <u><strong>goin</strong></u>。<br>比如 C 出现后的 Day 1 结尾：</p><table><thead><tr><th>人</th><th>水</th><th>饭</th><th>goin</th></tr></thead><tbody><tr><td>A</td><td>2</td><td>0</td><td>2</td></tr><tr><td>B</td><td>0</td><td>2</td><td>2</td></tr><tr><td>C</td><td>1</td><td>1</td><td>0</td></tr></tbody></table><p>Day 2 的时候，A 和 B 各自想偷懒，C 就趁机多干活，用多余的物资换取 A 和 B 手中的 <u><strong>goin</strong></u>。</p><table><thead><tr><th>人</th><th>水</th><th>饭</th><th>goin</th></tr></thead><tbody><tr><td>A</td><td>1</td><td>0</td><td>2-x</td></tr><tr><td>B</td><td>0</td><td>1</td><td>2-x</td></tr><tr><td>C</td><td>2</td><td>2</td><td>2x</td></tr></tbody></table><p>x 是多少呢？是 4/6，也就是 0.66666… 个 <u><strong>goin</strong></u>。因为我们说过 <u><strong>goin</strong></u> 的总量永远都是 4 个，而且是可以无限微分的，此时世界上每天会产出 3 个人的水和饭，一共 6 份，所以每个 <u><strong>goin</strong></u> 的价值就是 4/6。<br>同理，如果有人想一劳永逸的一天产出非常多的水，那么购买一份水的价格也会因为分母的增加而降低。用极限的思维来说，水一天可以产出无限多，那么水的价格就会无限接近于 0。</p><blockquote><p>有人可能会疑惑，我干了这么多活，为啥每一份的水价格还降低了？关于这一点我们不深入讨论，可以参考马克思的《政治经济学批判》，用一个简单的原理解释就是：既然你一天能产出无限多的水，那么说明产出一份水耗费你的劳动量就无限接近于 0。此时，x 实际上也不会无限接近于 0，因为即便你产出了无穷多的水，每一份水也不可能以和饭相同的价值在市场上流通，这主要不是因为水的需求是有限的，而是因为分母的 6 并不是在指代商品的个数总量，而是劳动量，因此 6 为分母指的是三个人一天的劳动量为 6，而不是说一共有 6 份商品，否则一碗饭当中还有非常多的米呢。因此如果你一天能产出无限多的水，这无限多的水包含的劳动量并不是无限的，无非就是两碗饭的劳动量罢了，因此此时的 x 也不会无限接近于 0。</p></blockquote><p>因此这种分配其实就是一种缩放，是一个 <u><strong>goin</strong></u> 对于资源总量（或者说商品 / 劳动）的缩放，之所以称之为缩放，是因为 <u><strong>goin</strong></u> 的总量是固定的，而资源总量在某一固定时刻也是固定的。</p><p>而这个缩放的过程必须由神来替人们精准的初始化，否则就会出现上面的情况（<u><strong>goin</strong></u> 没有价值）。并且神在初始化分配完之后，还需要继续发光发热，也就是指导人们进行交易时这个商品的价格 x 是多少, 当然神也可以不指导，让市场无形的大手来替他干这个活。</p><p>那么此时，你会发现，这个 <u><strong>goin</strong></u> 其实与马克思的货币几乎一致了，也就是&quot;货币是商品，商品的价值是劳动量&quot;。</p><p>不同的地方在于，马克思的货币是由人类社会共同决定的，是人的运动最终将一种商品推举出来形成了货币，于是具有其一定的特点和性质。</p><p>而 <u><strong>goin</strong></u> 是由神来决定的，神是那么的公平和万能，可以为你实现精准的缩放和无法篡改的余额，于是省略了商品货币的一些特性也在情理之中。</p><h2 id="最后的胡思乱想">最后的胡思乱想</h2><p>现代的货币体系，已经不再是马克思的商品货币了，而是一种信用体系下的货币。</p><p>于是乎，信用好或者强大的国家可以&quot;肆无忌惮&quot;的发行货币，也就是印钱，并且全球市场仍会为其买单，而信用差的国家一旦效仿则会被市场惩罚 —— 比如津巴布韦。</p><p>如何理解这种货币体系呢？</p><p>个人认为，结合马克思的商品货币来看，可以理解为：</p><ul><li>马克思的商品货币：我有一些商品，我用它来和你交换你的商品。</li><li>现代的信用货币：我有一些商品兑换券，我用它来和你交换你的商品，你乐意接受，是因为你相信我真的有商品供你兑换，（即便事实上，我此时并没有那些商品，但未来我可能会造出来的）。</li></ul>]]></content>
    
    
    <categories>
      
      <category>imagination</category>
      
    </categories>
    
    
    <tags>
      
      <tag>货币</tag>
      
      <tag>Marx</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一种基于数据库的分布式锁设计</title>
    <link href="/tech/simple_db_lock/"/>
    <url>/tech/simple_db_lock/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在并发场景中，我们经常使用锁来解决数据的共享问题，但语言标准库中的锁往往只能应用于单机的场景，因为多实例部署的场景下，一个实例并不能获取到另一个实例内存中构建的锁。</p></blockquote><h2 id="分布式锁">分布式锁</h2><p>简单来说，分布式锁一般会额外引入一个“中心化的节点”，让所有服务实例都向它请求锁，这样一来实例与实例之间就能通过这个中心化的节点来进行通信了。</p><p>上面提到的“中心化节点”的选型有很多种选择，在业内比较常见的有 Redis / ZooKeeper / 数据库等，本文介绍一种基于数据库的分布式锁设计，数据库本身的选型没有标准的答案，理论上来说只要支持唯一索引（Unique Index）的数据库都符合选型标准，例如常见的 MySQL 和 MongoDB。</p><p>为什么需要唯一索引？因为支持了唯一索引的数据库都具备以下的能力（不考虑硬件故障等意外情况）：</p><p><u><strong>多个并发请求同时向数据库插入唯一键相同的记录时，只有一个请求能够成功。</strong></u>并且失败的请求往往能够识别出失败的原因是来自竞争，例如 <code>Duplicate Key Error</code>。</p><p>可以看到，唯一索引的表现和语言标准库中的锁非常一致。</p><h2 id="数据库表结构设计">数据库表结构设计</h2><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> PLock <span class="hljs-keyword">struct</span> &#123;ID       <span class="hljs-type">string</span> <span class="hljs-comment">// 数据库主键</span>Key      <span class="hljs-type">string</span> <span class="hljs-comment">// 锁定的 key, 与 BizType 组成 uniq key</span>Val      <span class="hljs-type">string</span> <span class="hljs-comment">// 锁的 value, 可以是业务相关的自定义数据</span>BizType  <span class="hljs-type">string</span> <span class="hljs-comment">// 锁的类型, 与 Key 组成 uniq key</span>ExpireAt <span class="hljs-type">int64</span>  <span class="hljs-comment">// 过期时间</span>&#125;</code></pre></div><p>这里为了阅读体验，我们将数据库表结构设计的尽量精简，实际情况中可以根据业务需要自行修改表结构。</p><p>上面可以看出，我们使用 <code>BizType</code> 和 <code>Key</code> 组成了一个唯一索引 <code>(BizType, Key)</code>，然后添加了两个额外的字段 <code>Val</code> / <code>ExpireAt</code> 来存储锁的额外信息。</p><h2 id="加解锁流程设计">加解锁流程设计</h2><p>有了基本的表结构后，我们接下来需要考虑如何基于这张表来实现加解锁的流程。我们在开始前不妨先思考清楚我们想要实现的功能是什么，从业务的角度出发不难得到下面的流程图：</p><pre><code class=" mermaid">flowchart LRdb(Database.PLock)p1(Proc1)p2(Proc2)p3(Proc3)p1 --Lock---&gt; dbp2 --Lock---&gt; dbp3 --Lock---&gt; dbdb --Result---&gt; res(Proc3 Wins!!!)res --&gt; do1(Proc1 quit)res --&gt; do2(Proc2 quit)res --&gt; do3(Proc3 continue)do3 --&gt; ok(job success)do3 --&gt; err(job failed)ok --&gt; e(end)err --&gt; ee --Unlock--&gt; db</code></pre><p>可以看到，我们至少需要两个接口：<code>Lock</code> / <code>Unlock</code>，同时，为了实现一个比较完备的组件，我们在运行过程中可能还需要获取一些别的信息，最终我们将一个“选举器”整理为如下的接口：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-comment">// Elect, 选举器接口, 确保多实例部署情况下在同一时刻, 同一 key 只有一个实例在运行对应任务</span><span class="hljs-keyword">type</span> Elect <span class="hljs-keyword">interface</span> &#123;<span class="hljs-comment">// Lock, 锁定 key 并运行 cb, 通过 cb 传入的 context 可以用于监听任务的取消信号</span><span class="hljs-comment">// 因此 cb 内部实现应当处理 ctx.Done() 信号, 以便在任务取消时及时退出</span><span class="hljs-comment">// 仅当锁定成功时, 才会运行 cb 并返回 true</span><span class="hljs-comment">// 其余情况均返回 false, 如有错误, 则返回错误</span>Lock(key <span class="hljs-type">string</span>, cb <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context)</span></span>) (ok <span class="hljs-type">bool</span>, err <span class="hljs-type">error</span>)<span class="hljs-comment">// Unlock, 解锁 key 并取消运行中的任务</span>Unlock(key <span class="hljs-type">string</span>) (err <span class="hljs-type">error</span>)<span class="hljs-comment">// HoldingKeys, 返回当前持有的所有 key</span>HoldingKeys() []<span class="hljs-type">string</span><span class="hljs-comment">// LockedKeys, 返回当前被锁定的所有 key</span><span class="hljs-comment">// 注意和 HoldingKeys 的区别, HoldingKeys 只返回当前实例持有的 key,</span><span class="hljs-comment">// 而 LockedKeys 返回所有实例持有的 key, 一般从数据库中查询得知</span>LockedKeys() ([]<span class="hljs-type">string</span>, <span class="hljs-type">error</span>)<span class="hljs-comment">// Close 优雅退出</span>Close()&#125;</code></pre></div><p>接口定义的方法也比较简洁，需要实现的具体功能见代码的注释即可。</p><p>但是我们不难发现，接口内定义的方法似乎没有覆盖到 <code>PLock</code> 表中全部的字段，尤其是唯一键中的 <code>BizType</code>—— 这里稍微解释一下，我个人的编码习惯会将其放入到实现类中去，这里给出一个基于 MongoDB 的实现：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-comment">// mongoElect, 基于 MongoDB 的 Elect 实现, 字段含义见 MongoElectConfig</span><span class="hljs-keyword">type</span> mongoElect <span class="hljs-keyword">struct</span> &#123;bizType                          mongodb.PLockBizTypeholder                           <span class="hljs-type">string</span>holdDuration                     time.DurationrefreshInterval, refreshDuration time.Durationmu           *sync.RWMutexrunningTasks <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*lockedTask <span class="hljs-comment">// key: lock key, value: locked task</span>logger *logrus.Entry&#125;<span class="hljs-keyword">type</span> MongoElectConfig <span class="hljs-keyword">struct</span> &#123;<span class="hljs-comment">// BizType 业务类型</span>BizType mongodb.PLockBizType<span class="hljs-comment">// Holder 锁的持有者名称, 例如: 服务实例 ID</span>Holder <span class="hljs-type">string</span><span class="hljs-comment">// HoldDuration 初始锁的持有时间, 例如: 任务执行时间</span>HoldDuration time.Duration<span class="hljs-comment">// RefreshInterval 锁的续期间隔, 例如: 任务执行时间的 1/3</span>RefreshInterval time.Duration<span class="hljs-comment">// RefreshDuration 锁的续期时间(以 now 为标准), 至少为 RefreshInterval 的 2 倍</span>RefreshDuration time.Duration&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewMongoElect</span><span class="hljs-params">(conf *MongoElectConfig)</span></span> Elect &#123;<span class="hljs-keyword">if</span> conf == <span class="hljs-literal">nil</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;conf must not be nil&quot;</span>)&#125;<span class="hljs-keyword">if</span> conf.BizType == <span class="hljs-string">&quot;&quot;</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;bizType must not be empty&quot;</span>)&#125;<span class="hljs-keyword">if</span> conf.Holder == <span class="hljs-string">&quot;&quot;</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;holder must not be empty&quot;</span>)&#125;<span class="hljs-keyword">if</span> conf.HoldDuration &lt;= <span class="hljs-number">0</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;holdDuration must be positive&quot;</span>)&#125;<span class="hljs-keyword">if</span> conf.RefreshInterval &lt;= <span class="hljs-number">0</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;refreshInterval must be positive&quot;</span>)&#125;<span class="hljs-keyword">if</span> conf.RefreshDuration &lt;= <span class="hljs-number">0</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;refreshDuration must be positive&quot;</span>)&#125;<span class="hljs-keyword">if</span> conf.RefreshDuration &lt; conf.RefreshInterval*<span class="hljs-number">2</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;refreshDuration must be greater than 2 * refreshInterval&quot;</span>)&#125;<span class="hljs-keyword">return</span> &amp;mongoElect&#123;bizType:         conf.BizType,holder:          conf.Holder,holdDuration:    conf.HoldDuration,refreshInterval: conf.RefreshInterval,refreshDuration: conf.RefreshDuration,mu:              <span class="hljs-built_in">new</span>(sync.RWMutex),runningTasks:    <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*lockedTask),logger: logrus.WithFields(logrus.Fields&#123;<span class="hljs-string">&quot;bizType&quot;</span>:      conf.BizType,<span class="hljs-string">&quot;holder&quot;</span>:       conf.Holder,<span class="hljs-string">&quot;holdDuration&quot;</span>: conf.HoldDuration,<span class="hljs-string">&quot;refresh&quot;</span>:      fmt.Sprintf(<span class="hljs-string">&quot;%v/%v&quot;</span>, conf.RefreshInterval, conf.RefreshDuration),<span class="hljs-string">&quot;module&quot;</span>:       <span class="hljs-string">&quot;mongo_elect&quot;</span>,&#125;),&#125;&#125;</code></pre></div><p>上面这个实现类实现的具体功能是：加锁时，初始设置好锁的过期时间为 <code>HoldDuration</code>，如果加锁成功，则开始运行任务，运行过程中每经过 <code>RefreshInterval</code> 的间隔，就把锁的过期时间延长为 <code>time.Now + RefreshDuration</code>，直到任务结束为止。</p><p>通过这种设计，我们可以“大致”保证<u><strong>在任务完成之前锁不会过期</strong></u>，因为我们会不断的进行 refresh 操作来延长锁的持有时间。当然如果想要让程序健壮地达到这个目标，我们需要引入更多的复杂性，仅仅依赖一个结构体的字段定义是不足以实现的。</p><p>接下来，我们开始实现加解锁的流程（接口中的其他方法比较简单，略过）：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(e *mongoElect)</span></span> Lock(key <span class="hljs-type">string</span>, cb <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(context.Context)</span></span>) (ok <span class="hljs-type">bool</span>, err <span class="hljs-type">error</span>) &#123;e.mu.Lock()<span class="hljs-keyword">defer</span> e.mu.Unlock()<span class="hljs-comment">// 锁定成功后, 运行任务</span><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<span class="hljs-keyword">if</span> ok &#123;e.logger.Infof(<span class="hljs-string">&quot;[Lock] elect success, key: %v&quot;</span>, key)task := e.runningTasks[key]<span class="hljs-keyword">if</span> task == <span class="hljs-literal">nil</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;[Lock] task not found after lock&quot;</span>)&#125;e.runTask(task, cb)&#125;&#125;()<span class="hljs-comment">// 预查询目标锁</span>lock, err := mongodb.PLockDAL.QueryByUniqKey(key, e.bizType)<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;e.logger.WithError(err).Error(<span class="hljs-string">&quot;[Lock] elect failed with query error&quot;</span>)<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 目标锁不存在, 尝试创建</span><span class="hljs-keyword">if</span> lock == <span class="hljs-literal">nil</span> &#123;isDup, err := e.createLock(key)<span class="hljs-keyword">return</span> err == <span class="hljs-literal">nil</span> &amp;&amp; !isDup, err&#125;<span class="hljs-comment">// 目标锁存在, 但已过期, 精确删除该锁后再尝试创建</span><span class="hljs-keyword">if</span> lock.ExpireAt &lt; common.Millisec(time.Now()) &#123;e.logger.Warnf(<span class="hljs-string">&quot;[Lock] elect for an expired lock, try delete it, key: %v, lock: %v&quot;</span>, key, lock)<span class="hljs-keyword">if</span> err = mongodb.PLockDAL.DeleteByID(lock.ID); err != <span class="hljs-literal">nil</span> &#123;e.logger.WithError(err).Error(<span class="hljs-string">&quot;[Lock] elect failed with delete error&quot;</span>)<span class="hljs-keyword">return</span>&#125;isDup, err := e.createLock(key)<span class="hljs-keyword">return</span> err == <span class="hljs-literal">nil</span> &amp;&amp; !isDup, err&#125;<span class="hljs-comment">// 锁是自己创建的, 报错提示</span><span class="hljs-keyword">if</span> lock.Value == e.holder &#123;<span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>, fmt.Errorf(<span class="hljs-string">&quot;lock of %s already owned&quot;</span>, key)&#125;<span class="hljs-comment">// 锁不是自己创建的, 返回失败</span>e.logger.WithFields(logrus.Fields&#123;<span class="hljs-string">&quot;key&quot;</span>:  key,<span class="hljs-string">&quot;lock&quot;</span>: lock,&#125;).Warn(<span class="hljs-string">&quot;[Lock] elect failed for already locked&quot;</span>)<span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>, <span class="hljs-literal">nil</span>&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(e *mongoElect)</span></span> createLock(key <span class="hljs-type">string</span>) (dup <span class="hljs-type">bool</span>, err <span class="hljs-type">error</span>) &#123;expireAt := common.Millisec(time.Now().Add(e.holdDuration))id, isDup, err := mongodb.PLockDAL.Create(key, e.holder, e.bizType, expireAt)e.logger.Infof(<span class="hljs-string">&quot;[createLock] elect result, key: %v, id: %v, err: %v&quot;</span>, key, id, err)<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>, err&#125;<span class="hljs-keyword">if</span> isDup &#123;e.logger.Warnf(<span class="hljs-string">&quot;[createLock] elect failed for already locked, key: %v&quot;</span>, key)<span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>, <span class="hljs-literal">nil</span>&#125;<span class="hljs-keyword">if</span> id == <span class="hljs-literal">nil</span> &#123;err = fmt.Errorf(<span class="hljs-string">&quot;[createLock] elect failed for missing lock id, key: %v&quot;</span>, key)e.logger.WithError(err).Error(<span class="hljs-string">&quot;Unknown error&quot;</span>)<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 成功创建锁, 记录任务</span>task := defaultLockedTask(key)task.lockID = *ide.runningTasks[key] = task<span class="hljs-keyword">return</span>&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(e *mongoElect)</span></span> runTask(task *lockedTask, cb <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(context.Context)</span></span>) &#123;refreshFn := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;ticker := time.NewTicker(e.refreshInterval)lockID := task.lockID.(primitive.ObjectID)logger := e.logger.WithField(<span class="hljs-string">&quot;lockID&quot;</span>, lockID.String())<span class="hljs-keyword">for</span> &#123;<span class="hljs-keyword">select</span> &#123;<span class="hljs-keyword">case</span> &lt;-task.canceled():e.logger.Info(<span class="hljs-string">&quot;[refreshFn] refresh lock canceled&quot;</span>)ticker.Stop()e.safeCancelTask(task)<span class="hljs-keyword">return</span><span class="hljs-keyword">case</span> &lt;-ticker.C:<span class="hljs-comment">// 查询锁</span><span class="hljs-keyword">var</span> lock *mongodb.PLock<span class="hljs-keyword">for</span> &#123;<span class="hljs-keyword">var</span> err <span class="hljs-type">error</span>lock, err = mongodb.PLockDAL.QueryByID(lockID)<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;logger.WithError(err).Error(<span class="hljs-string">&quot;[refreshFn] refresh lock failed with query error&quot;</span>)time.Sleep(time.Second)<span class="hljs-keyword">continue</span>&#125;<span class="hljs-keyword">break</span>&#125;nowTs := common.Millisec(time.Now())<span class="hljs-comment">// 锁不存在, 异常情况, 直接退出</span><span class="hljs-comment">// 或者续期不及时, 已被其他实例抢占</span><span class="hljs-keyword">if</span> lock == <span class="hljs-literal">nil</span> || lock.ExpireAt &lt; nowTs &#123;logger.Errorf(<span class="hljs-string">&quot;[refreshFn] refresh lock failed for lock not found, maybe released&quot;</span>)e.safeCancelTask(task)<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 正常续期</span>expireAt := common.Millisec(time.Now().Add(e.refreshDuration))e.logger.Infof(<span class="hljs-string">&quot;[refreshFn] refresh lock start, new expireAt: %v&quot;</span>, expireAt)<span class="hljs-keyword">if</span> err := mongodb.PLockDAL.UpdateExpireAtByID(lockID, expireAt); err != <span class="hljs-literal">nil</span> &#123;logger.WithError(err).Error(<span class="hljs-string">&quot;[refreshFn] refresh lock failed with update error&quot;</span>)<span class="hljs-comment">// 如果续期失败, 且距离过期时间不足 2 倍的 refresh interval, 则直接退出</span><span class="hljs-comment">// 否则可能导致锁过期时, 任务还在执行</span><span class="hljs-comment">// 其余情况暂时不管, 会在下次续期时重试</span><span class="hljs-keyword">if</span> lock.ExpireAt-nowTs &lt; e.refreshInterval.Milliseconds()*<span class="hljs-number">2</span> &#123;logger.Error(<span class="hljs-string">&quot;[refreshFn] refresh lock failed for too late&quot;</span>)e.safeCancelTask(task)<span class="hljs-keyword">return</span>&#125;&#125;e.logger.Infof(<span class="hljs-string">&quot;[refreshFn] refresh lock success, new expireAt: %v&quot;</span>, expireAt)&#125;&#125;&#125;task.run(cb, refreshFn)&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(e *mongoElect)</span></span> safeCancelTask(task *lockedTask) &#123;e.mu.Lock()<span class="hljs-keyword">defer</span> e.mu.Unlock()e.cancelTask(task)&#125;<span class="hljs-comment">// WARN: 该方法需要在持有锁的情况下调用</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(e *mongoElect)</span></span> cancelTask(task *lockedTask) &#123;<span class="hljs-comment">// 先取消任务</span>task.cancelAndWait()lockID := task.lockID.(primitive.ObjectID)<span class="hljs-comment">// 再删除 db 锁, 重试直到成功</span>common.WithRetry(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-type">error</span> &#123;<span class="hljs-keyword">if</span> err := mongodb.PLockDAL.DeleteByID(lockID); err != <span class="hljs-literal">nil</span> &#123;e.logger.WithError(err).Error(<span class="hljs-string">&quot;[cancelTask] cancel task failed with delete error&quot;</span>)<span class="hljs-keyword">return</span> err&#125;<span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>&#125;, <span class="hljs-number">-1</span>, time.Second)<span class="hljs-comment">// 最后删除任务</span><span class="hljs-built_in">delete</span>(e.runningTasks, task.key())&#125;</code></pre></div><p>上面的代码比较长，我们逐步进行解释（注，本文将省略数据库层面的代码）：</p><ol><li>加锁时，首先查询想要锁的唯一键是否存在<ol><li>如果不存在，则直接进行加锁即可（可能会由于竞争而加锁失败）</li><li>如果存在，到 2</li></ol></li><li>目标锁存在，进一步检查其是否过期<ol><li>如果过期了，则通过 id 字段精确删除这条锁记录后，再尝试创建</li><li>如果没有过期，是一把正常的锁，到 3</li></ol></li><li>目标锁正常，进一步检查这把锁的持有人是谁<ol><li>如果是自己，则报错，这里我们暂不支持可重入</li><li>如果不是自己，也报错，说明加锁失败的原因</li></ol></li></ol><p>最后，我们回到开头就写好的 <code>defer</code> 函数，如果最终加锁的结果是成功的，则开始运行 <code>cb</code> 函数，上面代码中使用了一个封装好的 <code>lockedTask</code> 类型，具体实现我们放在下文展示，这里先继续关注运行的流程。</p><hr><p>可以看到，在 <code>runTask</code> 函数中，我们定义了一个 <code>refreshFn</code> 用于刷新锁的有效期，然后将这个 <code>refreshFn</code> 和业务的 <code>cb</code> 一起运行了，这里我们聚焦到刷新的逻辑上：</p><ol><li><p>监听 task 的退出信号</p><ol><li>如果退出了，说明 task 以及不再运行了，直接返回即可（当然我们冗余调用了一次 <code>safeCancelTask</code>，目的主要是将 task 从结构体维护的 <code>runningTask</code> 中清理出去）</li><li>如果没有退出，则到 2</li></ol></li><li><p>监听 ticker</p><p>前面我们提到了，我们的设计是每经过 A 时间，就续期 B 时间，所以依赖一个 ticker 来实现 A 的逻辑。</p><p>续期的逻辑如下：</p><p>a. 查询持有的锁记录，不存在或过期则直接调用 <code>safeCancelTask</code> 退出。（事实上，这种情况理论上不应存在，除非前置的查询由于 db 的问题不断重试，但为了以防万一还是写上了这段兜底的代码，具体原因见 b）</p><p>b. 锁存在且未过期的情况下，我们调用 Update 函数进行续期，失败时如下处理：</p><p>​b.1. 如果 Update 失败，且锁的过期时间小于当前时间 + 2 倍的续期间隔，则直接中断</p><p>​b.2. 否则暂时忽略，等待下一次续期重试</p><p>看到这里，我们应该能明白，为什么说续期时理论上不会发生锁记录不存在或锁过期的情况了，因为在续期过程中，即使续期的 Update 行为发生了错误，我们也会妥善的进行处理 —— 一旦发现锁临近过期，我们就会立即终止任务，防范于未然；如果锁过期时间较为久远，则容忍本次失败。</p></li></ol><hr><p>接下来看一看解锁的实现：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(e *mongoElect)</span></span> Unlock(key <span class="hljs-type">string</span>) <span class="hljs-type">error</span> &#123;e.mu.Lock()<span class="hljs-keyword">defer</span> e.mu.Unlock()task, ok := e.runningTasks[key]<span class="hljs-keyword">if</span> !ok &#123;<span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;lock of %s not owned&quot;</span>, key)&#125;e.cancelTask(task)<span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>&#125;</code></pre></div><p>有了加锁的底子，解锁实现起来就比较简单了，只需要调用 <code>cancelTask</code> 方法即可。</p><hr><p>附：lockedTask 具体实现</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> lockedTask <span class="hljs-keyword">struct</span> &#123;ctx    context.Contextcancel context.CancelFunclockKey <span class="hljs-type">string</span>lockID  anydoneCh  <span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;runOnce *sync.Once&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">defaultLockedTask</span><span class="hljs-params">(key <span class="hljs-type">string</span>)</span></span> *lockedTask &#123;ctx, cancel := context.WithCancel(context.Background())<span class="hljs-keyword">return</span> &amp;lockedTask&#123;ctx:     ctx,cancel:  cancel,lockKey: key,doneCh:  <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;),runOnce: <span class="hljs-built_in">new</span>(sync.Once),&#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lt *lockedTask)</span></span> run(cb <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(context.Context)</span></span>, refresh <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span>) &#123;lt.runOnce.Do(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<span class="hljs-comment">// 后台运行任务</span><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;cb(lt.ctx)<span class="hljs-built_in">close</span>(lt.doneCh)lt.cancel()log.WithFields(logrus.Fields&#123;<span class="hljs-string">&quot;lockKey&quot;</span>: lt.lockKey,<span class="hljs-string">&quot;lockID&quot;</span>:  lt.lockID,&#125;).Info(<span class="hljs-string">&quot;locked task done&quot;</span>)&#125;()<span class="hljs-comment">// 后台刷新锁有效期</span><span class="hljs-keyword">go</span> refresh()&#125;)&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lt *lockedTask)</span></span> cancelAndWait() &#123;lt.cancel()&lt;-lt.doneCh&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lt *lockedTask)</span></span> canceled() &lt;-<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125; &#123;<span class="hljs-keyword">return</span> lt.ctx.Done()&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lt *lockedTask)</span></span> key() <span class="hljs-type">string</span> &#123;<span class="hljs-keyword">return</span> lt.lockKey&#125;</code></pre></div><p>不难看出，<code>lockedTask</code> 类型主要是封装了业务任务的执行流程，为其添加了基于 <code>context.Context</code> 的中断控制以及刷新锁的有效期的方法。</p><hr><p>最终我们得到的选举器的工作过程大致如下图所示：</p><p><img src="/img/simple_db_lock/p1.png" alt="流程图"></p><h2 id="结尾">结尾</h2><p>结束了吗？还没有，即使我们实现了一个 <code>Elect</code> 接口，我们仍需要考虑一个问题：调用方应该怎样合理的进行调用？</p><p>我在实际工作中遇到过这样的需求：一个服务的多实例同时启动后，均匀的让每个实例处理同一个类型的不同任务。比如说，这个服务需要订阅 100 个消息队列的 topic，我将部署 10 台实例，在他们启动后，让这 100 个订阅任务均匀的分配到这些实例上去。</p><p>此时，我们在应用层也有许多工作要做，例如：</p><ol><li>限制每个实例最多处理的任务数量，在本例中可以是 20 （此时允许有 5 台实例挂掉，剩下 5 台实例可以接管）。</li><li>启动异步的监控协程，监控有哪些任务没有实例在处理，一旦发现则尝试抢占对应任务的锁并接管。</li></ol><p>总而言之，本文实现了一个与业务无关的中间组件，目的是向大家展示分布式系统下复杂的情况以及我们可能的处理方式，希望能对读者有所启发。</p><p>如何将程序写得更为健壮一直是计算机领域内的一大难题，我们可以针对不同的场景对其需要的健壮性进行合理评估。对于很多不重要的场景而言，将代码实现得无比健壮也许是浪费时间的，例如，我也会在很多场景下简单地使用 redis 中的 <code>set nx ex</code> 指令来充当一个简单的分布式锁，但对于很多重要的场景而言（例如银行、电商），这种方式往往都是不可取的。</p>]]></content>
    
    
    <categories>
      
      <category>tech</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Golang</tag>
      
      <tag>Database</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从「股市」App 看股市</title>
    <link href="/economics/analyze_stocks/"/>
    <url>/economics/analyze_stocks/</url>
    
    <content type="html"><![CDATA[<blockquote><p>从 Apple Stocks App （股市 App）开始，看懂一支股票。</p><p>注：本文不构成任何投资建议。</p></blockquote><h2 id="前言">前言</h2><p>作为一个程序员，尤其是金融交易相关的程序员，自己或多或少也会与“投资理财”打交道。目前我的日常生活中接触最多的理财产品就是基金，中国内陆市面上可以自由购买的基金的「标的」中，常见的无非是股票和债券两种（当然也有部分稳健的基金会投资于货币或其他标的）。即便是 FOF 类的基金也是如此，绕过中间的层层代理，最终在基金经理的运作下，我的钱会被用于购买股票、债券或是其他产品。</p><p>于我而言，甚至是于大多数人而言，基金最大的意义在于让专业的交易员来替我规划投资组合，避免“吊死在一棵树上”。而在市场上的一揽子基金中，我更倾向于购买 ETF 指数基金，这类基金的目标往往是追踪一个市场上的指数，例如新能源汽车行业的 ETF 指数基金的表现，往往与整个新能源汽车行业的公司股票表现相关。在这类基金中，基金经理的操作空间较小，往往由程序和算法来计算投资组合的比例分配，可以较好的体现一个行业的整体表现，一般不必担心人为因素所造成的偏差。</p><p>于是，作为普通的投资者——往往不具备看准一支股票的预言能力，我可以站在一个更为宏观的角度来选择我的投资方向，比如：“相比于互联网行业，我更看好新能源行业，同时我还看好白酒行业”，那么此时我就可以购买相关行业的指数基金来验证我的想法。相比之下，在“蔚小理和比亚迪”中选择我要购买的具体的股票，就显得较为困难了。</p><h2 id="进入正题">进入正题</h2><p>前面提到了一些简单的背景——看起来当我购买了行业的指数基金之后，我就可以放弃思考了，只要等着新一代的年轻人开始爱上喝茅台、开新能源汽车，我就可以大赚一笔！</p><p>知其然，还要知其所以然，既然我们投资的基金的标的基本是由股票构成，那么我们自然会意识到，占比较重的股票的涨跌，会直接影响到我们的基金价格。</p><p>好巧不巧，最近和一位好友闲聊时，他提到说他正准备开通一个美股的交易账号，我便询问他是想购买哪一支股票，他说他比较看好国内新能源车企中的「理想汽车」。顺势之下，我便打开了 MacBook 上的「股市」App，查看了理想汽车在美股的相关数据。</p><p><img src="/img/analyze-stocks/liauto.png" alt="Li Auto"></p><p>可以看到，除了股价的走势之外，「股市」App 的图表下方还有一系列相关的数据，这些数据代表了什么，我们又能从中获得怎样的信息？</p><h2 id="走势图与-K-Line">走势图与 K Line</h2><p>股市 App 中的“走势图” UI 较为简单，较为简单的反映了股价随着时间的变化曲线，从中我们能获取到的信息比较有限 —— 这是因为股市 App 本身并不是一个交易所 App，用户在这里并不能买卖股票，它的数据来源也注明了是 “yahoo! finance”，因此我们在该 App 上不能获取到详细的交易数据也是可以理解的。</p><p>与之对应的，我们可以看到在数据表中，有「今日开盘价」和「今日最高 / 低价」这几栏数据。实际上，联系上表中缺失的「今日收盘价」，我们可以根据这四维数据绘制出一个“小蜡烛”，将每天的小蜡烛都进行汇总，会得到大名鼎鼎的「K 线图」。</p><p>相反地，从一张已有的 K 线图中，我们可以反向地解读出这四维的数据，也就可以对某一天的交易情况做出一个合理的推测了。相关的信息可以参照 OANDA Lab 撰写的研究文章，该文章十分详细的阐述了这四维数据背后所对应的可能情况，这里就不做展开了：</p><p><a href="https://www.oanda.com/bvi-ft/lab-education/dictionary/k-charts/">K 线及其透露的市场秘密</a></p><h2 id="成交量和平均成交量">成交量和平均成交量</h2><p>「成交量」的定义比较简单，也就是它们的字面意思，代表了一定时间段内的成交量，股市 App 中的单位是“股数”，也就是成交了多少股的意思。</p><p>一般而言，股票的成交量越大，可以说它的流动性越好 —— 也就是说大家都愿意去买卖这支股票，这一点不难理解。从更深层上来说，参与买卖股票的人对股价的评价越冲突时，成交量就越大，因为当大家对股价的看法都比较一致时，也就更难产生交易的行为。</p><p>举例来说，如果持有特斯拉股票的人，都认为特斯拉的股价处于偏低的状态，日后还有较大的升值空间，那么大家就不太愿意在二级市场上抛售自己所持有的股票，会攥在手里等待升值。反之，如果市面上看空和看多的人有激烈的冲突，那么市场上买卖的人就多了起来，有的人急于抛售，害怕股价亏损给自己带来损失，剩下的人则乐意接盘，认为现在是个抄底的好机会。</p><p><u>值得注意的是，股市 App 中的「平均成交量」与金融行业中普遍使用的术语是不同的。</u></p><p>「平均成交量」的计算公式如下：<br>$$<br>平均成交量 = 成交量 \div 笔数<br>$$<br>也就是说，平均成交量代表了每一笔交易平均成交了多少股。</p><p>而股市 App 中的「平均成交量」指的是过去一段时间内的「每日成交量」的平均数，也就是用来衡量过去一段时间中，每天大约交易了多少股，而不是指代每笔交易的平均成交额。</p><p>因此，综合来讲，这两个指标都有助于我们评估一支股票的流动性，更为详细的信息则无法获取到了。</p><h2 id="贝塔系数">贝塔系数</h2><p>贝塔系数是一种用来评估股票证券风险的工具，用通俗的话来说，贝塔系数反映的是当前股票与大盘之间的关联关系 —— 贝塔系数绝对值越大，大盘涨的时候，当前股票就涨的越多，反之亦然。</p><p>例如：</p><ol><li>当贝塔系数 = 1.1 时，大盘涨了 10 %，当前股票就会涨 11 %。</li><li>当贝塔系数 = 5.6 时，大盘跌了 10 %，当前股票就会跌 56 %。</li></ol><p>是不是感觉看起来有点像合约交易中的杠杆？从计算上来说确实如此，但这两者有着本质上的不同：</p><p>合约杠杆是用户在开始交易前<u>提前设置</u>好的，而贝塔系数则是根据历史数据<u>回过头计算得到</u>的。</p><p>接下来简单看一眼贝塔系数的计算公式：<br>$$<br>\beta = \frac{Cov(r_a, r_m)}{\sigma_m^2}\<br>\begin{cases}<br>r_a &amp;= 股票的收益\<br>r_m &amp;= 市场的收益\<br>Cov(r_a, r_m) &amp;= 二者的协方差\<br>\sigma_m^2 &amp;= 市场收益的方差<br>\end{cases}<br>$$</p><blockquote><p>协方差的值可以反映两个指标之间的相关性：</p><p>协方差为正数，则指标 A 增加📈时，指标 B 也有增加📈的趋势；</p><p>协方差为负数，则指标 A 增加📈时，指标 B 有减小📉的趋势；</p><p>协方差为 0 ，则两个指标之间的关联性不强。</p><p>方差则表明了数据的分散程度，方差越大数据越分散。</p></blockquote><p>公式表明，贝塔系数本身其实<u><strong>并不能表明股票和市场之间的直接联系</strong></u>，但可以帮助我们大致的判断一支股票在过去一段时间内的“股性”。</p><blockquote><p>从数学上来说，贝塔系数为 0 只能推导出“证券价格波动与市场价格波动无关”，而不能说明这个证券是没有风险的。但反过来说，如果一个证券没有风险，那么它的贝塔系数一定为 0。</p><p>但其实根据个人经验来说，我们一般在市场中交易的股票都能够使用贝塔系数来当作「股票和市场间的联系」看待，因为普通人交易的股票中的绝大部分都与市场情绪是强相关的。</p></blockquote><p>一般来说，熊市时我们可以选择贝塔系数低的股票来帮助我们抵御风险，牛市来临时我们可以选择贝塔系数高的股票来帮助我们放大收益。</p><h2 id="每股收益，越高越好！">每股收益，越高越好！</h2><p>每股收益的定义也比较简单：<br>$$<br>EPS = \frac{期末净利润}{期末股份总数}<br>$$<br>可以看到，每股收益越高，在市场中往往说明该公司的净利润越高（减少股份总数的情况比较少，这里暂不考虑）。</p><p>市场上往往使用 EPS 排名来区分优质股和垃圾股。</p><h2 id="市盈率是什么，越高越好？">市盈率是什么，越高越好？</h2><p>前面提到了每股收益 EPS 是越高越好的，那么对于市盈率 PE 是否也是这样呢？</p><p>先看市盈率 PE 的计算公式：<br>$$<br>PE = \frac{股价}{EPS}<br>$$</p><p>可以看到，EPS 的计算与前文提到的 EPS 是息息相关的。而我们前面又提到，EPS 是越高越好的，因为 EPS 越高往往说明公司的净利润越高，股票越优质。</p><p>那么 PE 是不是也是越高越好呢？通过公式我们可以看到，PE 越高往往说明股价越高，或是 EPS 越小。而这两种情况都不算是好消息 —— 我们既不希望在股价处于高点时买入，也不希望购入 EPS 很低的“垃圾股”。</p><p>举例来说，随着一家优秀公司的成长和发展，这家公司股票的 EPS 会不断增加，此时购入其股票的人也会越来越多，于是其股价也会不断上升，最终这家公司的市盈率 PE 会落在一个合理的区间中（分子和分母都在不断增大）。</p><p>但是只有一家公司的 PE 值，其参考价值往往不够大，最好的方式是<u><strong>在同行业中对不同公司的 PE 进行对比</strong></u>，例如对比五粮液和茅台两家公司的 PE 值，或是对比理想和比亚迪之间的 PE 值。通过这种对比我们可以大致的看出一家公司在行业中的股价是否“偏高”。</p><p>接下来我们将 EPS 带入公式，从另一个角度来理解市盈率：<br>$$<br>PE = \frac{股价}{EPS} = \frac{股价}{\frac{期末净利润}{期末股份总数}}<br>= \frac{股价\cdot期末股份总数}{期末净利润}\approx \frac{市值}{期末净利润}<br>$$<br>最终公式中的分子为<code>股价*股数</code>，我们可以将其理解为一家公司的市值，于是 PE 就被化简为市值比上利润了，这种形式是不是看起来更好理解一些 —— PE 过高要么说明其市值过高，要么说明其利润太少。</p><p>最后我们再回归 PE 公式本身，从最后一个视角来理解 PE：<br>$$<br>PE = \frac{股价}{EPS}<br>$$<br>思考我购入一只股票后，永不卖出并且及时提取分红的情况下，我需要多少时间才能回本？</p><p>假设公司 A 的股价是每股 100 元，A 公司的每股收益 EPS = 10，那么当我花了 100 元购买一股之后，单纯吃股息的情况下，我每年能够获得 10 元收益，于是我需要 <code>100 / 10 = 10</code> 年的时间才能回本。</p><hr><p>MBA 智库中有一个 PE 的参考范围：</p><ul><li>0-13：即价值被低估</li><li>14-20：即正常水平</li><li>21-28：即价值被高估</li><li>28+：反映股市出现投机性泡沫</li></ul><hr><p>OANDA Lab 中也有下方表格供参考：</p><table><thead><tr><th>股价范围</th><th>PE 范围</th><th>预期投资回报率</th></tr></thead><tbody><tr><td>偏高</td><td>20 &lt; PE</td><td>&lt; 5%</td></tr><tr><td>合理</td><td>10 &lt; PE &lt; 20</td><td>&lt; 6.7%</td></tr><tr><td>偏低</td><td>PE &lt; 10</td><td>&lt; 8.3%</td></tr></tbody></table><hr><p>作为普通的投资者，如何根据上述提到的诸多信息来选购一家公司的股票呢？下面是根据公式推导的一个结论表格：</p><table><thead><tr><th>股价</th><th>EPS 每股收益</th><th>PE 市盈率</th></tr></thead><tbody><tr><td>A = B</td><td>越高越好</td><td>股价相同，EPS 越高，PE 越低，回本时间越短</td></tr><tr><td>越低越好</td><td>A = B</td><td>EPS 相同，股价越低，PE 越低，回本时间越短</td></tr><tr><td>A ≠ B</td><td>A ≠ B</td><td>此时一般只看 PE，PE 越低，回本时间越短</td></tr></tbody></table><h2 id="市净率又是什么，和市盈率有关系吗？">市净率又是什么，和市盈率有关系吗？</h2><p>市净率 PB 指的是股价和每股净资产的比值：<br>$$<br>PB = \frac{股价}{每股净资产}<br>$$</p><blockquote><p>每股净资产是净资产 / 股数</p><p>净资产就是一家公司的<strong>总资产-总负债</strong>，也就是当公司卖掉所有资产和付清所有负债之后剩余的价值</p></blockquote><p>同样我们代入公式进行进一步推导：<br>$$<br>PB = \frac{股价}{每股净资产} = \frac{股价}{\frac{净资产}{股数}} = \frac{股价\cdot股数}{净资产} \approx \frac{市值}{净资产}<br>$$<br>可以看到 PB 越等于市值除以净资产。</p><p>看过了前面内容，这里我们也能迅速的得出，一般而言 PB 越低的股票投资价值越高，这一点和 PE 是基本相同的。</p><p>举例来说：在理想情况下，公司的 Day 1 当天，PB 应该为 1，即：公司价值 100 万，那么我花 1 万就能买到 1% 的公司；随着时间增长，公司股票越来越值钱，在股价涨了 10 倍之后，公司价值 1000 万时，我花 1 万只能买到 0.1% 的公司了，此时 PB 也就变成了 10。</p><p>一般来说，我们会认为 PB 比 PE 更为稳定，因为从公式中我们就能看出来，PE 随着盈利变化，而 PB 随着净资产变化，在短期时间内，公司的盈利也许会发生巨大的波动，例如苹果举行发布会后，手机的销量也许会大幅上升，但公司的净资产的变化却非常少。</p><p>其次，PE 不适用于亏损的企业，因为亏损的企业没有盈利无法计算 PE，但是这类企业是有净资产的，PB 仍然能够被计算出来。</p><h2 id="AI-时代，交给-AI">AI 时代，交给 AI</h2><p>写在最后，AI 的时代，再让我们请教一下 AI。</p><p>根据 GuruFocus 给出的数据，我们不难看出 Li Auto 的股票在同行业中，呈现出高 PE 低 PB 的情况，交给 ChatGPT 来对其进行分析：</p><p><img src="/img/analyze-stocks/pe.png" alt="PE"></p><p><img src="/img/analyze-stocks/pb.png" alt="PB"></p><p><img src="/img/analyze-stocks/chatgpt.png" alt="ChatGPT"></p><p>AI 给出的分析仅供参考，这里给出个人的一些思考：</p><p>理想汽车最近在新能源行业中扭亏为盈，刚刚进入盈利阶段的理想由于盈利不多，因此在 PE 的计算中分母比较小，造成了 PE 本身很大，而 PB 较低，则代表了理想公司的账面资产比较多（分母较大）。也就是说，PB 低，PE 高的情况，针对当前阶段的理想来说，基本都是因为分母造成的。</p><p>按照彼得林奇的说法，针对强周期性的股票，就应该在 PB 低 PE 高的情况下买入，因为在弱周期来临时，由于盈利不佳，PE 会升高，但资产不太变动的情况下，PB 即使在弱周期也可能较低。在此刻买入就越等于在弱周期买入，针对周期性股票，在弱周期买入显然是有利的。</p><p>一般来说，低 PB 高 PE 的情况往往会出现在即将实现困境反转型的企业或是周期股的底部，理想比较偏向前者，但这类股票也往往比较难把握，因为“很可能它反转不了呢”。或者说，虽然 PB 很低，我此时能用相同的钱买入更多的公司资产，但也许“都是些产生不了利润的垃圾资产呢”。总而言之，这类情况的股票在一般情况下“即使低价，也很难吸引人”，把握这类资产需要很强的专业能力。</p>]]></content>
    
    
    <categories>
      
      <category>economics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>股票</tag>
      
      <tag>金融</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>理解 Golang context.Context</title>
    <link href="/tech/golang_ctx/"/>
    <url>/tech/golang_ctx/</url>
    
    <content type="html"><![CDATA[<blockquote><p>Go 在 1.7 版本中引入了标准库 context，现在在各大开源库中已经变得随处可见。</p><p>本文基于 go1.21.1 darwin/arm64 源码编写。</p></blockquote><h2 id="入门-Context">入门 Context</h2><h3 id="Context-是什么？">Context 是什么？</h3><p>在 <code>context.go</code> 文件的开头，Go Authors 定义了主角 <code>Context interface</code> ，并对其做出了如下描述：</p><blockquote><p><em>A Context carries a deadline, a cancellation signal, and other values across API boundaries.</em></p><p><em>Context’s methods may be called by multiple goroutines simultaneously.</em></p></blockquote><p>也就是说，Context 具备如下 4 个功能：</p><ol><li>可以携带用于控制「超时」的 Deadline 信息</li><li>可以携带用于控制「取消」的 Signal 信息</li><li>可以携带自定义数据</li><li>可能被多个 <code>goroutine</code> 并发调用</li></ol><p>从这几个基本功能及其命名中，我们可以大致看出，<code>Context</code> 是一个数据结构，它不仅可以用于保存自定义的数据，还额外携带了被动超时和手动取消的功能，除此之外，它本身还是<u>并发安全</u>的 —— 我们该如何运用起来？它对我们的编程有什么实际的帮助？</p><hr><h3 id="Context-的基本编程范式">Context 的基本编程范式</h3><p>前面我们已经了解到 <code>Context</code> 的大致概念，接下来我们将目光放在代码层面，看看这个数据结构在 Go 语言中基本的编程范式是怎样的。</p><p>在 Golang 官方的<a href="https://pkg.go.dev/context">文档</a>中，明确地指出了 <code>context.Context</code> 的使用场景：</p><blockquote><p><em>Incoming requests to a server should create a <a href="https://pkg.go.dev/context#Context">Context</a>, and outgoing calls to servers should accept a Context. The chain of function calls between them must propagate the Context …</em></p></blockquote><p>一个服务器收到请求之后，应该创建一个 <code>Context</code> ，而下游的服务器也应该接受一个 <code>Context</code> ，在函数调用链中，<code>Context</code> 也应该不间断的被传递。</p><p>也就是说，<code>Context</code> 这个数据结构，<u>应该伴随一整个请求的完整链路</u>：</p><p><img src="/img/go-ctx/pass-ctx.png" alt="向下游传递的 ctx"></p><p>除此之外，在服务的内部，<code>Context</code> 也<u>应该在函数调用链中不断的被传递</u>：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;ctx := context.Background()chainRoot(ctx, ...)&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">chainRoot</span><span class="hljs-params">(ctx context.Context, ...)</span></span> &#123;...chainSecond(ctx, ...)...&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">chainSecond</span><span class="hljs-params">(ctx context.Context, ...)</span></span> &#123;...chainThird(ctx, ...)...&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">chainThird</span><span class="hljs-params">(ctx context.Context, ...)</span></span> &#123;...&#125;</code></pre></div><p>至此，我们对 <code>Context</code> 的基本使用方式有了一个基本的了解 —— 将其放在函数参数列表中的第一位，然后在编码时手动传递。在跨服务调用的场景下，我们应该将 ctx 序列化后伴随请求传递到下游服务中，下游服务再将其反序列化出来继续使用。</p><p>此外，从上面的代码中，我们也不难理解为什么在 Golang 官方的注释中描述道：<code>Context</code> 可能被多个 <code>goroutine</code> 并发调用 —— 在整个调用链中，我们很有可能开启若干协程来处理业务，且每个协程都对 <code>Context</code> 都具备访问权限。</p><hr><h3 id="Context-的具体使用">Context 的具体使用</h3><p>通过上面的描述，我们已经大致了解到 <code>Context </code> 在实际编码中的编程范式 —— 作为参数进行传递。一些有经验的程序员在初见时，自然而然会觉得：“这不是在对代码造成侵入吗？”，就像 Golang 中处理错误的方式一样，也会有人觉得这十分不优雅。</p><p>让我们先抛开这些“审美观念”不谈，把目光先聚焦在 <code>Context</code> 的具体使用方式上，看看它能对我们的编程过程带来多大的帮助。理解了它真正能起到的作用之后，我们再根据实际业务情况来做权衡也不迟。</p><p>接下来根据第一节中提到的前三种数据承载的能力，我们分别给出相应的 demo 进行演示。</p><h4 id="1-传递自定义数据">1. 传递自定义数据</h4><p>我们可以使用 <code>context.Background()</code> 来获得一个初始化的 <code>Context</code>，再使用 <code>context.WithValue()</code> 来给一个现有的 <code>Context</code> 注入自定义数据:</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;ctx := context.Background()ctx = context.WithValue(ctx, <span class="hljs-string">&quot;key1&quot;</span>, <span class="hljs-string">&quot;value1&quot;</span>)ctx = context.WithValue(ctx, <span class="hljs-string">&quot;key2&quot;</span>, errors.New(<span class="hljs-string">&quot;value2&quot;</span>))ctx = context.WithValue(ctx, <span class="hljs-string">&quot;key3&quot;</span>, <span class="hljs-number">3</span>)fn(ctx)&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">fn</span><span class="hljs-params">(ctx context.Context)</span></span> &#123;<span class="hljs-built_in">println</span>(ctx.Value(<span class="hljs-string">&quot;key1&quot;</span>).(<span class="hljs-type">string</span>))<span class="hljs-built_in">println</span>(ctx.Value(<span class="hljs-string">&quot;key2&quot;</span>).(<span class="hljs-type">error</span>).Error())<span class="hljs-built_in">println</span>(ctx.Value(<span class="hljs-string">&quot;key3&quot;</span>).(<span class="hljs-type">int</span>))&#125;</code></pre></div><p>从这段代码中可以看出，<code>Context</code> 的行为就像是一个 <code>map[string]any</code> ，我们在获取数据时可能会需要用到类型断言。</p><p>传递自定义数据相关的使用比较简单，这里不再展开。</p><hr><h4 id="2-用于超时控制">2. 用于超时控制</h4><p>很多时候，我们需要对一个过程（可以是本地函数调用，也可以是远程过程调用）设置好时间的限制，避免其运行太久。</p><p>我们可以使用如下四个函数来给一个 <code>Context</code> 注入超时信息：</p><ol><li><code>context.WithTimout()</code></li><li><code>context.WithTimeoutCause()</code></li><li><code>context.WithDeadline()</code></li><li><code>context.WithDeadlineCause()</code></li></ol><p>其中，函数末尾带有 <code>Cause</code> 意味这你可以「自定义一个超时错误」传入函数中，当发生超时的时候 <code>Context</code> 会将这个自定义错误返回出来，否则它会返回一个默认的超时错误。</p><p>并且，<code>WithTimout*</code> 本质上是 <code>WithDeadline*</code> 的一个封装，封装过程也极其简单，即：将 <code>time.Duration</code> 与 <code>time.Now</code> 求和从而计算得出 <code>Deadline</code>。</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;ctx := context.Background()<span class="hljs-comment">// 给 ctx 设置 3s 后超时</span>ctx, cancel := context.WithTimeout(ctx, time.Second*<span class="hljs-number">3</span>)<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<span class="hljs-keyword">defer</span> cancel()longTimeWork(ctx)&#125;()<span class="hljs-comment">// ctx 超时结束后，从中获取导致其结束的 err 信息</span><span class="hljs-keyword">select</span> &#123;<span class="hljs-keyword">case</span> &lt;-ctx.Done():<span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;main:&quot;</span>, ctx.Err().Error())&#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">longTimeWork</span><span class="hljs-params">(ctx context.Context)</span></span> &#123;<span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; ;i++ &#123;<span class="hljs-keyword">select</span> &#123;<span class="hljs-keyword">case</span> &lt;-ctx.Done(): <span class="hljs-comment">// 监听超时信号</span><span class="hljs-keyword">return</span><span class="hljs-keyword">default</span>: <span class="hljs-comment">// 未超时则继续处理业务逻辑</span><span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;doing sth inside&quot;</span>, i)time.Sleep(time.Second)&#125;&#125;&#125;</code></pre></div><div class="code-wrapper"><pre><code class="hljs sh">Output:doing sth inside 1doing sth inside 2doing sth inside 3main: context deadline exceeded</code></pre></div><p><strong>代码解析：</strong></p><p>在上面的例子中，我们在外层设置了一个过期时间为 3 秒的 <code>Context</code> ，然后将这个 <code>Context</code> 作为参数传递给了一个耗时很长的函数，该函数内部不断监听着这个 <code>Context</code> 的超时信号，当超时发生时立即退出。</p><p>最后在外层，我们监测到 <code>Context</code> 超时后，可以通过 <code>Context.Err()</code> 来获取错误信息，即输出中的 <code>context deadline exceeded</code>。</p><p><strong>思考：</strong></p><p>仔细观察上面对于超时过程的监控过程，我们不难发现，对于超时信号的监控侵入了 <code>longTimeWork</code> 的代码实现。</p><p>这种方式看起来让我们的代码变得不够优雅，但它也给我们带来一个好处 —— 极细粒度的超时检测，例如我们可以将代码改写为下方这样：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">longTimeWork</span><span class="hljs-params">(ctx context.Context)</span></span> &#123;<span class="hljs-comment">// 封装一个判断是否超时的函数</span>timeouted := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-type">bool</span> &#123;<span class="hljs-keyword">select</span> &#123;<span class="hljs-keyword">case</span> &lt;-ctx.Done():<span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><span class="hljs-keyword">default</span>:<span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>&#125;&#125;subwork1(...)<span class="hljs-keyword">if</span> timeouted() &#123;<span class="hljs-keyword">return</span>&#125;subwork2(...)<span class="hljs-keyword">if</span> timeouted() &#123;<span class="hljs-keyword">return</span>&#125;subwork3(...)<span class="hljs-keyword">if</span> timeouted() &#123;<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// ...</span>&#125;</code></pre></div><p>可以看到，我们甚至可以将检测超时的粒度细分为「行级」，每执行一行代码就检测一次。</p><p>通过 <code>Context</code> 赋予我们的超时机制，我们可以用一行代码为基本单位来实现细粒度的超时检测（粒度可以从 1 行到 n 行），在 <code>Context</code> 的帮助下，我们可以容易地避免掉大量无意义的运算行为。</p><hr><h4 id="3-用于手动终止">3. 用于手动终止</h4><p>在上一节中，我们看到了基于超时的行为控制，但有时我们的业务逻辑可能需要更精准的控制，例如：虽然现在还尚未超时，但是我当下就想立马取消后续的所有运算。</p><p>比如 javascript 中 <code>Promise.Race()</code> 就是一个很好的例子。我们有时会开启多个异步任务让他们进行“比赛”，任何一个任务完成都意味着这场比赛已经结束，因为我们已经拿到了我们想要的计算结果，此时别的任务再进一步去做运算已经失去了意义，这时我要是能手动取消这些任务就能节省大量的运算资源。</p><p>在 <code>Context</code> 中，我们可以使用<code>context.WithCancel</code> 来给 <code>Context</code> 设置一个手动取消的信号监听器：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;ctx := context.Background()ctx, cancel := context.WithCancel(ctx)<span class="hljs-keyword">go</span> longTimeWork(ctx)<span class="hljs-comment">// 3s 后手动取消</span>timer := time.NewTimer(time.Second * <span class="hljs-number">3</span>)<span class="hljs-keyword">select</span> &#123;<span class="hljs-keyword">case</span> &lt;-timer.C:cancel()&#125;<span class="hljs-keyword">select</span> &#123;<span class="hljs-keyword">case</span> &lt;-ctx.Done():<span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;main:&quot;</span>, ctx.Err().Error())&#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">longTimeWork</span><span class="hljs-params">(ctx context.Context)</span></span> &#123;<span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; ; i++ &#123;<span class="hljs-keyword">select</span> &#123;<span class="hljs-keyword">case</span> &lt;-ctx.Done():<span class="hljs-keyword">return</span><span class="hljs-keyword">default</span>:<span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;doing sth inside&quot;</span>, i)time.Sleep(time.Second)&#125;&#125;&#125;</code></pre></div><div class="code-wrapper"><pre><code class="hljs sh">Output:doing sth inside 0doing sth inside 1doing sth inside 2main: context canceled</code></pre></div><p>可以看到，这次我们在外层等待 3s 后手动调用 <code>cancel()</code>取消了异步任务，而之前是在外部仅设置超时时间，ctx 内部自主取消，差别还是比较明显的。</p><p>同样，内部响应取消信号的粒度与之前前文是一致的，可以进行自定义，甚至可以忽略这个信号 —— 只要你不去监听 <code>ctx.Done()</code> 即可。</p><hr><h4 id="4-综合使用">4. 综合使用</h4><p>我们在实际应用的过程中，可以将前面提到的若干特性结合起来一并使用。</p><p>这里举一个实用的例子：</p><blockquote><p>我们往往在生产环境会部署若干个服务，用户的请求会经过网关到达一个又一个的服务，最后经过一系列处理后返回结果给客户端。</p><p>此时我们面临着若干的问题：</p><ol><li>网关设置的超时时间如何与后端服务进行联动？</li></ol><p>注意，网关虽然有自己的超时时间，在超时发生时，网关会拒绝等待后端服务的响应，直接给用户返回 HTTP 504 错误。但是此时如果后端服务没有感知到这一点，就会继续进行无意义的处理和运算，最终返回给网关的结果也会被网关丢弃，造成不必要的资源浪费。同理，服务调用链上的每个节点之间也都面临相同的问题，不局限于网关和网关的下一跳节点。</p><ol start="2"><li>通用数据的传递有没有更简洁的方式？</li></ol><p>客户端发起的请求，在处理过程中往往需要很多额外的信息（请求本身的信息可能并不足够），这些信息往往在前置的节点中会被查询出来，然后捎带给下游节点。但是，在服务内部的函数调用链上，如何将所有这些额外的数据进行传递呢？一种简单方式就是将这些中途得到的信息以参数的形式传给函数内部，但是这可能随着数据种类的增多，导致函数的参数列表变得臃肿。</p><ol start="3"><li>能不能灵活的终止进行中的任务？</li></ol><p>与前面「用于手动终止」一节提到的原理类似，仅仅依赖超时时间来进行流程控制是不够灵活的，我们希望可以自己决定何时终止。</p></blockquote><p>下面给出一段伪代码演示综合使用的方式（实际使用中可能会封装得更加抽象和优雅，这里只做展示用）</p><ul><li>代码使用了 <code>gin</code> 框架作为 http 服务器</li><li>我们首先定义了通用的数据和特定接口的请求体</li><li>然后编写了一个中间件用于前置解析请求并生成 <code>ctx</code></li><li>随后在接口的 handler 中我们可以直接获取到解析好的 <code>ctx</code> 并传递给业务函数进行使用了</li></ul><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> BaseCtx <span class="hljs-keyword">struct</span> &#123;UserID    <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;userID&quot;`</span>AccountID <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;accountID&quot;`</span>&#125;<span class="hljs-keyword">type</span> UserRequest <span class="hljs-keyword">struct</span> &#123;Username <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;username&quot;`</span>&#125;<span class="hljs-comment">// Middleware 解析请求中的 JSON 请求体并将参数存储到 Context 中</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ContextMiddleware</span><span class="hljs-params">()</span></span> gin.HandlerFunc &#123;<span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<span class="hljs-comment">// 读取请求体</span>body, err := io.ReadAll(c.Request.Body)<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;c.JSON(http.StatusBadRequest, gin.H&#123;<span class="hljs-string">&quot;error&quot;</span>: <span class="hljs-string">&quot;Failed to read request body&quot;</span>&#125;)c.Abort()<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 将请求体重新放回请求中</span>c.Request.Body = io.NopCloser(bytes.NewBuffer(body))<span class="hljs-comment">// 解析 JSON 请求体到 BaseCtx 结构</span><span class="hljs-keyword">var</span> baseCtx BaseCtx<span class="hljs-keyword">if</span> err := json.Unmarshal(body, &amp;baseCtx); err != <span class="hljs-literal">nil</span> &#123;c.JSON(http.StatusBadRequest, gin.H&#123;<span class="hljs-string">&quot;error&quot;</span>: <span class="hljs-string">&quot;Failed to parse JSON&quot;</span>&#125;)c.Abort()<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 将参数存储到 Context 中</span>ctx := context.WithValue(context.Background(), <span class="hljs-string">&quot;userID&quot;</span>, baseCtx.UserID)ctx = context.WithValue(ctx, <span class="hljs-string">&quot;accountID&quot;</span>, baseCtx.AccountID)<span class="hljs-comment">// 将新的 Context 替换原有的 Context</span>c.Request = c.Request.WithContext(ctx)<span class="hljs-comment">// 继续处理请求</span>c.Next()&#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;r := gin.Default()  <span class="hljs-comment">// 注册解析 ctx 的中间件 </span>r.Use(ContextMiddleware())r.POST(<span class="hljs-string">&quot;/user&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<span class="hljs-comment">// 获取 Context</span>ctx := c.Request.Context()<span class="hljs-comment">// 超时时间为 5 秒</span>ctx, cancel := context.WithTimeout(ctx, <span class="hljs-number">5</span>*time.Second)<span class="hljs-keyword">defer</span> cancel()<span class="hljs-comment">// 读取请求体</span>body, err := io.ReadAll(c.Request.Body)<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;c.JSON(http.StatusInternalServerError, gin.H&#123;<span class="hljs-string">&quot;error&quot;</span>: <span class="hljs-string">&quot;Failed to read request body again&quot;</span>&#125;)c.Abort()<span class="hljs-keyword">return</span>&#125;userReq := &amp;UserRequest&#123;&#125;<span class="hljs-keyword">if</span> err := json.Unmarshal(body, userReq); err != <span class="hljs-literal">nil</span> &#123;c.JSON(http.StatusBadRequest, gin.H&#123;<span class="hljs-string">&quot;error&quot;</span>: <span class="hljs-string">&quot;Failed to parse JSON again&quot;</span>&#125;)c.Abort()<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 在处理程序中使用 ctx 和请求体</span><span class="hljs-built_in">println</span>(ctx, userReq)c.String(http.StatusOK, <span class="hljs-string">&quot;ok&quot;</span>)&#125;)r.Run(<span class="hljs-string">&quot;:8080&quot;</span>)&#125;</code></pre></div><p>上面大致演示了一下在实际生产中如何使用 ctx，一般来说，我们会在接到请求后利用一些中间件来提前做好解析，包括配置好当前请求的超时时间等，后续在业务逻辑相关的代码中就可以拿来即用了。</p><p>当然，需要注意的是，我们在业务逻辑中可能会调用下游服务，此时我们还需要在调用下游服务前实现一个类似的中间件，将 ctx 中必要的参数序列化到请求中，从而可以传递到下游中去。</p><p>但是，我们不难发现 ctx 中非常规的数据是无法进行序列化的，例如 <code>function</code> 、<code>chan</code> 等，甚至包括设置好的超时监听器。因此，我们可能需要将超时时间等信息，以时间戳或字符串的形式进行序列化，这些同样可以封装在中间件的逻辑中。</p><hr><h2 id="Context-原理">Context 原理</h2><p>前面介绍了 <code>Context</code> 的使用方式，接下来介绍 <code>Context</code> 的实现原理。</p><h3 id="接口定义">接口定义</h3><p><code>Context</code> 本身是一个接口，对外提供的方法比较少，常用的方法已经在上文演示过了：</p><ol><li><code>ctx.Done()</code> ，用于监听取消 / 超时信号</li><li><code>ctx.Err()</code> ，用于获得取消 / 超时的原因</li><li><code>ctx.Value()</code> ，用于获得自定义数据</li></ol><p>除此之外还有一个方法叫做 <code>Deadline() (ddl time.Time, ok bool)</code>，这个方法用于获得设置好的超时时间。</p><hr><h3 id="实现类">实现类</h3><p>既然是一个接口，那么就应该有相对应的实现：</p><ul><li><code>valueCtx</code>，对应 <code>context.WithValue()</code>，是一个用于承载自定义数据的实现。</li><li><code>timerCtx</code>，对应 <code>context.WithDeadline*|WithTimout*()</code>，是一个用于承载超时逻辑的实现。</li><li><code>cancelCtx</code>，对应 <code>context.WithCancel*()</code>，是一个用于承载取消逻辑的实现。</li></ul><hr><h3 id="继承关系">继承关系</h3><p>从上面的几个 <code>context.With*(parent Context)</code> 方法的参数定义中，我们发现 <code>Context</code> 与 <code>Context</code> 之间是存在继承关系的，比如：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;ctx := context.WithValue(context.Background(), <span class="hljs-string">&quot;k1&quot;</span>, <span class="hljs-string">&quot;v1&quot;</span>)ctx, _ = context.WithTimeout(ctx, <span class="hljs-number">5</span>*time.Second)&#125;</code></pre></div><p>这段代码能够生成一个既带有自定义数据 <code>&lt;k1, v1&gt;</code> 又带有超时时间 <code>5*time.Second</code> 的 <code>Context</code>。</p><p>由此，我们从最简单的 <code>valueCtx</code> 开始，先探寻 <code>Context</code> 之间的继承关系是如何实现的。</p><hr><h3 id="valueCtx">valueCtx</h3><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> valueCtx <span class="hljs-keyword">struct</span> &#123;Contextkey, val any&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithValue</span><span class="hljs-params">(parent Context, key, val any)</span></span> Context &#123;<span class="hljs-keyword">if</span> parent == <span class="hljs-literal">nil</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;cannot create context from nil parent&quot;</span>)&#125;<span class="hljs-keyword">if</span> key == <span class="hljs-literal">nil</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;nil key&quot;</span>)&#125;<span class="hljs-keyword">if</span> !reflectlite.TypeOf(key).Comparable() &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;key is not comparable&quot;</span>)&#125;<span class="hljs-keyword">return</span> &amp;valueCtx&#123;parent, key, val&#125;&#125;</code></pre></div><p>可以看到，<code>valueCtx</code> 本身就是一个单链表结构，通过内部的 <code>Context</code> 字段指向父节点来完成一个反向的连接。</p><p>当我们连续调用三次 <code>context.WithValue</code> 时，如下：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;ctx := context.Background()ctx = context.WithValue(ctx, <span class="hljs-string">&quot;k1&quot;</span>, <span class="hljs-string">&quot;v1&quot;</span>)ctx = context.WithValue(ctx, <span class="hljs-string">&quot;k2&quot;</span>, <span class="hljs-string">&quot;v2&quot;</span>)ctx = context.WithValue(ctx, <span class="hljs-string">&quot;k3&quot;</span>, <span class="hljs-string">&quot;v3&quot;</span>)&#125;</code></pre></div><p>会得到一个如图所示的链表结构，很好理解：</p><p><img src="/img/go-ctx/valueCtx.png" alt="反向关联的 valueCtx"></p><p>也就是说，当我们调用 <code>Context.Value(key string)</code> 的时候，我们会从当前的 <code>valueCtx</code> 一路往前寻找，直到链表的首节点为止：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *valueCtx)</span></span> Value(key any) any &#123;<span class="hljs-keyword">if</span> c.key == key &#123;<span class="hljs-keyword">return</span> c.val&#125;<span class="hljs-keyword">return</span> value(c.Context, key)&#125;</code></pre></div><hr><h3 id="cancelCtx">cancelCtx</h3><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> cancelCtx <span class="hljs-keyword">struct</span> &#123;Contextmu       sync.Mutex            <span class="hljs-comment">// protects following fields</span>done     atomic.Value          <span class="hljs-comment">// of chan struct&#123;&#125;, created lazily, closed by first cancel call</span>children <span class="hljs-keyword">map</span>[canceler]<span class="hljs-keyword">struct</span>&#123;&#125; <span class="hljs-comment">// set to nil by the first cancel call</span>err      <span class="hljs-type">error</span>                 <span class="hljs-comment">// set to non-nil by the first cancel call</span>cause    <span class="hljs-type">error</span>                 <span class="hljs-comment">// set to non-nil by the first cancel call</span>&#125;</code></pre></div><p>这里变得稍微复杂一些了，但是我们可以发现，反向链表的数据结构仍然得到了保留，多余的字段都是用于服务 <code>cancel</code> 功能的。</p><p>那么我们看一看 <code>context.WithCancel()</code> 做了什么，是如何初始化一个 <code>cancelCtx</code> 并用它构建起一个链表节点的：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithCancel</span><span class="hljs-params">(parent Context)</span></span> (ctx Context, cancel CancelFunc) &#123;c := withCancel(parent)<span class="hljs-keyword">return</span> c, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123; c.cancel(<span class="hljs-literal">true</span>, Canceled, <span class="hljs-literal">nil</span>) &#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">withCancel</span><span class="hljs-params">(parent Context)</span></span> *cancelCtx &#123;<span class="hljs-keyword">if</span> parent == <span class="hljs-literal">nil</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;cannot create context from nil parent&quot;</span>)&#125;c := &amp;cancelCtx&#123;&#125;c.propagateCancel(parent, c)<span class="hljs-keyword">return</span> c&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *cancelCtx)</span></span> propagateCancel(parent Context, child canceler) &#123;c.Context = parentdone := parent.Done()<span class="hljs-keyword">if</span> done == <span class="hljs-literal">nil</span> &#123;<span class="hljs-keyword">return</span> <span class="hljs-comment">// parent is never canceled</span>&#125;...<span class="hljs-keyword">if</span> p, ok := parentCancelCtx(parent); ok &#123;<span class="hljs-comment">// parent is a *cancelCtx, or derives from one.</span>p.mu.Lock()<span class="hljs-keyword">if</span> p.err != <span class="hljs-literal">nil</span> &#123;<span class="hljs-comment">// parent has already been canceled</span>child.cancel(<span class="hljs-literal">false</span>, p.err, p.cause)&#125; <span class="hljs-keyword">else</span> &#123;<span class="hljs-keyword">if</span> p.children == <span class="hljs-literal">nil</span> &#123;p.children = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[canceler]<span class="hljs-keyword">struct</span>&#123;&#125;)&#125;p.children[child] = <span class="hljs-keyword">struct</span>&#123;&#125;&#123;&#125;&#125;p.mu.Unlock()<span class="hljs-keyword">return</span>&#125;...<span class="hljs-comment">// 这里实现了取消的逻辑</span><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<span class="hljs-keyword">select</span> &#123;<span class="hljs-keyword">case</span> &lt;-parent.Done():child.cancel(<span class="hljs-literal">false</span>, parent.Err(), Cause(parent))<span class="hljs-keyword">case</span> &lt;-child.Done():&#125;&#125;()&#125;</code></pre></div><p>上面的代码可能看起来比较复杂，但是本质上实现了一个大致如下的功能：</p><ul><li>将当前的 <code>cacelCtx</code> 与链表中与自己最近的父级 <code>cancelCtx</code> 关联起来</li><li>开启一个 <code>goroutine</code> 监听父级 <code>cancelCtx</code> 的取消信号</li></ul><p>也就是说，当一个可以进行取消操作（比如 <code>valueCtx</code> 就不具备取消功能）的 ctx 被取消时，它在链表上的所有关联起来的子级 ctx 也会被取消。</p><p><img src="/img/go-ctx/cancelCtx.png" alt="额外产生的正向关联"></p><p>从上图可以看到，<code>cancelCtx</code> 在链表上与自己最近的父级 <code>cancelCtx</code> 建立起了一个正向的关联，这个关联正是使用 <code>children map[canceler]struct&#123;&#125;</code> 字段来实现的。</p><p>有了这个关联关系，当父级节点进行 <code>cancel()</code> 操作时，所有的可以取消的子级节点也会被 <code>cancel()</code>。但是反过来则不行，也就是说一个子级节点取消后并不会影响它的父级节点。</p><p>具体的取消实现逻辑这里略过，Golang 本身利用了原子变量和锁机制保证了并发安全，最终实现的目标便是在 <code>cancelCtx.done</code> 中安全的放入一个已经被关闭的 <code>chan</code>，从而让外界能够通过 <code>&lt;-ctx.Done()</code> 语法来感知到当前 ctx 已经被取消了；同时还给 <code>ctx.err</code> 赋予了对应的信息，外界便可以通过 <code>ctx.Err()</code> 来获取到这个信息。</p><hr><h3 id="timerCtx">timerCtx</h3><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> timerCtx <span class="hljs-keyword">struct</span> &#123;cancelCtxtimer *time.Timer <span class="hljs-comment">// Under cancelCtx.mu.</span>deadline time.Time&#125;</code></pre></div><p>从定义中，我们不难看出，<code>timerCtx</code> 继承了 <code>cancelCtx</code>，也就是说 <code>timerCtx</code> 也是「可取消」的 <code>Context</code>，在上面图中的链表结构中，它的关联方式与 <code>cancelCtx</code> 是保持一致的。</p><p>只不过，<code>timerCtx</code> 本身还依赖于一个额外的 <code>timer *timer.Timer</code> 来实现它的超时逻辑。</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithDeadlineCause</span><span class="hljs-params">(parent Context, d time.Time, cause <span class="hljs-type">error</span>)</span></span> (Context, CancelFunc) &#123;<span class="hljs-keyword">if</span> parent == <span class="hljs-literal">nil</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;cannot create context from nil parent&quot;</span>)&#125;...c := &amp;timerCtx&#123;deadline: d,&#125;c.cancelCtx.propagateCancel(parent, c)...c.mu.Lock()<span class="hljs-keyword">defer</span> c.mu.Unlock()<span class="hljs-keyword">if</span> c.err == <span class="hljs-literal">nil</span> &#123;<span class="hljs-comment">// 注意这里，timer 中的 goroutine 在到期之后会调用这个 cancel 方法</span>c.timer = time.AfterFunc(dur, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;c.cancel(<span class="hljs-literal">true</span>, DeadlineExceeded, cause)&#125;)&#125;<span class="hljs-keyword">return</span> c, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123; c.cancel(<span class="hljs-literal">true</span>, Canceled, <span class="hljs-literal">nil</span>) &#125;&#125;</code></pre></div><p>从上面的代码中可以看到，整体上 <code>timerCtx</code> 与 <code>cancelCtx</code> 行为保持一致，但是利用了一个 <code>time.Timer</code> 启动了一个额外的 <code>goroutine</code> 来实现超时之后自动调用 <code>cancel()</code> 的逻辑。</p><p>至此，我们的 <code>Context</code> 继承关系大致如下所示：</p><p><img src="/img/go-ctx/timerCtx.png" alt="context.Context 组成的树"></p><hr><h2 id="后话">后话</h2><p>不管 Context 使用起来是否优雅，毋庸置疑的是它是 Golang 团队官方提出的编程范式和解决方案，我在字节跳动工作期间，整个团队都在以规范的方式使用着 Context。</p><p>具体来说，有以下几个典型的应用场景：</p><ul><li>我们会使用 Context 来传递一些在网关层就可以使用插件植入的 “租户/ 用户 ID” 以及 “租户密钥” 之类的数据，配合 <code>gorm</code> 框架提供的回调功能，可以让业务无感知的情况下，进行数据库查询条件的修改，以及写前加密、读后解密的逻辑。</li><li>字节跳动开源的 <code>KiteX</code> RPC 框架（<a href="https://github.com/cloudwego/kitex">Link</a>）中，实现了 Context 的自动序列化 / 反序列化，让业务方无感知的就能够获取并传递 Context。</li><li>团队的基建中，也依赖 Context 进行流量染色和链路追踪的功能。</li><li>…</li></ul><p>Golang 官方对于 Context 的使用还有诸多建议，就个人而言，我认为最需要注意的是我们不应该将 Context 视为一个万能的参数传递容器，否则将导致代码的可读性和可维护性大打折扣 —— 试想如果项目中所有函数都如下定义该是多么可怕的一件事：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Xxx</span><span class="hljs-params">(ctx context.Context)</span></span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Yyy</span><span class="hljs-params">(args <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]any)</span></span></code></pre></div><p>PS：我目前所在的团队从不使用 Context（虽然我本人非常倾向使用），链路上也没有通过 <code>TracingId / LogId</code> 之类的参数进行串联，但是就目前来看，这也没有对我们的运维和迭代造成太大的困扰。</p><p>总而言之，Context 不是银弹，但它已经证明了它的强大。</p>]]></content>
    
    
    <categories>
      
      <category>tech</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>漫画图解 AWS KMS 与 AWS Secret Manager 的集成</title>
    <link href="/tech/aws_kms_and_secret_mgr/"/>
    <url>/tech/aws_kms_and_secret_mgr/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在 AWS 中，用户时常容易混淆「AWS KMS」与「AWS Secrets Manager」—— 不仅是从名字上容易混淆，而且在实际使用的过程中，二者在<u>某些场景中</u>也存在一定的可互换性。</p><p>从顶层的设计出发点来说，KMS 是一种允许用户管理加密密钥的服务，用于加密、解密、签名和其他操作。</p><p>而「Secrets Manager」则更像是一种用来存储密码和 API 密钥等高等级数据的数据库。有了它，我们就可以避免应用程序中进行硬编码 API Key，也可以无需自行存储用户密码（除非你的团队有极强的专业水准和工程能力，否则自己维护一个包含了用户账号密码的数据库是极其困难且不安全的，而 AWS 提供的加密服务甚至武装到了硬件）。</p><p>与此同时，为了更好地保护机密数据，AWS Secrets Manager 也可以配合使用 KMS 对其内容进行加密来获取更高的安全性。</p><p>下面用一则漫画来演示二者集成的大致工作流程：</p><p><img src="/img/comic_kms/comic.png" alt="漫画图解"></p><h2 id="后话">后话</h2><p>在上面的漫画中，忽略了一个重要问题——谁有权限从 Secrets Manager 中获取解密的明文数据？</p><p>AWS 根据使用的密钥管理方式都实现了类似的授权机制：</p><ol><li>用户基于 KMS 自动托管的加密密钥可以使用 KMS 来管理授权范围，需要配合 IAM 系统在 AWS 平台上进行配置，客户端通过 AWS Credential 来表明自己的身份。</li><li>用户基于自行管理的 KMS 密钥来加密的数据也可以使用类似的方式在平台上配置 Policy 和 IAM 等来实现鉴权，区别在于自行管理的 KMS 密钥的 id 是自定义的，需要自己找到对应密钥的配置进行更改。</li></ol><p>综上所述，通过对二者的观察，可以看到一个比较明显的区别在于——Secrets Manager可以获取到存进去的数据的明文，而 KMS 只是提供了加解密等比较原子的功能，KMS 是无论如何都不会将设置进去的密钥返回出来的，它所做的只是在安全的黑盒中使用你最初配置的密钥对你的输入进行加解密操作（当然还有一些额外的功能，例如签名和验签等，这里不再赘述）。</p><p>本文只是大致介绍了两者的集成流程，并比较了二者的区别，有兴趣的读者可以阅读下面的参考资料和 AWS 的官方文档进行查阅。</p><h2 id="参考资料">参考资料</h2><p><a href="https://blog.lightspin.io/understanding-the-integration-between-kms-and-secrets-manager-on-aws">Understanding the Integration Between KMS and Secrets Manager on AWS</a></p>]]></content>
    
    
    <categories>
      
      <category>tech</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AWS</tag>
      
      <tag>安全</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一种高性能的 Kafka 消费模型</title>
    <link href="/tech/high_perf_kafka_consumer/"/>
    <url>/tech/high_perf_kafka_consumer/</url>
    
    <content type="html"><![CDATA[<blockquote><p>Kafka 无疑是现在最流行的消息队列。</p></blockquote><h2 id="闲话">闲话</h2><p>对于消息队列的选型，在国内环境中， RocketMQ 是一个强大的对手，网络上也有各种各样的对比和指导思想，有兴趣的读者可以自行搜索查看，在本文中并不会让这两者分个高下。</p><p>网络上林林总总的文档中，比较有参考意义的是 Apache RocketMQ 官方文档中的对比：<a href="https://rocketmq.apache.org/zh/docs/">Apache RocketMQ 5.0 中文文档</a>。</p><p>可以看到，相比之下RocketMQ 是一个更为“现代化”的消息队列中间件，原生支持了 Kafka 不具备的许多功能，同时也对 Kafka 已有的功能做了一些补充和改进。同时，从文中也可以看到 RocketMQ 相比 Kafka 有着“低延时”和“高可用”的优点，但 Kafka 相比之下拥有更高的“吞吐量”。</p><p>此外，官方文档中没有对两者的性能做出详细的说明，而阿里巴巴官方在外网发布了这篇文章作为补充：<a href="https://alibaba-cloud.medium.com/kafka-vs-rocketmq-multiple-topic-stress-test-results-d27b8cbb360f">基于 Topic 数量的性能压测</a>。</p><p>但是，就笔者的经验来说，在大部分实际的技术选型中，有以下三个“反直觉”的真相：</p><ol><li>许多细节上的差异并不会给项目带来明显的优势。举一个实际的例子来说：在绝大部分情况下，将接口响应时间从 10s 优化至 100ms，对比将响应时间从 100ms 优化至 1ms ，给用户带来的体感是完全不同的（后者远小于前者），同时付出的成本也是完全不同的（后者远大于前者）。</li><li>社区活跃度的重要程度往往被我们轻视——当你遇见问题的时候，更活跃的社区往往能给你带来更短的定位 / 解决时间。这里是一个自带活跃度对比的外网社区的统计结果：<a href="https://stackshare.io/stackups/kafka-vs-rocketmq">社区活跃度的对比</a>。从中可以看到，RocketMQ 在全球范围内的社区影响力远低于 Kafka。</li><li>不同的公司的技术选型思路有巨大的差异。举例来说，我在字节跳动工作期间，公司内部所使用的云平台是自研的“字节云”。在字节云中，从 Golang 的镜像，到云服务器的 Linux 内核，都是公司自研的——根据公司的实际情况做出了相应的优化。当时在云平台的官方文档中，基础架构的同学写下了一段大致如下的描述：“强烈推荐各业务方从 Kafka / BMQ 切换到 RocketMQ，当前字节云中的 RocketMQ 中间件从各方位对比前者都有显著的优势” —— 有时候，只需要这样一句话，就能打消业务方几乎所有的疑问和顾虑（同时也解决了 2 中所描述的社区问题）。</li></ol><p>总的来说，所有技术选型都应该基于实际情况进行决策。就像 CAP 定理和“软件工程没有银弹”一样，世界上没有完美的解决方案，到底是否应该“以牺牲部分吞吐量为代价，来获得 RocketMQ 同步刷盘的能力”，还是“它们都太差了，我要自研一款属于我的 MQ”，是需要根据实际业务场景来决定的。</p><p>而我现在所处的公司，在决策时面临的困难显然不那么强烈——我们使用亚马逊的 AWS 来部署服务，而 AWS 官方并没有提供基于 RocketMQ 的 Paas 服务，但 AWS MSK （Managed Streaming for Apache Kafka）已经相当成熟了，我们也就自然而然的选择了 Kafka 作为我们的消息队列，事实也证明，即便是和阿里一样同样置身在金融行业中，我们使用了所谓相比之下没有那么“高可靠、低延时”的 Kafka，也并没有给我们带来任何的困扰。</p><h2 id="正文">正文</h2><h3 id="基于-Golang-的-Kafka-SDK">基于 Golang 的 Kafka SDK</h3><p>相同的中间件在不同编程语言中的实现的 SDK 必然是有差异的，它们往往会根据语言自身的特点做出相应的适配和优化。我所采用的 sdk 是 segmentio 公司研发的 <a href="https://github.com/segmentio/kafka-go">kafka-go</a>，是 golang 中非常流行的一个库，也是适配得较好的一个库。</p><p>这个库的实现原理大致如下：</p><p><img src="/img/kafka-go/kafka-go-sdk.png" alt="kafka-go sdk"></p><ol><li>kafka-go 会向 Kafka Broker 拉取一定数量的消息放入内存中的 msg chan（该 chan 的缓存大小是可配置的）</li><li>然后应用程序通过调用 <code>FetchMessage</code> 方法来从这个 chan 中获取到一个消息并进行消费</li><li>当消费成功后，应用程序通过调用 <code>CommitMessages</code> 方法来提交 commit request</li><li>根据配置，kafka-go 会将 commit chan 中的请求立即提交，或将其 merge 合并为一个请求异步提交</li></ol><hr><h3 id="简单的阻塞消费模型">简单的阻塞消费模型</h3><p>最简单的消费模型其实和上面描述的过程是一致的，如下：</p><p><img src="/img/kafka-go/simple.png" alt="一次消费一条消息"></p><p>当消费成功时直接提交；当消费失败时，根据需要进行无限重试，或是直接丢弃（提交 commit 请求视为成功）。</p><p>常用 RocketMQ 的用户可以思考一下为什么我们一定要阻塞在某一条消息的处理上，为什么不能使用一个 <code>sync.WaitGroup</code> 来进行一定程度的并发呢？</p><p>曾经我在字节工作期间使用 RocketMQ 时，确实是这么做的，就像在接到 HTTP 请求后开启协程来处理一样，在接到消息后也开启协程进行处理。但这是建立在 RocketMQ 本身是支持消息重试的基础上的，当 RocketMQ 消息消费失败后，我们可以显示地向 RocketMQ 提交一个 <code>NACK</code> 请求来表明消息处理失败了，此时消息会被 RocketMQ 丢入重试队列中等待二次消费，当失败次数达到阈值后，会被其放进死信队列中，消息永远是不会丢失的。</p><p>但对于 Kafka 而言，它的提交行为是不区分 <code>ACK </code> / <code> NACK</code> 的，它的 commit 请求中只包含一个 <code>offset</code> 参数来标识当前消费者的消费进度。与此同时，kafka-go sdk 又在内存中将消息缓存到 chan 中，当我开启若干个协程调用 FetchMessage 方法时，获取到的消息是完全不同的。也就是说，当我开启三个协程处理三条消息时，可能分别在处理 offset = <code>1</code> / <code>2</code> / <code>3</code> 的 3 条消息，当 1 和 2 处理失败但 3 处理成功时，一旦将 3 commit 到 Kafka 中，1 和 2 就永久的丢失了（再也不会被消费了）。</p><p>这种模型虽然很简单，但也十分低效，适合的场景也非常有限，举几个实际的例子：</p><ol><li>新增 / 注销账号产生的消息。类似的场景下消息产生的 QPS 很可能 &lt; 1，因此使用该模型并不会造成性能瓶颈，反而在一定程度上可以提升开发效率。</li><li>需要使用顺序消费的场景。也就是说，在消费某条消息之前，必须消费完这条消息之前的所有消息，例如涉及到某些状态流转的场景，阶段 A 不能直接转换为阶段 C，而是必须经过阶段 B，此时我们需要顺序消费 A-&gt;B、B-&gt;C 这两条消息。</li></ol><hr><h3 id="高性能的批量消费模型">高性能的批量消费模型</h3><p>在 Kafka 不支持 <code>ACK</code> / <code>NACK</code> 的情况之下，如果我们仍需要保证消费的有序性，是不是就无法使用并发消费了呢？当然不是。接下来将介绍一种可配置、高并发的高性能消费模型：</p><h4 id="以-Partition-为维度并发">以 Partition 为维度并发</h4><p>熟悉 Kafka 架构的同学可能知道，Kafka 同一个 Topic 下的消息是分为多个 Partition 进行存储的，每个 Partition 中的消息都是按照投递的顺序进行排序的，也就是说，我们在消费同一个 Topic 的情况下，至少可以进行 Partition 维度的并发——就像在 RocketMQ 中，每个 Queue 中的消息是局部有序的。</p><p><img src="/img/kafka-go/by_partition.png" alt="根据 partition 并发处理"></p><p>在这种模型中，我们需要做的主要有两件事：</p><ol><li>实现一个简单的 Dispatcher，根据 Kafka Message 的 Partition 进行分组后，将这条消息投入对应 Partition 的 chan 中</li><li>实现一个通用的 Worker，用于处理 Partition Chan 中的消息</li></ol><p>以下是我写的一段核心代码：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> KafkaConsumer[T msgtype.KafkaMessage] <span class="hljs-keyword">struct</span> &#123;callback           <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(msgs ...T)</span></span>partitionMsgs      <span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-keyword">chan</span> TpartitionQueueSize <span class="hljs-type">int</span>minBatchSize   <span class="hljs-type">int</span>maxBatchSize   <span class="hljs-type">int</span>forceFlushTime time.DurationcloseCh <span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *KafkaConsumer[T])</span></span> Run() &#123;<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;log.Info(<span class="hljs-string">&quot;kafka consumer started&quot;</span>)<span class="hljs-keyword">for</span> &#123;msg := c.fetchMsg()<span class="hljs-comment">// 优雅退出</span><span class="hljs-keyword">select</span> &#123;<span class="hljs-keyword">case</span> &lt;-c.closeCh:log.Info(<span class="hljs-string">&quot;kafka consumer stopped&quot;</span>)<span class="hljs-keyword">return</span><span class="hljs-keyword">default</span>:&#125;c.parallelHandle(msg)&#125;&#125;()&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *KafkaConsumer[T])</span></span> Stop() &#123;<span class="hljs-built_in">close</span>(c.closeCh)&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *KafkaConsumer[T])</span></span> parallelHandle(msg T) &#123;partition := msg.RawMessage().Partition<span class="hljs-keyword">if</span> _, ok := c.partitionMsgs[partition]; !ok &#123;c.startPartitionHandler(partition)&#125;c.partitionMsgs[partition] &lt;- msg&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *KafkaConsumer[T])</span></span> startPartitionHandler(partition <span class="hljs-type">int</span>) &#123;<span class="hljs-comment">// 初始化分区消息队列</span>c.partitionMsgs[partition] = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> T, c.partitionQueueSize)<span class="hljs-comment">// 启动分区消费者</span><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;flushTimer := time.NewTimer(c.forceFlushTime)<span class="hljs-keyword">for</span> &#123;msgBatch := <span class="hljs-built_in">make</span>([]T, <span class="hljs-number">0</span>, c.maxBatchSize)<span class="hljs-comment">// 先取一条消息, 避免直接进入计时</span>msgBatch = <span class="hljs-built_in">append</span>(msgBatch, &lt;-c.partitionMsgs[partition])flushTimer.Reset(c.forceFlushTime)<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<span class="hljs-keyword">for</span> <span class="hljs-built_in">len</span>(msgBatch) &lt; c.maxBatchSize &#123;<span class="hljs-keyword">select</span> &#123;<span class="hljs-comment">// 超时退出</span><span class="hljs-keyword">case</span> &lt;-flushTimer.C:<span class="hljs-keyword">return</span><span class="hljs-comment">// 接收到新的 msg</span><span class="hljs-keyword">case</span> msg := &lt;-c.partitionMsgs[partition]:msgBatch = <span class="hljs-built_in">append</span>(msgBatch, msg)<span class="hljs-comment">// 暂时没有新的消息到来，但也尚未超时，此时缓存的消息若满足最小接收量则退出</span><span class="hljs-keyword">default</span>:<span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(msgBatch) &gt; c.minBatchSize &#123;<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 再次 select, 避免空转</span><span class="hljs-keyword">select</span> &#123;<span class="hljs-keyword">case</span> &lt;- flushTimer.C:<span class="hljs-keyword">return</span><span class="hljs-keyword">case</span> msg := &lt;-c.partitionMsgs[partition]:msgBatch = <span class="hljs-built_in">append</span>(msgBatch, msg)&#125;&#125;&#125;&#125;()<span class="hljs-comment">// callback 中根据业务自行实现重试保证成功或是 drop</span>c.callback(msgBatch...)c.CommitMessages(msgBatch...)&#125;&#125;()&#125;</code></pre></div><p>可以看到，在实际的代码实现中，会加入许多额外的细节来提供健壮性，其中使用了 <code>map[int]chan T</code> 结构来维护消息的分组过程，也就是实现了上述的 <code>Dispatcher</code>。除此之外，在 <code>startPartitionHandler(int)</code> 方法中，以异步的形式实现了前文中的<code>Worker</code>。</p><p>在 Worker 的具体实现中，我使用了 3 个可配置的选项来根据实际情况动态的调控消费行为，分别是：</p><ol><li><code>forceFlushTime</code> ，每次处理消息前最大的循环时间——防止一直接收不到足量的消息而阻塞</li><li><code>maxBatchSize</code>，每次批量处理消息的最大数量——防止一次性接收过多消息</li><li><code>minBatchSize</code>，每次批量处理消息的最小数量——某些时候上游已经暂时不再产生消息，此时为了避免持续空转到超时，可以提前返回</li></ol><hr><h4 id="从单条转向到批量处理消息">从单条转向到批量处理消息</h4><p>从上面的 <code>KafkaConsumer</code> 中可以看到，我们对于消息的处理从单条转向了批量。在批量处理的过程中，我们需要保证所有消息都处理成功后（至少是业务上认为处理成功），再返回成功，常见的处理方式就是无限重试。在处理完一批消息之后，我们需要批量的提交消息，kafka-go 本身就提供了批量处理消息的函数，但是我们也需要进行一些合理的封装来实现如下功能：</p><ol><li>给 kafka 对应的 partition 提交 offset</li><li>合理拆分消息数组，避免一次性提交的消息大小超过 kafka 的配置限额</li><li>对 kafka 的连接进行合理的检测</li></ol><p>伪代码如下：</p><div class="code-wrapper"><pre><code class="hljs go"><span class="hljs-keyword">type</span> KafkaPartitionProducer[T msgtype.KafkaMessage] <span class="hljs-keyword">struct</span> &#123;brokers   []<span class="hljs-type">string</span>topic     <span class="hljs-type">string</span>partition <span class="hljs-type">int</span>conn      *kafka.Conncodec     *kafka.CompressionCodeclogger *logrus.Entry&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pp *KafkaPartitionProducer[T])</span></span> ProduceMust(msgs ...T) &#123;<span class="hljs-keyword">if</span> pp.codec == <span class="hljs-literal">nil</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;codec is nil&quot;</span>)&#125;<span class="hljs-keyword">if</span> pp.conn == <span class="hljs-literal">nil</span> &#123;pp.connectMust()&#125;<span class="hljs-comment">// 构造 kafka 消息</span>kmsgs := <span class="hljs-built_in">make</span>([]kafka.Message, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(msgs))<span class="hljs-keyword">for</span> _, msg := <span class="hljs-keyword">range</span> msgs &#123;kmsg := pp.buildKafkaMessage(msg)<span class="hljs-keyword">if</span> kmsg == <span class="hljs-literal">nil</span> &#123;<span class="hljs-keyword">continue</span>&#125;kmsgs = <span class="hljs-built_in">append</span>(kmsgs, *kmsg)&#125;<span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(kmsgs) == <span class="hljs-number">0</span> &#123;pp.logger.Warn(<span class="hljs-string">&quot;no messages to produce&quot;</span>)<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 无限重试直到发送成功</span><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; ; i++ &#123;nbytes, _, offset, _, err := pp.conn.WriteCompressedMessagesAt(*pp.codec, kmsgs...)<span class="hljs-keyword">if</span> err == <span class="hljs-literal">nil</span> &#123;log.Infof(<span class="hljs-string">&quot;write compressed messages success&quot;</span>)<span class="hljs-keyword">break</span>&#125;<span class="hljs-keyword">switch</span> err &#123;<span class="hljs-keyword">case</span> kafka.MessageSizeTooLarge:log.WithError(err).Errorf(<span class="hljs-string">&quot;kafka message size too large&quot;</span>)<span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(kmsgs) &lt;= <span class="hljs-number">1</span> &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;kafka message size too large&quot;</span>)&#125;<span class="hljs-comment">// 消息过多对半递归重发</span>mid := <span class="hljs-built_in">len</span>(kmsgs) / <span class="hljs-number">2</span>pp.ProduceMust(msgs[:mid]...)pp.ProduceMust(msgs[mid:]...)<span class="hljs-keyword">default</span>:<span class="hljs-comment">// 其它错误直接重连</span>log.WithError(err).Errorf(<span class="hljs-string">&quot;failed to write compressed messages&quot;</span>)pp.connectMust()&#125;&#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(pp *KafkaPartitionProducer[T])</span></span> connect() <span class="hljs-type">error</span> &#123;<span class="hljs-keyword">if</span> pp.conn != <span class="hljs-literal">nil</span> &#123;pp.conn.Close()pp.conn = <span class="hljs-literal">nil</span>&#125;<span class="hljs-keyword">for</span> _, addr := <span class="hljs-keyword">range</span> pp.brokers &#123;log := pp.logger.WithField(<span class="hljs-string">&quot;addr&quot;</span>, addr)ctx, canceler := context.WithTimeout(context.Background(), <span class="hljs-number">5</span>*time.Second)<span class="hljs-keyword">defer</span> canceler()<span class="hljs-comment">// 连接到指定 broker 的 topic / partition</span>conn, err := kafka.DialLeader(ctx, <span class="hljs-string">&quot;tcp&quot;</span>, addr, pp.topic, pp.partition)<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;log.WithError(err).Errorf(<span class="hljs-string">&quot;failed to dial leader for partition&quot;</span>)<span class="hljs-keyword">continue</span>&#125;<span class="hljs-comment">// 测试 kafka 连接是否正常</span>first, err := conn.ReadFirstOffset()<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;log.WithError(err).Error(<span class="hljs-string">&quot;failed to read first offset&quot;</span>)conn.Close()<span class="hljs-keyword">continue</span>&#125;last, err := conn.ReadLastOffset()<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;log.WithError(err).Error(<span class="hljs-string">&quot;failed to read last offset&quot;</span>)conn.Close()<span class="hljs-keyword">continue</span>&#125;log.WithFields(logrus.Fields&#123;<span class="hljs-string">&quot;first&quot;</span>: first,<span class="hljs-string">&quot;last&quot;</span>:  last,&#125;).Info(<span class="hljs-string">&quot;dial conn success&quot;</span>)pp.conn = conn<span class="hljs-keyword">break</span>&#125;<span class="hljs-comment">// 没有可用的 broker 连接</span><span class="hljs-keyword">if</span> pp.conn == <span class="hljs-literal">nil</span> &#123;pp.logger.WithField(<span class="hljs-string">&quot;brokers&quot;</span>, pp.brokers).Error(<span class="hljs-string">&quot;failed to dial leader from all brokers&quot;</span>)<span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;failed to dial leader for partition %d&quot;</span>, pp.partition)&#125;<span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>&#125;</code></pre></div><hr><h4 id="消费过程的流水线">消费过程的流水线</h4><p>考虑到 Kafka 的消费过程本质上也是一个不同流程的串联，于是我们可以在消费过程上进一步的进行优化。</p><p>举例来说，我们的消费需要进行如下几个步骤：</p><ol><li>消息内容解析，例如有的消息里面包含紧凑的二进制数据，需要进行反序列化等操作才能被程序继续处理</li><li>风控检查，拒绝掉不合理的消息</li><li>日志记录，记录消息的来临</li><li>业务处理，根据消息的内容进行业务处理</li><li>落库，将消息的处理结果落库</li></ol><p>不难发现，其中可能有的步骤并不强烈依赖顺序处理，而有的步骤又需要。</p><p>假设我们基于前面的消费模型构建了我们的应用，那么在合理配置 Kafka 的硬件和配置参数的情况下，瓶颈将很容易的出现在上面这个消费过程上。</p><p>这里列举一个极简的优化方案：</p><ul><li>我们在每一步中都使用 golang 的 <code>chan</code> 进行解耦，比如 1 处理完之后通过 <code>chan</code> 传递给 2 继续处理。</li><li>而前面的每一个数字序号，都是一个单独的 <code>goroutine</code>，仅仅通过 <code>chan</code> 来接收消息。</li><li>然后对于首尾的两个环节进行特殊处理<ul><li>首个环节需要接入 Kafka，真正的从 Kafka 中拉取消息</li><li>末尾环节需要将处理结果落库后，向 Kafka 提交 offset</li></ul></li></ul><p>如此一来，我们便可以实现所谓: “业务处理第一条消息时，我们的程序已经开始解析并反序列化第二条消息了”。<br>于是我们在消费过程中的吞吐量将会得到极大的提升。</p><p>当然，也有另外一种粗暴的方案，就是使用多个 <code>goroutine</code> 来批量消费一批消息，然后 <code>wg.Wait()</code> 等待所有消息处理完毕后再提交 offset。这种方案的优势在于实现简单，但是劣势在于无法保证消息的有序性，需要业务方自行保证消息的幂等性。</p><h2 id="后话">后话</h2><h3 id="Consumer-Group">Consumer Group</h3><p>Kafka 的 Consumer Gourp 离不开 Rebalance 机制，所谓 Rebalance 指的就是将一个 Topic 下若干 Partition 通过协商的过程平均分配给同一个 Consumer Group 中不同 Consumer 的过程。也就是说，一个 Partition 只能被一个 Consumer Group 中的一个消费者消费，也就让我们可以容易的实现局部顺序消费，配合上 Producer 端的少许逻辑，就可以达成业务上的顺序性。</p><p><img src="/img/kafka-go/kafka-consumergroup.png" alt="consumer group 与 partition"></p><p>在上图中，以订单的流转为例，只需要 Producer 在生产消息时根据订单 id 分配固定的 Partition 有序的发送消息（如对于订单221，将发起订单、流转订单、完成订单三个操作依次发送到 P1 中），下游的 Consumer 就能保证同一个订单的消息被按序处理，因为同一个 Partition 中的消息不会同时被两个 Consumer 消费。</p><p>但是有些极端的情况仍可能导致重复消费的错误，例如 C1 在消费完「发起订单」后，还没来得及 Commit 就挂掉了，Rebalance 后 C2 或 C3 又会重新接收到该消息，并尝试再次发起订单，因此业务方自行保证消息消费的幂等性是十分有必要的。</p><hr><h3 id="Ack-Insync">Ack &amp;&amp; Insync</h3><p><strong>Ack 的种类:</strong></p><ul><li><code>Ack = 0</code>，producer 不需要等待任何 broker 确认收到消息的回复</li><li><code>Ack = 1</code>，producer 只需要等待 leader broker 确认收到消息的回复</li><li><code>Ack = all</code>，producer 需要等待所有 min.insync.replicas 确认收到消息的回复</li></ul><p><strong>Insync:</strong><br>in-sync replicas (ISR) 是指能够与主节点保持同步的副本集合。这些副本需要持续跟踪主节点上的最新写入消息，并将其应用到自己的日志中。</p><p>为了避免消息写入消息后，主节点立即宕机导致的消息丢失问题，我们一般会配置 <code>min.insync.replicas</code> 参数，然后协同使用 <code>Ack = all</code> 来保证消息写入多个节点才确认。</p><p><strong>配置思路:</strong></p><p>$$<br>replication\ factor=min.insync.replicas+N<br>$$</p><p>上述公式能够保证我们在 N 个节点宕机的情况下，仍然能够保证系统的可用性。</p><p>举例来说，假设我们需要让某个 topic 的消息至少被 3 个节点保存（一主两从），此时我们能够接受一个（主）节点宕机，那么 <code>min.insync.replicas</code> 为 2。<br>这也就是我之前在加密货币交易所的交易系统团队工作时，内部默认的配置。（这里再次提醒，我们需要使用 <code>Ack = all</code> 才能与上述配置协同工作保证消息可靠）。</p><p><strong>抄答案:</strong></p><table><thead><tr><th>configuration item</th><th>value</th><th>type</th><th>explain</th></tr></thead><tbody><tr><td>unclean.leader.election.enable</td><td>false</td><td>brokers</td><td>disallow unclean leader election</td></tr><tr><td>replication factor</td><td>3</td><td>topic</td><td>we need to have at least 3 replicas</td></tr><tr><td>min.insync.replicas</td><td>2</td><td>topic</td><td>we need to have at least 2 in-sync replicas</td></tr><tr><td>ack</td><td>all</td><td>producer</td><td>we need to wait for all in-sync replicas to acknowledge the message</td></tr><tr><td>block.on.buffer.full</td><td>true</td><td>producer</td><td>we need to block when the buffer is full</td></tr><tr><td>broker cnt</td><td>4</td><td>brokers</td><td>we need to deploy 4 brokers</td></tr></tbody></table><p><strong>吞吐量 vs 延迟:</strong></p><blockquote><p>除上述之外，还有部分用于提升 Kafka 消费吞吐量的配置（注意，提升吞吐量的同时往往都会造成延迟的增加，请根据业务选择）</p></blockquote><ul><li>producer<ul><li><code>linger.ms</code>, default 0, 消息在缓冲区中的停留时间, 增大该值可以等待更多消息加入批次，提高吞吐量，但也会增加延迟。</li><li><code>batch.size</code>, default 16KB, 一次批量发送消息的大小, 增大该值可以减少网络开销，提高吞吐量，但也会增加延迟。</li><li><code>buffer.memory</code>, 生产者本地缓冲区大小, 用于存储待发送的消息。适当增大可以提高吞吐量，但过大会增加内存使用风险。</li></ul></li><li>broker<ul><li><code>socket.send.buffer.bytes / socket.receive.buffer.bytes</code>, 控制生产者与代理、代理与消费者之间的网络缓冲区大小（默认值 100 KB）。</li><li><code>log.segment.bytes</code>, 日志分段文件大小。适当增大可以减少文件数量，提高磁盘写入性能，但也会增加延迟。</li><li><code>log.buffer.size</code>, Kafka 日志文件缓存大小，与底层 I/O 性能相关。</li></ul></li><li>consumer<ul><li><code>fetch.min.bytes / fetch.max.bytes</code>, 定义消费者每次拉取的最小/最大数据量，增大可以减少请求次数，提高吞吐量。</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>tech</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Golang</tag>
      
      <tag>Kafka</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Career 2023</title>
    <link href="/career/career_2023/"/>
    <url>/career/career_2023/</url>
    
    <content type="html"><![CDATA[<blockquote><p>今天是 2023 年 4 月 26 日，是我在字节跳动的第 <u><em><strong>1046</strong></em></u> 天。</p></blockquote><h2 id="平淡的学生时代">平淡的学生时代</h2><p>和大多数人一样，我的学生时代没有做出什么出彩的成就，没有参加过任何竞赛，也没有去争取过保研资格，毕业论文也和优秀毫无关联。</p><p>和大多数人不一样的是，我没有参加过大学的开学典礼，也没有参加过大学的校运会，甚至在毕业的时候连张毕业照也没去拍，领完毕业证就走了。</p><p>但是从某些角度来看，也许，<u>只是说也许</u>，做的还算不错——从没有名牌大学的江西省考入了985、选择了计算机专业、毕业就加入了字节跳动。</p><p>其实客观的来看，这也不是什么特别“不错”的事情，尤其是当你身处这座围城的时候更是如此。在成都，电子科大在计算机专业有更响亮的名声；在业内，字节跳动也有不少同事在往外看更好的机会。</p><p><u>总而言之，选择计算机行业这件事，是我至今都很少去反思、怀疑的，想必未来也是如此。</u></p><p>川大是一个包容的学校，条条框框很少，至少对我来说是这样，我的大学四年基本都是过着“放养式”的生活。学校给的约束不多，引导也不多，所以我的选择更多的还是围绕一些自己偶然预见的机会，以及友好的同学/学长/学姐抛出的橄榄枝来进行决策的。</p><p>其实在我身处川大的四年的经历中，能称之为 Milestone 的事情并不多，主要是以下几个：</p><ol><li>大一上学期的「数字逻辑」课，期末总分是 63 分。</li></ol><p><img src="/img/career_2023/grade.png" alt="我的大一上学期期末总成绩"></p><ol start="2"><li>大二上学期开始学习Java，并决定以它作为自己的主要语言。</li><li>大二上学期在室友的帮助下进入了「403 实验室」。</li></ol><p><img src="/img/career_2023/lab403.png" alt="403实验室"></p><ol start="4"><li>大二下开始决定备战 2020 年的春招实习。</li></ol><p>数字逻辑这门课就像是浇灭我初入大学校园热情的第一盆冷水（后面还有汇编语言，微机系统等… …），双语的教学模式让人猝不及防，闻所未闻的「门」让人摸不清楚头脑，甚至在期末考试前的几次课前小测验，我都不知道要算在期末的总分当中。看到期末成绩的那一刻，我第一反应就是<u><em><strong>“我肯定不能保研了”</strong></em></u>。—— 这也难免为后续出来找工作打下了心里基础。</p><p>大二上学期学了 Java 之后（在大一学的是C/C++），第一次见到“集合类 Collections”，发现写代码变的简单了，也就提起了对编程的兴趣。当时正好在学计算机网络这门课程，老师讲到 DHCP 协议的时候，我就联想到川大的校园网 SCUNET 经常登陆不上去，后来发现是 IP 池不足以给上下课人员高峰期的每个同学使用，就用 Java 写了个抢校园网的工具，给当时 Java 程序设计协会的同学使用了一段时间，后来也被一个学弟拿去改了改放 Github 上了，<a href="https://github.com/Stevewy/NetworkAssistant">代码在这里</a>。这里顺便感谢学校的前辈总结的 SCUNET 前世今生，这篇博客的详细程度至今都令我叹为观止，想必是耗费了大量心血制作而成，<a href="https://scunet.syaoran.top/">传送门在此</a>。</p><p>在大二上学期的时候，我在一个同寝的室友的帮助下进入了一个计算机社团，当时叫做「四川大学Java程序设计协会」，这个协会配有一个很大的实验室，其实就是一个有空调有大型办公桌的机房，甚至还可以在里面抽烟🚬。当时在这个实验室里面遇到了几个同级的同学，还有几个学长学姐，他们教了我不少关于 SSM 开发的知识；但我觉得更重要的是，在很多同学每天早起去图书馆占座的时候，我有了一个更好的硬件环境，可以帮助我心无旁骛的学习。</p><p>大二下学期是个转折点，四年的大学生涯已经过去了<code>3/4</code>，之所以这么说是因为当时我们都倾向于尽量在前三年修完所有必修课，以及凑够毕业所需要的学分。所以在当时，大家对自己能否保研/出国，心里都有了个底，我就是那一类“不能保研，又不想考研”的人。而且当时在403实验室，有一个比我大一届的学长已经拿到了拼多多的 offer，所以也算是有了个目标，就这么开始了几乎为期一年的长跑。其实当时准备的也不见得有多好，但倒确实是坚持了整整一年。</p><p>春招的结果是挺圆满的，可能是因为当时<u><strong>大环境比较好</strong></u>，最后拿到了一个成都字节跳动的 offer，还有一个杭州阿里巴巴企业智能事业部的 offer。最后我还是因为舍不得成都，就选择去了字节，20 年 6 月份以实习生入职，同年 10 月通过了转正答辩。顺带一提的是，阿里的那个部门，在当时不久后的未来就开发出了全国都在用的「支付宝健康码」。</p><p>补充一个很真实的帖子截图：</p><p><img src="/img/career_2023/zhihu.jpeg" alt="&quot;知识改变命运&quot;"></p><p>20-23 年互联网行业的形势真是潮起潮落。</p><h2 id="“Always-Day-1”-to-Day-1046">“Always Day 1” to Day 1046</h2><p>2020 年 6 月 15 号我以实习生的身份加入了字节跳动，那个时候我所在的部门叫做 EE —— Efficiency Engineering，翻译过来就是「效率工程」，主要是负责字节跳动内部效能工具的开发，比如字节自研的一整套 People 应用 —— 涵盖了 OKR、CoreHR（人事系统）、招聘系统和薪酬系统等，当然还有一些横向的工具，比如 aPaaS 低代码平台等。那时候整个大部门的 Slogan 让我印象很深刻：“<u><em>以字节跳动为实验对象，以敏捷为理念，学习优秀企业的实践，开发、改变现代企业交流沟通和业务开展效率的工具系统。</em></u>”</p><p>我的团队是负责招聘系统的，内部代号 ATSX，即 Application Tracking System X。当时团队还不大，后端一共二三十人，产品也还没有商业化，我进去的时候，我们的产品正处在商业化的前夕（同年年底完成的商业化），所以当时从 6 月到 11 月的这段时间，团队内的业务还是非常繁忙的，后来为了冲刺，团队内还喊出了“决战 930” 和 “再战 1031” 的口号。</p><p>顺带一提的是，当时互联网的形势还算不错，一共二三十人的后端团队内，包括我在内有大概 6，7 个实习生 —— 后来我是唯一转正并留下来的。</p><h3 id="“艰难”的转正之路">“艰难”的转正之路</h3><p>之所以称转正“艰难”，一是因为同批的 6，7 个实习生中只有两人通过 —— 除我之外的另一个女生后来没有选择留下来；二是因为当时正常的同学一般在实习三个月之后就会发起转正答辩，我花了整整四个半月才将整个流程走完。</p><p>我是怎么通过转正的？概括来说，是遇见了一些同批次同学没遇见的机遇，换成俗套的句式来描述，就是运气好：性格和 Leader 很对付、需求交付的也比较及时。</p><p>在我刚加入团队的时候，团队内部有一个新人 landing 必须要做的事情，就是在熟悉自己组内的业务一个月后，写一篇串讲文档，再约一个很大的会议室邀请组内所有同学来旁听。你需要一篇详细的文档来描述你所负责的业务，然后在有限的时间内讲解完文档上的所有内容，并且过程中你需要回答任何同学对你提出的问题 / 质疑，过程中你的 Leader / Scrum Master / Mentor 会在你的文档上留言记录全过程。只有串讲通过的实习生同学，才会开始被安排业务需求，否则只有做一些横向的/业务无关的任务；如果串讲失败，则需要在会后修改文档然后找时间再次发起会议。</p><p>当时串讲的严格程度令我汗颜，简单来说，串讲的考核是打分制的，准确的说是“扣分制”，过程中每答错一个问题就扣 10 分，低于 60 分就宣告失败。一次串讲的时长从 30 分钟到一个小时不等，参与的人数从 10 到 20 人不等，形形色色的问题个数也从 5 到 10 个不等。最令人感到窒息的是，同学们问出的问题往往都是你的串讲文档以外的内容，时而上浮到业务逻辑，时而下潜到服务使用的 RPC 框架、中间件、数据库表设计的理念，甚至还有云平台的配置和 Golang 的基础知识。当时同一批的实习生，有连续两次串讲失败的，我在一旁看得焦虑无比。</p><p>后来我在两位 Leader 的支持下跳过了串讲的流程直接进入了转正答辩环节，并且答辩环节也是所谓“走个过场”，不过那都是后话了。</p><p>我进来的第二周，我的 Leader 就给我安排了一个对新人不太友好的任务 —— 写一个飞书机器人来追踪代码上线前后的一些发布流程，将他每次发布时需要做的很多人工操作进行自动化。之所以说不友好，是因为作为一个大学生（也可能只是我自己），其实在面对陌生的工业环境时，很难立马融入到一些“平台化”、“标准化”的流程中去。具体来说，就是阅读飞书开放平台的服务端文档对当时的我而言是一件很困难的事情，这倒不是因为那些文档写的有多么晦涩难懂，而是在于让你在毫无实践经验的情况之下，只通过阅读文档来进行一些开发工作。这个问题稍一延伸，就变化为：“从理论跨越到实践”。</p><p>幸运的是，飞书团队在 Github 上开源了一套机器人的 SDK，简化了不少基于 OAuth 2.0 的应用鉴权流程；并且在武汉一位同事的帮助下，通过一些非常 trick 的方式赋予了机器人用户身份 —— 让机器人使用我 Leader 的身份来操作云文档；与此同时，字节内部对网络隔离的要求还不是那么严格，我可以方便的把编译出来的可执行文件直接部署运行在我个人的开发机上，省去了不少关于服务部署的学习成本。最后这个机器人成功的跑了起来，虽然内部的实现非常简陋，就连很多持久化的功能都是直接依赖于开发机上部署的 redis 来做的。</p><p>总结来说，站在现在的角度来回顾当时短短一周的过程，有两件事是比较重要的：</p><p>第一是打开思路：xx 平台提供了官方文档，我们未必就一定要按照这个文档去做对接，在这个具体的例子里是恰好飞书团队官方就开源了一套 SDK，即使没有官方的 SDK，我们也大概率能够在网络上找到别人封装好的轮子。当然上面这个例子只是一个具体现实的映射，我们还有很多别的场景不适用于上面这个具体的解决思路，重要的事情是不要局限于问题的表象、现有的解决思路可能是一种束缚。</p><blockquote><p>这里稍微展开一下，我在字节跳动听过几次<a href="https://baike.baidu.com/item/%E6%9D%A8%E9%9C%87%E5%8E%9F/55833965">震原</a>的分享，其中有一个分享的主题叫做《工程师成长的真相：“成长是自己的事情”》，里面他举了一个例子，也是他早期在百度期间听<a href="https://baike.baidu.com/item/%E7%8E%8B%E5%A4%A2%E7%A7%8B/10198826">王梦秋</a>分享的：捕鼠器案例的启示。</p><p>简单来说，当你被安排了一个“优化捕鼠器🪤”的任务来提升捕鼠效率之后，你可能会 focus 在捕鼠器本身去优化物理结构，然后在一段时间后就达到瓶颈；但是后来你可能会发现任务的目标在于灭鼠，于是你下一步会想到舍弃捕鼠器而转为使用灭鼠药，于是你又开始 focus 在灭鼠药的配方和投放位置上；最后你会发现老鼠没了之后也保护不了粮食，因为你的粮仓时常漏水；step by step，你可能会将你的目标转移到「粮食保护」这件事情上去，制定具体的粮食保护评估指标，然后你可能会成立“粮食保护小组”，最后上升到更高层面的“政策”、“法律法规”上去，最后可能在国家层面就形成了粮食保护局，或者世界范围内的粮食保护组织，就像 WTO 这些组织一样。</p></blockquote><p>第二是主动寻求帮助，如果确实觉得文档对于当前阶段的你是晦涩的，坚持一段时间也无果，那么不妨去问问前辈，我们常说“不耻下问”，在这里对应的是“不畏上问”。我当时在飞书上点开了我们行政群的一个“提醒你按时吃饭”机器人的详细信息，在里面看到了开发者是 xx 同学，我就直接小窗私聊那位同学请教机器人的开发细节了。First thing first，大多数时候解决问题比较重要，个人的想法、情绪先摆到一旁，解决问题带来的正反馈与自己克服自己的心理障碍所造成的损耗，这二者综合起来的数学期望往往都是 &gt; 0 的。</p><blockquote><p>这里也稍微展开说一说，在上面引文中震原的分享中还有一点，就是“成长是自己的事情”，这里震原想表述的主要是你要有自己的目标，有了明确的目标之后，那么你身边的人和物都是资源。你的 Leader 是资源，你的同事也是资源，站在这个视角来看，公司也就是组织资源的一种形式，能够通过一些“权威”的方式来降低交易成本。那么对应到这个例子中，我就是利用了飞书机器人的 profile 详情页查看到机器人的作者，然后利用飞书提供的方便快捷的“视频通话”的资源，来触达到身在武汉的机器人作者这个资源，最后利用这个资源完成了我的目标。</p></blockquote><h3 id="转正后的长期迷茫">转正后的长期迷茫</h3><p>2021 年 7 月，我结束了为期一年的实习，无缝衔接到正式工作中去。</p><p>从 7 月到第二年的 3 月，我都处在一个长期的迷茫过程中。22 年 3 月之后其实也只是略有改善，并没有好多少，直到 22 年的 6 月我才真正结束了为期一年的迷茫。</p><p>之所以称那段时间为迷茫，是因为那段时间迷茫的太过明显 —— 没有目标，也没有压力，完全是听从别人的安排去做事，做的事情也非常简单。</p><p>具体地说，别人都在做业务需求的时候，我在做杂活，别人当项目 Owner 的时候，我在里面打辅助，而且辅助的不见得有多好。</p><p>之所以会这样，主要有两方面原因：</p><p>一是个人原因。初入职场的同学往往没有明确的目标，总是被动的去解决问题；在高一层的 level 上缺乏思考，或是想不清楚，亦或是想清楚了但懒得解决，也可能是不敢提出来解决，于是就形成了一种“高不成低不就”的状态。我当时就是如此，虽然在团队内有一年的实习经历，对流程和套路都比较熟悉，但也仅限于此。我当时没有主动的去研究组里的服务代码，所以对不是自己负责的业务不熟悉，也没有主动的去研究团队的服务架构，导致对系统流量的链路不熟悉。</p><p>体现到实际工作中最明显的一点就是，每当线上用户对业务提出咨询时（招聘系统作为一个 B 端的产品，虽然技术架构做的没有 C 端深，但其功能逻辑异常复杂，有时甚至需要专门的同学给客户进行培训后才能投入使用），我都是一头雾水，会直接将别的同学拉入咨询群中帮我解答。更严重的是，有时线上出现了故障，我都不清楚如何排查。</p><blockquote><p>这里说一件真实发生的故事，现在的大部分业务都是由多个微服务组成的，我们团队也不例外；在团队内我们细分了多个小组，简称 Scrum，每个 Scrum 会负责一到三个微服务。当时作为新人，我养成了一个非常狭隘的视角 —— 我只要关注自己组里的一到两个微服务的代码仓库就行了。</p><p>有一次接到需求之后去找我的 Leader 询问如何开发，他告诉我相关的代码在 xxx 服务的代码仓库里面，然后顺手就要在我的电脑上打开那个仓库，想直接一口气帮我找到相关文件。然后他找了半天发现我压根就没有拉过那个仓库的代码到我电脑上，没忍住吐槽了我几句。</p></blockquote><p>那么为什么会这样呢，直接因是自己对于工作的 Scope 圈的太小，终极因是自己没有明确的目标。</p><p>二是团队原因。团队始终处于一个高速成长的阶段，时至今日也是如此，团队一直在面临的不仅仅是层出不穷的新需求，更多的是过于追求高速度而欠下的技术债。团队如何应对上面的情况不是这里的关注点，重要的是当时确实缺乏一些对于新人的引导，大家都在忙自己手上的活，Leader 那边没有给我制定明确的发展计划，我自己也没意识到这一点 —— 最后就好像一只被放养的羊，自娱自乐，自给自足。</p><p>总的来说，作为一个新人，我并没有想清楚自己要什么，也就没有利用任何的资源来达成任何目标。也许大多数人在一开始的时候都会面临这样的窘境，但我不知道我让这种情况持续了接近一年的时间，是不是超过了同批次同学的中位数。</p><h3 id="向“独当一面”出发">向“独当一面”出发</h3><p>直到 22 年的 3 月，这个情况才略有改善，改善的直接因是组里有个关系很好的同事 w 晋升了，想缓一缓，然后把后续的一些需求交给我来当 Owner。说到这里还是要感谢 w 同学，我当时负责的第一个需求，连方案都是他预先帮我出好的，而且开发过程中他的贡献的代码量并不比我低。</p><p>虽然是被动的，但好在整个需求交付的过程和结果都还不错。被动的被推上战场，并不代表过程中的事情都会变的格外艰难，跨团队沟通、对交付风险的把控、项目整体 Milestone 的制定对于没有经验的人来说虽然有挑战，但是“hone by doing（事上磨炼）”的感觉也会给人带来不少的正反馈。不过比较特殊的是，我做的这个需求本身可能和业务不太挂钩，还是偏横向，而且当时也因为个人的一些情况导致有些不在状态；但总的来说，这件事是个开始，多少改善了大家对我的印象，也为后续逐渐成长为“业务主要支撑同学”打下了基础。</p><p>22 年的 6 月，我接到了第一个需要我独立完成的较大的业务需求，业务的复杂度很低，总的来说就是批量勾选一些实体，然后将实体上挂的一些文件进行打包导出，然后用户就可以把这个包下载下来，也就是一个批量的文件下载功能。需求虽然简单，但是当时我们团队并没有一个好的流处理文件的解决方案，现成的方案都是需要借助容器里的本地磁盘作为介质来存储中间产物的，也就是会先把源文件下载下来到 <code>/tmp</code> 文件夹中，然后压缩成一个 <code>xx.zip</code> 压缩包，也存在 <code>/tmp</code> 文件夹中，最后再把压缩包进行上传。所以当时我从技术的视角出发，写了一个基于 Golang 的流式「下载-压缩-上传」的 SDK，只需要在在两个流的对接处留下一定大小的 Buffer，就可以实现完整的多文件传输链路，而无需依赖硬盘来保存中间文件，这个 SDK 完成后也得到了很多需求的服用，目前已经是团队内的一个标准解决方案了。</p><p>我想说的是，这可能和字节范里的“追求极致”没有太大的关系，而更多的是作为一个工程师的工程素养的问题。你需要敏锐的意识到现有方案的种种问题，然后评估其风险，接着思考是否有更优解，以及更优解是否有业界成熟的经验可以复用，最后盘点其 <code>ROI</code> 是不是足够的高，同样关键的是，这个过程需要在有限的时间内完成。听起来可能会很困难，事实上也确实不简单，要做好这些事情确实需要一些时间的沉淀，需要丰富的经验，对于新人来说确实不够友好。</p><blockquote><p>时间管理是永恒的话题，每个人的时间都是有限的，工作时间的很大一部分都会花在工作本身，留给自己沉淀积累的时间永远不会太多，关于改进的方式，可以参照「<a href="https://wiki.mbalib.com/wiki/5%E5%B0%8F%E6%97%B6%E5%8E%9F%E5%88%99">5小时原则</a>」和「<a href="https://wiki.mbalib.com/wiki/%E4%B8%80%E4%B8%87%E5%B0%8F%E6%97%B6%E5%AE%9A%E5%BE%8B">一万小时定律</a>」。</p><p>经验积累的方面，我想数据库索引的思维也许能够带来一些启发。既然时间是有限的，那么我们<u><em>在有限的时间内如何能够获取到更多的信息</em></u>这一问题，也许可以转变为 —— <u><em>如何加快获取信息的速度</em></u>。我的一个想法是，你可以通过各类搜索引擎，不管是 Google、Github 还是企业内的文档搜索工具，来获取到大量成熟、现成的解决方案，然后你可以对这些方案做一个初步的了解，尤其是“这个方案到底解决了什么问题”是必须要弄清楚的，这一系列过程就像是在你的脑海中建立了数据库的 <code>二级索引</code>，以后当你遇到这类问题的时候，你就能够迅速通过这个索引来找到 <code>primary key</code> 然后回表查询，所谓的回表也就是通过各类搜索引擎来帮助获取详细信息了。</p><p>举个例子来说，我的实际工作中并不需要我亲身接触到 Elastic Search，但我会知道它是业内实现搜索功能最常用的中间件；与此同时，我还记得我曾经在逛 Github 的时候，通过 Golang 的标签偶然看见过最近点赞量很高的 <a href="https://github.com/zincsearch/zincsearch">Zinc</a> 引擎，然后我通过它的简介知道它也能够很好的实现搜索功能，只是相比 ES 而言显得更轻量。所以也许在未来的某一天，当我的团队需要从 0 到 1 的去搭建搜索服务的时候，我能够迅速的通过这些“索引”来获取对应的知识帮助团队完成技术决策。</p></blockquote><p>当有了一些积淀之后，后续的规划和目标也理应变的清晰起来，不管是晋升的计划还是对于业务的责任感。字节一直都很强调的 “Ownership” 也许在管理手段上会显得较为严苛，但是毕竟成长是自己的事情，不管外界是如何变化，自己的想法是否明确总是更为重要的。</p><p>具体的说，如果你正在待着的地方，所属行业发展快、团队氛围好、回报比较公平且周围有比你厉害的前辈可以借鉴，那么你所在的环境就已经是很好的了。</p><p>当然，上面所说的这些点，在我看来并不是符合「安娜·卡列尼娜」原则的，很多同行都会为了上述中的一到两点而选择加入一个团队。</p><h3 id="正面思考，用脚投票">正面思考，用脚投票</h3><p>“正面思考，用脚投票”这八个字是我在字节期间某一次听 「Tech Talk 定坤震原面对面」所接触到的。</p><p>任何公司发展到一定规模之后，组织架构的层级就会变得更为复杂，导致我们无法（或是很难）与上层（你的 +2 / +3，或是公司的 CEO）直接进行跨级沟通，也就是说我们往往都只会和自己团队内的 Leader 或别的同事进行沟通。所以这也就是为什么大家常说：“转岗换团队和换公司并没有什么区别。”</p><p>不过这类问题往往是与工作/业务相关的，换句话说就是和你的个人发展相关的 —— 根据我的经验，大家对于“停车场停车不方便”、“下午茶的质量堪忧”、“疫情要来了，我们什么时候居家办公”之类的问题会表现地更坦诚清晰，<u><em>其实无非就是，针对大家共同面临的问题，我们会显得更有底气</em></u>。</p><p>人与人之间的沟通也是一个永恒的话题，过程中不可避免的会有很多矛盾的产生。关于这点，在《<em>Guns, Germs, and Steel</em>: The Fates of Human Societies》（<em>枪炮</em>、<em>病菌与钢铁</em>：人类社会的命运）一书中有许多详细的论证。</p><blockquote><p>书中的第14章《<u>从人人平等到盗贼统治</u>》中描述了人类社群的发展过程：游群-部落-酋邦-国家，每个社群的规模和组成结构都很大差异。书中提出，当社群发展到酋邦阶段时，内部冲突的问题十分严重，主要是因为酋邦人口众多且大部分人彼此之间并没有血缘或姻亲关系，所以酋邦在 7500 年兴起后，人类开始学习面临陌生人的第一课：如何面对经常遇见的陌生人，不互相残杀？</p><p>虽然现代社会的公司和社群的发展不能相提并论，但是 Jared Diamond 在书中的论述还是有可借鉴的点。如果我们按照书中的人数指标来看待公司，那么公司整体就类似于一个酋邦，各个业务线的大部门就相当于一个部落，而我们每个小团队就像是一个游群。但是这么划分之后，显然我们会发现实际的工作体验与 Jared 的论述有极大的出入，我个人的想法是我们一个 5，60 人的业务团队更像是一个融合了“部落”和“酋邦”的社群。</p><p><img src="/img/career_2023/book.jpeg" alt="&quot;社群的种类&quot;"></p></blockquote><p>显然我们不能像治理酋邦或是国家一样，通过宗教和卸除人民武装等手段来解决人与人之间的矛盾，更现实的解决方式还是要从每个人自身出发。在《<em>Selfish Gene</em>》（<em>自私的基因</em>）一书中有提到作者不支持“以进化论为基础的道德观”，在实际工作中我们往往也能发现，基于善意的假设去开展工作往往会比恶意假设带来的结果更好。</p><p>在工作中，我们时常会觉得自己的想法不被别人理解，比如对于自己的绩效不满意，觉得领导给自己的晋升规划过于滞后，或是单纯觉得他人就是在针对自己，在遇到这种情况的时候，往往需要我们去正面思考和应对，当矛盾和 Gap 产生的时候，你是否思考过你是不是有哪些事情没有沟通清楚，如果是的话，你有没有思考过可以找谁去进一步了解信息，有没有理性的劝说对方，举个初高中老师常说的例子：</p><blockquote><p>请计算 x 的值<br>$$<br>x^2 + 2x + 1 = 0<br>$$<br>同学 A：<br>$$<br>\begin{aligned}解: 原式=<br>(x+1)^2 &amp;= 0<br>\newlinex+1   &amp;= 0<br>\newlinex     &amp;= -1<br>\newline答：综上，x = -1<br>\end{aligned}<br>$$<br>同学 B：<br>$$<br>-1<br>$$</p></blockquote><p>阅卷人可能会给同学 B 的答案上打一个“半勾”，然后扣 1-2 分，如果是严格的阅卷人，也可能给 0 分，当然也不排除有的阅卷人不在意这些细节，经常有的同学被扣分之后，也许就直呼阅卷人是个 **。</p><p>实际工作中遇到的情形可能更复杂，不是一个非黑即白的场景，比如也许确实之前在某件事上没做好，然后被领导和同事质疑了，但是那件事之后表现的还不错，甚至还有一些小的亮点，然而年底的绩效还是不及预期，于是可能就觉得大家对自己有偏见了。这种情况下，也许真实的原因，只是团队内有别人在你不知道的方向上表现得更好，或者是今年业务的财报不佳，团队整体的绩效都不好。那么在这种情况下，你是否有和他人积极的沟通过，还是说一直回避这个问题，会对后续发展产生截然不同的两种影响。</p><p>当然也不排除有时自己已经正面的尝试去解决过这个问题，仍然没有什么改善，这种情况下可能你需要尝试跨级沟通，只是这样成本可能会显得“格外的高”；或者你选择离开，寻求更好的环境，也就是标题中的后半段 —— “<a href="https://wiki.mbalib.com/zh-tw/%E7%94%A8%E8%84%9A%E6%8A%95%E7%A5%A8">用脚投票</a>”，当然这样做的成本也不见得有多低，如果当前的环境确实很糟糕，且长时间得不到改善，那么大家也就会用脚来表达自己的意愿和想法。</p><p>但是总的来说，正面思考是首先要做的事情，在一个越大的群体里面，沟通的效率就越低，就越容易产生不信任的感觉，就像软件工程没有银弹一样，是一个永恒存在的问题。既然知道问题的根源来自于此，那么我们应该意识到在绝大多数情况下，都是有一些误会存在而导致的。</p><p>当然，理解“用脚投票”也同样重要，之前在网络上有看过一个言论：</p><blockquote><p>“每个人的每个选择，都是在权衡当下之后做出的最优解。”</p></blockquote><p>但是要注意到权衡的过程往往是不够客观的，比如有的同学会觉得换个工作太麻烦，需要重新复习“八股文”和算法题，也有的同学会因为在网络上看到很多言论说今年的就业形势紧张，现在出来没有什么机会，于是就选择“委屈一下“，保持现状。这样想其实是没有错的，只是你务必要去辨认清楚信息来源的真实性，”网上说的就业形势紧张是我的行业吗？“，”同行找不到工作，那我是不是也找不到？“，”每天早起一小时刷算法题和复习八股文是否会对我的生活造成很大的影响？“ 我有遇见过不少同学，甚至简历都没敢投递出去，就认为自己肯定得不到面试机会。</p><p>除此之外，在权衡过程中除了需要辨认信息的真实性，还需要避免采用单一的“<a href="https://zh.wikipedia.org/wiki/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95#:~:text=%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%EF%BC%88%E8%8B%B1%E8%AA%9E%EF%BC%9Agreedy%20algorithm,%E5%B0%B1%E6%98%AF%E4%B8%80%E7%A7%8D%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E3%80%82">贪心算法</a>”，这个算法的使用场景是很有限的，这里就不展开了。</p><p>补充一个例子：</p><blockquote><p>这里从另一个广泛的现象来阐述一下“正面思考”。大多数实施绩效考核的公司想必都发生过员工对绩效不满意，于是在网络上掀起舆论风暴的情况。我们把视角稍微延伸一下，就会发现其实不只是绩效的问题，当今任何没有得到公正处理（不管是主观还是客观）的事情，都有可能在媒体和网络上发酵出一阵轰动。</p><p>然后作为旁观者、事不关己者、义愤填膺者或是杞人忧天者，我们最终都会经历一个阶段，就是对<u>热度的退减</u>而产生愤怒或失望的情绪。</p><p>之前我也是这么想的，直到在一些分享中听到定坤对于这种现象的理解，才算是释怀了。其中的关键点在于，“让一件事情发酵的目的到底是什么”，这个问题是绝大多数人都没有想清楚的，或是压根就没有去想过的，就是单纯的吃瓜心理在背后作祟，甚至略显刻薄的说，很多人需要一些类似的事情来让自己的情绪得到调节。其实这个问题的答案还是比较单一的，用计算机的术语来说就是“索引的区分度不高”，一个事情发酵出来的目的往往是希望这件事最后会在群众的监督下解决，于是解决的结果会更为公平，即使不能让所有人满意，解决的过程至少也是秉公的。</p><p>那么在事情发酵之后，已经进入处理阶段之后，目的可能也就达成了，那么进一步的扩散应该是毫无必要的，也许还会带来许多诸如违反公司内部保密原则、损害公司的形象的弊端，所以会有一个人为的管控过程。</p><p>当然，也有一些特殊的情况，例如也许有些人让事情发酵的原因不是单纯的希望解决问题，或是管控之后没有进一步的推进问题的处理，不过这些情况不在我们的论证范围内了。</p></blockquote><p>现在，在加入字节跳动后的第 10xx 天，我决定离开这个地方，离开的原因很简单，我的团队经常用 <code>ROI（投资回报率）</code> 来衡量做一个需求的性价比——我觉得现阶段的我继续在这里做下去的 ROI 不高。</p><p>虽然我没有那么好的运气，去经历字节跳动，甚至是<u>国内</u>互联网行业的黄金发展期，但是我幸运地经历了我们业务的高速发展期（虽然看起来这边的业务一直都处在高速发展的道路上），见证了一个团队将业务商业化的全过程，于是自己也在其中获得了很快的成长。</p><p>“ROI 不高” 这个话术过于抽象，具体来说我思考的主要是以下几点：</p><ol><li>产品已经商业化 x 年，正处于稳定的迭代期，亮点和机会相对变少，逐渐到达瓶颈期。</li><li>除了业务稳定之外，我个人对其未来在市场上的发展也不抱太大的希望。</li><li>B 端的 HR 领域产品的复杂性往往体现在业务逻辑，技术深度相对不足。</li><li><strong><u>团队和产品内暴露出来的某些问题，当前的我并没有能力去解决、甚至是推动。</u></strong></li><li>相对来说，当前获得的回报无法掩盖上述的问题。</li></ol><p>通俗的说，对我而言，“打工”中很重要的一环是价值交换的过程，公司可以用物质来换取：我的 idea、我的劳动力、我的人脉（比如猎头行业），也就是说公司可以提供他的资源来换取我的资源。一般来说，在合作关系开始的时候达成这一点是必然的，只是随着时间的发展，平衡会逐渐被打破。</p><p>比如我会觉得随着时间流逝，我对业务日益熟悉，我的产出也日益变高，于是我的工资也理应上升；或者是我觉得团队的工作量相比去年翻了 1.x 倍，如果不给我涨薪，那我的时薪就在下降；除了物质层面，可能我们还会逐渐在技术上也到达瓶颈，比如我们可能会在 x 年的时间里把团队的技术架构和选型基本摸透。当然，更坏的情况是当前的环境会带来直接的负面影响——上面列举的例子充其量也只是“不进则退”，比如职场里“不顺畅的沟通“和”不正当的竞争“也许会给你带来更大的心理负担，又或许过长的工作时间会直接影响你的身体健康。</p><p>当然上面讨论的只是一些可能发生的具体问题，而问题如果能解决的话，就不是什么问题，这也就是为什么我标记了第三点思考的原因。总而言之，我已经正面思考过，思考的结果驱动我“用脚投票”了。</p><h2 id="End">End</h2><blockquote><p>我喜欢出发。凡是到达了的地方，都属于昨天，哪怕那山再青，那水再秀，那风再温柔。 —— 汪国真</p></blockquote><p>感谢字节的三年，庆幸自己的清醒，也佩服自己的勇气。</p>]]></content>
    
    
    <categories>
      
      <category>career</category>
      
    </categories>
    
    
    <tags>
      
      <tag>四川大学</tag>
      
      <tag>ByteDance</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
